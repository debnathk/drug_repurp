{"cells":[{"cell_type":"markdown","metadata":{},"source":["### A Deep Learning based Efficacy Prediction System for Drug Discovery"]},{"cell_type":"markdown","metadata":{},"source":["Here shows the demo for training process"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"]},{"name":"stderr","output_type":"stream","text":["Using TensorFlow backend.\n"]}],"source":["########################################################\n","# All rights reserved. \n","# Author: XIE Zhengwei @ Beijing Gigaceuticals Tech Co., Ltd \n","#                      @ Peking University International Cancer Institute\n","# Contact: xiezhengwei@gmail.com\n","#\n","#\n","########################################################\n","import os\n","import pdb\n","os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n","\n","# from densenet import DLEPS\n","from dleps_predictor2_playground import DLEPS\n","from keras.optimizers import Adam\n","\n","## Note: protobuf error can be resolved by downgrading it v3.20.1"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\debnathk\\Desktop\\Study\\phd@vcu\\codes\\DLEPS-main\\code\\DLEPS\\models\\model_zinc.py:115: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","Model: \"model_6\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_5 (InputLayer)            (None, 978, 2)       0                                            \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, 977, 64)      320         input_5[0][0]                    \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 64)           0           conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            (None, 277, 76)      0                                            \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 512)          33280       global_max_pooling1d_1[0][0]     \n","__________________________________________________________________________________________________\n","conv_1 (Conv1D)                 (None, 269, 9)       6165        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 512)          0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","conv_2 (Conv1D)                 (None, 261, 9)       738         conv_1[0][0]                     \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 512)          262656      dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv_3 (Conv1D)                 (None, 251, 10)      1000        conv_2[0][0]                     \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 512)          0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 2510)         0           conv_3[0][0]                     \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 512)          262656      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 435)          1092285     flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 512)          0           dense_5[0][0]                    \n","__________________________________________________________________________________________________\n","z_mean (Dense)                  (None, 56)           24416       dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","z_log_var (Dense)               (None, 56)           24416       dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 512)          262656      dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 56)           0           z_mean[0][0]                     \n","                                                                 z_log_var[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 568)          0           dense_6[0][0]                    \n","                                                                 lambda[0][0]                     \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 512)          291328      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 512)          0           dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 512)          262656      dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 512)          0           dense_9[0][0]                    \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 512)          262656      dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 512)          0           dense_10[0][0]                   \n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (None, 512)          262656      dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 512)          0           dense_11[0][0]                   \n","__________________________________________________________________________________________________\n","dense_12 (Dense)                (None, 1)            513         dropout_8[0][0]                  \n","==================================================================================================\n","Total params: 3,050,397\n","Trainable params: 3,050,397\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["# pdb.set_trace()\n","dleps_p = DLEPS()\n","model = dleps_p.model[0]\n","model.summary()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(350, 277, 76)\n","(75, 277, 76)\n","(350, 978, 2)\n","(75, 978, 2)\n","(350,)\n","(75,)\n"]}],"source":["import h5py\n","\n","h5f = h5py.File('../../data/vae_train.h5', 'r')\n","vae_train = h5f['data'][:]\n","h5f = h5py.File('../../data/vae_test.h5', 'r')\n","vae_test = h5f['data'][:]\n","h5f = h5py.File('../../data/gene_exp_data_train.h5', 'r')\n","seq_train = h5f['data'][:]\n","h5f = h5py.File('../../data/gene_exp_data_test.h5', 'r')\n","seq_test = h5f['data'][:]\n","h5f2 = h5py.File('../../data/y_train.h5', 'r')\n","y_train = h5f2['data'][:]\n","h5f2 = h5py.File('../../data/y_test.h5', 'r')\n","y_test = h5f2['data'][:]\n","# h5f3 = h5py.File('../../data/gene_exp_data_test.h5', 'r')\n","# seq_test = h5f3['data'][:]\n","# h5f4 = h5py.File('../../data/gene_exp_labels_test.h5', 'r')\n","# seq_labels = h5f4['data'][:]\n","\n","print(vae_train.shape)\n","print(vae_test.shape)\n","print(seq_train.shape)\n","print(seq_test.shape)\n","print(y_train.shape)\n","print(y_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Leveraging transfer learning for pretrained models"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# # Freezing already trained layers\n","# for layers in model.layers[:-8]:\n","#     layers.trainable = False"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# compile the model\n","optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n","model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae']) "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Use ModelCheckpoint to save model and weights\n","from keras.callbacks import ModelCheckpoint\n","# filepath = \"weights.best.sequential.hdf5\"\n","filepath = \"weights.best.conv1d_sample.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"]},{"cell_type":"code","execution_count":7,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 350 samples, validate on 75 samples\n","Epoch 1/1000\n","350/350 [==============================] - 2s 6ms/step - loss: 0.1893 - mae: 0.3252 - val_loss: 0.1943 - val_mae: 0.3327\n","\n","Epoch 00001: val_loss improved from inf to 0.19433, saving model to weights.best.conv1d_sample.hdf5\n","Epoch 2/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.1630 - mae: 0.2890 - val_loss: 0.1940 - val_mae: 0.3428\n","\n","Epoch 00002: val_loss improved from 0.19433 to 0.19400, saving model to weights.best.conv1d_sample.hdf5\n","Epoch 3/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.1491 - mae: 0.2781 - val_loss: 0.2048 - val_mae: 0.3439\n","\n","Epoch 00003: val_loss did not improve from 0.19400\n","Epoch 4/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.1413 - mae: 0.2667 - val_loss: 0.2225 - val_mae: 0.3709\n","\n","Epoch 00004: val_loss did not improve from 0.19400\n","Epoch 5/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.1378 - mae: 0.2744 - val_loss: 0.1921 - val_mae: 0.3284\n","\n","Epoch 00005: val_loss improved from 0.19400 to 0.19207, saving model to weights.best.conv1d_sample.hdf5\n","Epoch 6/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.1302 - mae: 0.2599 - val_loss: 0.1809 - val_mae: 0.3253\n","\n","Epoch 00006: val_loss improved from 0.19207 to 0.18088, saving model to weights.best.conv1d_sample.hdf5\n","Epoch 7/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.1317 - mae: 0.2680 - val_loss: 0.1842 - val_mae: 0.3275\n","\n","Epoch 00007: val_loss did not improve from 0.18088\n","Epoch 8/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.1219 - mae: 0.2430 - val_loss: 0.2013 - val_mae: 0.3449\n","\n","Epoch 00008: val_loss did not improve from 0.18088\n","Epoch 9/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.1154 - mae: 0.2380 - val_loss: 0.2151 - val_mae: 0.3600\n","\n","Epoch 00009: val_loss did not improve from 0.18088\n","Epoch 10/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.1047 - mae: 0.2258 - val_loss: 0.2044 - val_mae: 0.3470\n","\n","Epoch 00010: val_loss did not improve from 0.18088\n","Epoch 11/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.1088 - mae: 0.2302 - val_loss: 0.1989 - val_mae: 0.3428\n","\n","Epoch 00011: val_loss did not improve from 0.18088\n","Epoch 12/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0991 - mae: 0.2173 - val_loss: 0.2427 - val_mae: 0.3859\n","\n","Epoch 00012: val_loss did not improve from 0.18088\n","Epoch 13/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.1059 - mae: 0.2298 - val_loss: 0.2235 - val_mae: 0.3602\n","\n","Epoch 00013: val_loss did not improve from 0.18088\n","Epoch 14/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0914 - mae: 0.2066 - val_loss: 0.2256 - val_mae: 0.3675\n","\n","Epoch 00014: val_loss did not improve from 0.18088\n","Epoch 15/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0943 - mae: 0.2102 - val_loss: 0.2361 - val_mae: 0.3752\n","\n","Epoch 00015: val_loss did not improve from 0.18088\n","Epoch 16/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0816 - mae: 0.1855 - val_loss: 0.2527 - val_mae: 0.3922\n","\n","Epoch 00016: val_loss did not improve from 0.18088\n","Epoch 17/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0728 - mae: 0.1811 - val_loss: 0.2272 - val_mae: 0.3694\n","\n","Epoch 00017: val_loss did not improve from 0.18088\n","Epoch 18/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0668 - mae: 0.1652 - val_loss: 0.2450 - val_mae: 0.3875\n","\n","Epoch 00018: val_loss did not improve from 0.18088\n","Epoch 19/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0703 - mae: 0.1738 - val_loss: 0.2428 - val_mae: 0.3879\n","\n","Epoch 00019: val_loss did not improve from 0.18088\n","Epoch 20/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0610 - mae: 0.1590 - val_loss: 0.2366 - val_mae: 0.3902\n","\n","Epoch 00020: val_loss did not improve from 0.18088\n","Epoch 21/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0571 - mae: 0.1482 - val_loss: 0.2685 - val_mae: 0.4188\n","\n","Epoch 00021: val_loss did not improve from 0.18088\n","Epoch 22/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0526 - mae: 0.1386 - val_loss: 0.2877 - val_mae: 0.4341\n","\n","Epoch 00022: val_loss did not improve from 0.18088\n","Epoch 23/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0515 - mae: 0.1346 - val_loss: 0.2473 - val_mae: 0.3975\n","\n","Epoch 00023: val_loss did not improve from 0.18088\n","Epoch 24/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0452 - mae: 0.1208 - val_loss: 0.2325 - val_mae: 0.3793\n","\n","Epoch 00024: val_loss did not improve from 0.18088\n","Epoch 25/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0450 - mae: 0.1212 - val_loss: 0.2486 - val_mae: 0.3998\n","\n","Epoch 00025: val_loss did not improve from 0.18088\n","Epoch 26/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0443 - mae: 0.1182 - val_loss: 0.2628 - val_mae: 0.4126\n","\n","Epoch 00026: val_loss did not improve from 0.18088\n","Epoch 27/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0430 - mae: 0.1141 - val_loss: 0.2411 - val_mae: 0.3885\n","\n","Epoch 00027: val_loss did not improve from 0.18088\n","Epoch 28/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0402 - mae: 0.1122 - val_loss: 0.2334 - val_mae: 0.3877\n","\n","Epoch 00028: val_loss did not improve from 0.18088\n","Epoch 29/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0413 - mae: 0.1128 - val_loss: 0.2469 - val_mae: 0.3994\n","\n","Epoch 00029: val_loss did not improve from 0.18088\n","Epoch 30/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0364 - mae: 0.1013 - val_loss: 0.2698 - val_mae: 0.4239\n","\n","Epoch 00030: val_loss did not improve from 0.18088\n","Epoch 31/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0349 - mae: 0.0965 - val_loss: 0.2400 - val_mae: 0.3932\n","\n","Epoch 00031: val_loss did not improve from 0.18088\n","Epoch 32/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0359 - mae: 0.0988 - val_loss: 0.2402 - val_mae: 0.3884\n","\n","Epoch 00032: val_loss did not improve from 0.18088\n","Epoch 33/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0330 - mae: 0.0897 - val_loss: 0.2723 - val_mae: 0.4235\n","\n","Epoch 00033: val_loss did not improve from 0.18088\n","Epoch 34/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0358 - mae: 0.0931 - val_loss: 0.2536 - val_mae: 0.4046\n","\n","Epoch 00034: val_loss did not improve from 0.18088\n","Epoch 35/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0318 - mae: 0.0863 - val_loss: 0.2467 - val_mae: 0.3997\n","\n","Epoch 00035: val_loss did not improve from 0.18088\n","Epoch 36/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0316 - mae: 0.0849 - val_loss: 0.2710 - val_mae: 0.4193\n","\n","Epoch 00036: val_loss did not improve from 0.18088\n","Epoch 37/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0309 - mae: 0.0824 - val_loss: 0.2747 - val_mae: 0.4321\n","\n","Epoch 00037: val_loss did not improve from 0.18088\n","Epoch 38/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0319 - mae: 0.0892 - val_loss: 0.2447 - val_mae: 0.3945\n","\n","Epoch 00038: val_loss did not improve from 0.18088\n","Epoch 39/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0324 - mae: 0.0901 - val_loss: 0.2467 - val_mae: 0.4034\n","\n","Epoch 00039: val_loss did not improve from 0.18088\n","Epoch 40/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0313 - mae: 0.0854 - val_loss: 0.2544 - val_mae: 0.4061\n","\n","Epoch 00040: val_loss did not improve from 0.18088\n","Epoch 41/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0300 - mae: 0.0841 - val_loss: 0.2642 - val_mae: 0.4177\n","\n","Epoch 00041: val_loss did not improve from 0.18088\n","Epoch 42/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0277 - mae: 0.0738 - val_loss: 0.2605 - val_mae: 0.4147\n","\n","Epoch 00042: val_loss did not improve from 0.18088\n","Epoch 43/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0311 - mae: 0.0854 - val_loss: 0.2393 - val_mae: 0.3905\n","\n","Epoch 00043: val_loss did not improve from 0.18088\n","Epoch 44/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0305 - mae: 0.0847 - val_loss: 0.2517 - val_mae: 0.4077\n","\n","Epoch 00044: val_loss did not improve from 0.18088\n","Epoch 45/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0283 - mae: 0.0777 - val_loss: 0.2650 - val_mae: 0.4133\n","\n","Epoch 00045: val_loss did not improve from 0.18088\n","Epoch 46/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0296 - mae: 0.0819 - val_loss: 0.2478 - val_mae: 0.4075\n","\n","Epoch 00046: val_loss did not improve from 0.18088\n","Epoch 47/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0287 - mae: 0.0802 - val_loss: 0.2536 - val_mae: 0.4110\n","\n","Epoch 00047: val_loss did not improve from 0.18088\n","Epoch 48/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0259 - mae: 0.0686 - val_loss: 0.2669 - val_mae: 0.4212\n","\n","Epoch 00048: val_loss did not improve from 0.18088\n","Epoch 49/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0309 - mae: 0.0803 - val_loss: 0.2417 - val_mae: 0.3990\n","\n","Epoch 00049: val_loss did not improve from 0.18088\n","Epoch 50/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0272 - mae: 0.0734 - val_loss: 0.2422 - val_mae: 0.3935\n","\n","Epoch 00050: val_loss did not improve from 0.18088\n","Epoch 51/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0269 - mae: 0.0686 - val_loss: 0.2609 - val_mae: 0.4152\n","\n","Epoch 00051: val_loss did not improve from 0.18088\n","Epoch 52/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0257 - mae: 0.0687 - val_loss: 0.2466 - val_mae: 0.4020\n","\n","Epoch 00052: val_loss did not improve from 0.18088\n","Epoch 53/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0253 - mae: 0.0650 - val_loss: 0.2412 - val_mae: 0.3986\n","\n","Epoch 00053: val_loss did not improve from 0.18088\n","Epoch 54/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0257 - mae: 0.0690 - val_loss: 0.2577 - val_mae: 0.4144\n","\n","Epoch 00054: val_loss did not improve from 0.18088\n","Epoch 55/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0248 - mae: 0.0660 - val_loss: 0.2518 - val_mae: 0.4061\n","\n","Epoch 00055: val_loss did not improve from 0.18088\n","Epoch 56/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0258 - mae: 0.0668 - val_loss: 0.2360 - val_mae: 0.3892\n","\n","Epoch 00056: val_loss did not improve from 0.18088\n","Epoch 57/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0269 - mae: 0.0716 - val_loss: 0.2577 - val_mae: 0.4116\n","\n","Epoch 00057: val_loss did not improve from 0.18088\n","Epoch 58/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0251 - mae: 0.0652 - val_loss: 0.2650 - val_mae: 0.4222\n","\n","Epoch 00058: val_loss did not improve from 0.18088\n","Epoch 59/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0253 - mae: 0.0666 - val_loss: 0.2403 - val_mae: 0.3971\n","\n","Epoch 00059: val_loss did not improve from 0.18088\n","Epoch 60/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0247 - mae: 0.0652 - val_loss: 0.2601 - val_mae: 0.4170\n","\n","Epoch 00060: val_loss did not improve from 0.18088\n","Epoch 61/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0236 - mae: 0.0599 - val_loss: 0.2547 - val_mae: 0.4088\n","\n","Epoch 00061: val_loss did not improve from 0.18088\n","Epoch 62/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0246 - mae: 0.0635 - val_loss: 0.2411 - val_mae: 0.3938\n","\n","Epoch 00062: val_loss did not improve from 0.18088\n","Epoch 63/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0245 - mae: 0.0658 - val_loss: 0.2528 - val_mae: 0.4085\n","\n","Epoch 00063: val_loss did not improve from 0.18088\n","Epoch 64/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0232 - mae: 0.0589 - val_loss: 0.2661 - val_mae: 0.4218\n","\n","Epoch 00064: val_loss did not improve from 0.18088\n","Epoch 65/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0242 - mae: 0.0656 - val_loss: 0.2457 - val_mae: 0.4040\n","\n","Epoch 00065: val_loss did not improve from 0.18088\n","Epoch 66/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0258 - mae: 0.0716 - val_loss: 0.2479 - val_mae: 0.3996\n","\n","Epoch 00066: val_loss did not improve from 0.18088\n","Epoch 67/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0247 - mae: 0.0666 - val_loss: 0.2572 - val_mae: 0.4127\n","\n","Epoch 00067: val_loss did not improve from 0.18088\n","Epoch 68/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0227 - mae: 0.0581 - val_loss: 0.2465 - val_mae: 0.4025\n","\n","Epoch 00068: val_loss did not improve from 0.18088\n","Epoch 69/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0231 - mae: 0.0602 - val_loss: 0.2575 - val_mae: 0.4126\n","\n","Epoch 00069: val_loss did not improve from 0.18088\n","Epoch 70/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0231 - mae: 0.0577 - val_loss: 0.2572 - val_mae: 0.4098\n","\n","Epoch 00070: val_loss did not improve from 0.18088\n","Epoch 71/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0227 - mae: 0.0584 - val_loss: 0.2499 - val_mae: 0.4028\n","\n","Epoch 00071: val_loss did not improve from 0.18088\n","Epoch 72/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0226 - mae: 0.0558 - val_loss: 0.2500 - val_mae: 0.4042\n","\n","Epoch 00072: val_loss did not improve from 0.18088\n","Epoch 73/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0222 - mae: 0.0561 - val_loss: 0.2453 - val_mae: 0.4024\n","\n","Epoch 00073: val_loss did not improve from 0.18088\n","Epoch 74/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0222 - mae: 0.0569 - val_loss: 0.2418 - val_mae: 0.3975\n","\n","Epoch 00074: val_loss did not improve from 0.18088\n","Epoch 75/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0221 - mae: 0.0586 - val_loss: 0.2557 - val_mae: 0.4149\n","\n","Epoch 00075: val_loss did not improve from 0.18088\n","Epoch 76/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0229 - mae: 0.0613 - val_loss: 0.2466 - val_mae: 0.3991\n","\n","Epoch 00076: val_loss did not improve from 0.18088\n","Epoch 77/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0223 - mae: 0.0561 - val_loss: 0.2415 - val_mae: 0.3966\n","\n","Epoch 00077: val_loss did not improve from 0.18088\n","Epoch 78/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0223 - mae: 0.0583 - val_loss: 0.2490 - val_mae: 0.4021\n","\n","Epoch 00078: val_loss did not improve from 0.18088\n","Epoch 79/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0213 - mae: 0.0550 - val_loss: 0.2478 - val_mae: 0.4019\n","\n","Epoch 00079: val_loss did not improve from 0.18088\n","Epoch 80/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0216 - mae: 0.0558 - val_loss: 0.2392 - val_mae: 0.3924\n","\n","Epoch 00080: val_loss did not improve from 0.18088\n","Epoch 81/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0217 - mae: 0.0559 - val_loss: 0.2545 - val_mae: 0.4102\n","\n","Epoch 00081: val_loss did not improve from 0.18088\n","Epoch 82/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0220 - mae: 0.0593 - val_loss: 0.2564 - val_mae: 0.4076\n","\n","Epoch 00082: val_loss did not improve from 0.18088\n","Epoch 83/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0211 - mae: 0.0527 - val_loss: 0.2429 - val_mae: 0.3998\n","\n","Epoch 00083: val_loss did not improve from 0.18088\n","Epoch 84/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0226 - mae: 0.0612 - val_loss: 0.2465 - val_mae: 0.3991\n","\n","Epoch 00084: val_loss did not improve from 0.18088\n","Epoch 85/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0210 - mae: 0.0573 - val_loss: 0.2514 - val_mae: 0.4082\n","\n","Epoch 00085: val_loss did not improve from 0.18088\n","Epoch 86/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0216 - mae: 0.0570 - val_loss: 0.2404 - val_mae: 0.3947\n","\n","Epoch 00086: val_loss did not improve from 0.18088\n","Epoch 87/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0204 - mae: 0.0521 - val_loss: 0.2473 - val_mae: 0.4025\n","\n","Epoch 00087: val_loss did not improve from 0.18088\n","Epoch 88/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0204 - mae: 0.0519 - val_loss: 0.2530 - val_mae: 0.4026\n","\n","Epoch 00088: val_loss did not improve from 0.18088\n","Epoch 89/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0213 - mae: 0.0577 - val_loss: 0.2548 - val_mae: 0.4081\n","\n","Epoch 00089: val_loss did not improve from 0.18088\n","Epoch 90/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0210 - mae: 0.0570 - val_loss: 0.2543 - val_mae: 0.4088\n","\n","Epoch 00090: val_loss did not improve from 0.18088\n","Epoch 91/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0205 - mae: 0.0510 - val_loss: 0.2388 - val_mae: 0.3939\n","\n","Epoch 00091: val_loss did not improve from 0.18088\n","Epoch 92/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0209 - mae: 0.0543 - val_loss: 0.2454 - val_mae: 0.4038\n","\n","Epoch 00092: val_loss did not improve from 0.18088\n","Epoch 93/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0214 - mae: 0.0579 - val_loss: 0.2408 - val_mae: 0.3932\n","\n","Epoch 00093: val_loss did not improve from 0.18088\n","Epoch 94/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0204 - mae: 0.0538 - val_loss: 0.2448 - val_mae: 0.3999\n","\n","Epoch 00094: val_loss did not improve from 0.18088\n","Epoch 95/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0208 - mae: 0.0562 - val_loss: 0.2526 - val_mae: 0.4040\n","\n","Epoch 00095: val_loss did not improve from 0.18088\n","Epoch 96/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0197 - mae: 0.0504 - val_loss: 0.2458 - val_mae: 0.4038\n","\n","Epoch 00096: val_loss did not improve from 0.18088\n","Epoch 97/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0203 - mae: 0.0537 - val_loss: 0.2480 - val_mae: 0.4045\n","\n","Epoch 00097: val_loss did not improve from 0.18088\n","Epoch 98/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0200 - mae: 0.0519 - val_loss: 0.2371 - val_mae: 0.3918\n","\n","Epoch 00098: val_loss did not improve from 0.18088\n","Epoch 99/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0193 - mae: 0.0509 - val_loss: 0.2465 - val_mae: 0.4009\n","\n","Epoch 00099: val_loss did not improve from 0.18088\n","Epoch 100/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0206 - mae: 0.0516 - val_loss: 0.2480 - val_mae: 0.4003\n","\n","Epoch 00100: val_loss did not improve from 0.18088\n","Epoch 101/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0202 - mae: 0.0530 - val_loss: 0.2492 - val_mae: 0.4037\n","\n","Epoch 00101: val_loss did not improve from 0.18088\n","Epoch 102/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0211 - mae: 0.0602 - val_loss: 0.2561 - val_mae: 0.4064\n","\n","Epoch 00102: val_loss did not improve from 0.18088\n","Epoch 103/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0194 - mae: 0.0521 - val_loss: 0.2443 - val_mae: 0.3994\n","\n","Epoch 00103: val_loss did not improve from 0.18088\n","Epoch 104/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0187 - mae: 0.0490 - val_loss: 0.2455 - val_mae: 0.4010\n","\n","Epoch 00104: val_loss did not improve from 0.18088\n","Epoch 105/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0191 - mae: 0.0506 - val_loss: 0.2674 - val_mae: 0.4245\n","\n","Epoch 00105: val_loss did not improve from 0.18088\n","Epoch 106/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0195 - mae: 0.0539 - val_loss: 0.2438 - val_mae: 0.3961\n","\n","Epoch 00106: val_loss did not improve from 0.18088\n","Epoch 107/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0197 - mae: 0.0534 - val_loss: 0.2424 - val_mae: 0.3985\n","\n","Epoch 00107: val_loss did not improve from 0.18088\n","Epoch 108/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0193 - mae: 0.0537 - val_loss: 0.2501 - val_mae: 0.4025\n","\n","Epoch 00108: val_loss did not improve from 0.18088\n","Epoch 109/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0203 - mae: 0.0585 - val_loss: 0.2489 - val_mae: 0.4094\n","\n","Epoch 00109: val_loss did not improve from 0.18088\n","Epoch 110/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0201 - mae: 0.0616 - val_loss: 0.2355 - val_mae: 0.3873\n","\n","Epoch 00110: val_loss did not improve from 0.18088\n","Epoch 111/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0207 - mae: 0.0619 - val_loss: 0.2381 - val_mae: 0.3960\n","\n","Epoch 00111: val_loss did not improve from 0.18088\n","Epoch 112/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0189 - mae: 0.0498 - val_loss: 0.2334 - val_mae: 0.3860\n","\n","Epoch 00112: val_loss did not improve from 0.18088\n","Epoch 113/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0201 - mae: 0.0545 - val_loss: 0.2599 - val_mae: 0.4156\n","\n","Epoch 00113: val_loss did not improve from 0.18088\n","Epoch 114/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0193 - mae: 0.0538 - val_loss: 0.2422 - val_mae: 0.3966\n","\n","Epoch 00114: val_loss did not improve from 0.18088\n","Epoch 115/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0186 - mae: 0.0492 - val_loss: 0.2353 - val_mae: 0.3913\n","\n","Epoch 00115: val_loss did not improve from 0.18088\n","Epoch 116/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0181 - mae: 0.0483 - val_loss: 0.2394 - val_mae: 0.3955\n","\n","Epoch 00116: val_loss did not improve from 0.18088\n","Epoch 117/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0180 - mae: 0.0470 - val_loss: 0.2323 - val_mae: 0.3862\n","\n","Epoch 00117: val_loss did not improve from 0.18088\n","Epoch 118/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0188 - mae: 0.0498 - val_loss: 0.2413 - val_mae: 0.3979\n","\n","Epoch 00118: val_loss did not improve from 0.18088\n","Epoch 119/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0185 - mae: 0.0493 - val_loss: 0.2367 - val_mae: 0.3898\n","\n","Epoch 00119: val_loss did not improve from 0.18088\n","Epoch 120/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0179 - mae: 0.0478 - val_loss: 0.2397 - val_mae: 0.3943\n","\n","Epoch 00120: val_loss did not improve from 0.18088\n","Epoch 121/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0174 - mae: 0.0469 - val_loss: 0.2443 - val_mae: 0.3967\n","\n","Epoch 00121: val_loss did not improve from 0.18088\n","Epoch 122/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0176 - mae: 0.0466 - val_loss: 0.2381 - val_mae: 0.3952\n","\n","Epoch 00122: val_loss did not improve from 0.18088\n","Epoch 123/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0182 - mae: 0.0494 - val_loss: 0.2385 - val_mae: 0.3935\n","\n","Epoch 00123: val_loss did not improve from 0.18088\n","Epoch 124/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0176 - mae: 0.0468 - val_loss: 0.2574 - val_mae: 0.4129\n","\n","Epoch 00124: val_loss did not improve from 0.18088\n","Epoch 125/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0180 - mae: 0.0494 - val_loss: 0.2413 - val_mae: 0.3988\n","\n","Epoch 00125: val_loss did not improve from 0.18088\n","Epoch 126/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0192 - mae: 0.0558 - val_loss: 0.2382 - val_mae: 0.3892\n","\n","Epoch 00126: val_loss did not improve from 0.18088\n","Epoch 127/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0185 - mae: 0.0526 - val_loss: 0.2560 - val_mae: 0.4091\n","\n","Epoch 00127: val_loss did not improve from 0.18088\n","Epoch 128/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0189 - mae: 0.0546 - val_loss: 0.2496 - val_mae: 0.3986\n","\n","Epoch 00128: val_loss did not improve from 0.18088\n","Epoch 129/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0178 - mae: 0.0499 - val_loss: 0.2479 - val_mae: 0.4026\n","\n","Epoch 00129: val_loss did not improve from 0.18088\n","Epoch 130/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0181 - mae: 0.0511 - val_loss: 0.2526 - val_mae: 0.4023\n","\n","Epoch 00130: val_loss did not improve from 0.18088\n","Epoch 131/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0170 - mae: 0.0472 - val_loss: 0.2521 - val_mae: 0.4050\n","\n","Epoch 00131: val_loss did not improve from 0.18088\n","Epoch 132/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0195 - mae: 0.0551 - val_loss: 0.2353 - val_mae: 0.3813\n","\n","Epoch 00132: val_loss did not improve from 0.18088\n","Epoch 133/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0211 - mae: 0.0646 - val_loss: 0.2347 - val_mae: 0.3919\n","\n","Epoch 00133: val_loss did not improve from 0.18088\n","Epoch 134/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0184 - mae: 0.0532 - val_loss: 0.2629 - val_mae: 0.4216\n","\n","Epoch 00134: val_loss did not improve from 0.18088\n","Epoch 135/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0202 - mae: 0.0630 - val_loss: 0.2234 - val_mae: 0.3835\n","\n","Epoch 00135: val_loss did not improve from 0.18088\n","Epoch 136/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0192 - mae: 0.0577 - val_loss: 0.2273 - val_mae: 0.3868\n","\n","Epoch 00136: val_loss did not improve from 0.18088\n","Epoch 137/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0190 - mae: 0.0569 - val_loss: 0.2587 - val_mae: 0.4154\n","\n","Epoch 00137: val_loss did not improve from 0.18088\n","Epoch 138/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0167 - mae: 0.0454 - val_loss: 0.2442 - val_mae: 0.3960\n","\n","Epoch 00138: val_loss did not improve from 0.18088\n","Epoch 139/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0172 - mae: 0.0492 - val_loss: 0.2430 - val_mae: 0.3973\n","\n","Epoch 00139: val_loss did not improve from 0.18088\n","Epoch 140/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0172 - mae: 0.0483 - val_loss: 0.2532 - val_mae: 0.4085\n","\n","Epoch 00140: val_loss did not improve from 0.18088\n","Epoch 141/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0173 - mae: 0.0494 - val_loss: 0.2357 - val_mae: 0.3910\n","\n","Epoch 00141: val_loss did not improve from 0.18088\n","Epoch 142/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0177 - mae: 0.0516 - val_loss: 0.2328 - val_mae: 0.3869\n","\n","Epoch 00142: val_loss did not improve from 0.18088\n","Epoch 143/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0173 - mae: 0.0515 - val_loss: 0.2612 - val_mae: 0.4139\n","\n","Epoch 00143: val_loss did not improve from 0.18088\n","Epoch 144/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0176 - mae: 0.0506 - val_loss: 0.2522 - val_mae: 0.4076\n","\n","Epoch 00144: val_loss did not improve from 0.18088\n","Epoch 145/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0166 - mae: 0.0486 - val_loss: 0.2409 - val_mae: 0.3919\n","\n","Epoch 00145: val_loss did not improve from 0.18088\n","Epoch 146/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0167 - mae: 0.0481 - val_loss: 0.2407 - val_mae: 0.3952\n","\n","Epoch 00146: val_loss did not improve from 0.18088\n","Epoch 147/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0173 - mae: 0.0529 - val_loss: 0.2425 - val_mae: 0.3955\n","\n","Epoch 00147: val_loss did not improve from 0.18088\n","Epoch 148/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0164 - mae: 0.0461 - val_loss: 0.2528 - val_mae: 0.4089\n","\n","Epoch 00148: val_loss did not improve from 0.18088\n","Epoch 149/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0165 - mae: 0.0477 - val_loss: 0.2507 - val_mae: 0.4026\n","\n","Epoch 00149: val_loss did not improve from 0.18088\n","Epoch 150/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0160 - mae: 0.0467 - val_loss: 0.2486 - val_mae: 0.4053\n","\n","Epoch 00150: val_loss did not improve from 0.18088\n","Epoch 151/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0166 - mae: 0.0467 - val_loss: 0.2407 - val_mae: 0.3933\n","\n","Epoch 00151: val_loss did not improve from 0.18088\n","Epoch 152/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0167 - mae: 0.0479 - val_loss: 0.2397 - val_mae: 0.3950\n","\n","Epoch 00152: val_loss did not improve from 0.18088\n","Epoch 153/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0163 - mae: 0.0460 - val_loss: 0.2364 - val_mae: 0.3894\n","\n","Epoch 00153: val_loss did not improve from 0.18088\n","Epoch 154/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0171 - mae: 0.0507 - val_loss: 0.2570 - val_mae: 0.4141\n","\n","Epoch 00154: val_loss did not improve from 0.18088\n","Epoch 155/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0165 - mae: 0.0495 - val_loss: 0.2475 - val_mae: 0.4018\n","\n","Epoch 00155: val_loss did not improve from 0.18088\n","Epoch 156/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0158 - mae: 0.0474 - val_loss: 0.2288 - val_mae: 0.3866\n","\n","Epoch 00156: val_loss did not improve from 0.18088\n","Epoch 157/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0174 - mae: 0.0547 - val_loss: 0.2392 - val_mae: 0.3955\n","\n","Epoch 00157: val_loss did not improve from 0.18088\n","Epoch 158/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0163 - mae: 0.0491 - val_loss: 0.2586 - val_mae: 0.4163\n","\n","Epoch 00158: val_loss did not improve from 0.18088\n","Epoch 159/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0158 - mae: 0.0476 - val_loss: 0.2392 - val_mae: 0.3894\n","\n","Epoch 00159: val_loss did not improve from 0.18088\n","Epoch 160/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0157 - mae: 0.0460 - val_loss: 0.2471 - val_mae: 0.4000\n","\n","Epoch 00160: val_loss did not improve from 0.18088\n","Epoch 161/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0158 - mae: 0.0460 - val_loss: 0.2493 - val_mae: 0.3999\n","\n","Epoch 00161: val_loss did not improve from 0.18088\n","Epoch 162/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0157 - mae: 0.0472 - val_loss: 0.2453 - val_mae: 0.4015\n","\n","Epoch 00162: val_loss did not improve from 0.18088\n","Epoch 163/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0156 - mae: 0.0465 - val_loss: 0.2491 - val_mae: 0.4039\n","\n","Epoch 00163: val_loss did not improve from 0.18088\n","Epoch 164/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0155 - mae: 0.0467 - val_loss: 0.2485 - val_mae: 0.4031\n","\n","Epoch 00164: val_loss did not improve from 0.18088\n","Epoch 165/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0153 - mae: 0.0453 - val_loss: 0.2416 - val_mae: 0.3988\n","\n","Epoch 00165: val_loss did not improve from 0.18088\n","Epoch 166/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0150 - mae: 0.0432 - val_loss: 0.2436 - val_mae: 0.3968\n","\n","Epoch 00166: val_loss did not improve from 0.18088\n","Epoch 167/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0157 - mae: 0.0453 - val_loss: 0.2492 - val_mae: 0.4015\n","\n","Epoch 00167: val_loss did not improve from 0.18088\n","Epoch 168/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0152 - mae: 0.0435 - val_loss: 0.2411 - val_mae: 0.3928\n","\n","Epoch 00168: val_loss did not improve from 0.18088\n","Epoch 169/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0153 - mae: 0.0435 - val_loss: 0.2568 - val_mae: 0.4087\n","\n","Epoch 00169: val_loss did not improve from 0.18088\n","Epoch 170/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0152 - mae: 0.0456 - val_loss: 0.2535 - val_mae: 0.4068\n","\n","Epoch 00170: val_loss did not improve from 0.18088\n","Epoch 171/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0155 - mae: 0.0441 - val_loss: 0.2415 - val_mae: 0.3943\n","\n","Epoch 00171: val_loss did not improve from 0.18088\n","Epoch 172/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0152 - mae: 0.0462 - val_loss: 0.2581 - val_mae: 0.4133\n","\n","Epoch 00172: val_loss did not improve from 0.18088\n","Epoch 173/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0151 - mae: 0.0462 - val_loss: 0.2515 - val_mae: 0.4055\n","\n","Epoch 00173: val_loss did not improve from 0.18088\n","Epoch 174/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0149 - mae: 0.0448 - val_loss: 0.2407 - val_mae: 0.3924\n","\n","Epoch 00174: val_loss did not improve from 0.18088\n","Epoch 175/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0164 - mae: 0.0542 - val_loss: 0.2468 - val_mae: 0.3985\n","\n","Epoch 00175: val_loss did not improve from 0.18088\n","Epoch 176/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0148 - mae: 0.0461 - val_loss: 0.2474 - val_mae: 0.4025\n","\n","Epoch 00176: val_loss did not improve from 0.18088\n","Epoch 177/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0150 - mae: 0.0451 - val_loss: 0.2370 - val_mae: 0.3885\n","\n","Epoch 00177: val_loss did not improve from 0.18088\n","Epoch 178/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0148 - mae: 0.0439 - val_loss: 0.2429 - val_mae: 0.3949\n","\n","Epoch 00178: val_loss did not improve from 0.18088\n","Epoch 179/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0148 - mae: 0.0460 - val_loss: 0.2423 - val_mae: 0.3952\n","\n","Epoch 00179: val_loss did not improve from 0.18088\n","Epoch 180/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0147 - mae: 0.0459 - val_loss: 0.2444 - val_mae: 0.3964\n","\n","Epoch 00180: val_loss did not improve from 0.18088\n","Epoch 181/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0155 - mae: 0.0489 - val_loss: 0.2412 - val_mae: 0.3923\n","\n","Epoch 00181: val_loss did not improve from 0.18088\n","Epoch 182/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0150 - mae: 0.0473 - val_loss: 0.2510 - val_mae: 0.4036\n","\n","Epoch 00182: val_loss did not improve from 0.18088\n","Epoch 183/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0137 - mae: 0.0389 - val_loss: 0.2550 - val_mae: 0.4087\n","\n","Epoch 00183: val_loss did not improve from 0.18088\n","Epoch 184/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0147 - mae: 0.0465 - val_loss: 0.2458 - val_mae: 0.3980\n","\n","Epoch 00184: val_loss did not improve from 0.18088\n","Epoch 185/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0143 - mae: 0.0427 - val_loss: 0.2414 - val_mae: 0.3951\n","\n","Epoch 00185: val_loss did not improve from 0.18088\n","Epoch 186/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0142 - mae: 0.0427 - val_loss: 0.2536 - val_mae: 0.4092\n","\n","Epoch 00186: val_loss did not improve from 0.18088\n","Epoch 187/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0140 - mae: 0.0432 - val_loss: 0.2529 - val_mae: 0.4105\n","\n","Epoch 00187: val_loss did not improve from 0.18088\n","Epoch 188/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0141 - mae: 0.0411 - val_loss: 0.2391 - val_mae: 0.3973\n","\n","Epoch 00188: val_loss did not improve from 0.18088\n","Epoch 189/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0150 - mae: 0.0484 - val_loss: 0.2474 - val_mae: 0.4008\n","\n","Epoch 00189: val_loss did not improve from 0.18088\n","Epoch 190/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0141 - mae: 0.0426 - val_loss: 0.2487 - val_mae: 0.4063\n","\n","Epoch 00190: val_loss did not improve from 0.18088\n","Epoch 191/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0142 - mae: 0.0428 - val_loss: 0.2523 - val_mae: 0.4054\n","\n","Epoch 00191: val_loss did not improve from 0.18088\n","Epoch 192/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0145 - mae: 0.0468 - val_loss: 0.2575 - val_mae: 0.4149\n","\n","Epoch 00192: val_loss did not improve from 0.18088\n","Epoch 193/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0147 - mae: 0.0465 - val_loss: 0.2506 - val_mae: 0.4049\n","\n","Epoch 00193: val_loss did not improve from 0.18088\n","Epoch 194/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0144 - mae: 0.0455 - val_loss: 0.2647 - val_mae: 0.4204\n","\n","Epoch 00194: val_loss did not improve from 0.18088\n","Epoch 195/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0142 - mae: 0.0479 - val_loss: 0.2374 - val_mae: 0.3886\n","\n","Epoch 00195: val_loss did not improve from 0.18088\n","Epoch 196/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0147 - mae: 0.0487 - val_loss: 0.2483 - val_mae: 0.4036\n","\n","Epoch 00196: val_loss did not improve from 0.18088\n","Epoch 197/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0150 - mae: 0.0479 - val_loss: 0.2462 - val_mae: 0.3959\n","\n","Epoch 00197: val_loss did not improve from 0.18088\n","Epoch 198/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0159 - mae: 0.0529 - val_loss: 0.2590 - val_mae: 0.4129\n","\n","Epoch 00198: val_loss did not improve from 0.18088\n","Epoch 199/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0137 - mae: 0.0445 - val_loss: 0.2659 - val_mae: 0.4153\n","\n","Epoch 00199: val_loss did not improve from 0.18088\n","Epoch 200/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0145 - mae: 0.0445 - val_loss: 0.2407 - val_mae: 0.3902\n","\n","Epoch 00200: val_loss did not improve from 0.18088\n","Epoch 201/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0149 - mae: 0.0506 - val_loss: 0.2449 - val_mae: 0.3977\n","\n","Epoch 00201: val_loss did not improve from 0.18088\n","Epoch 202/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0132 - mae: 0.0402 - val_loss: 0.2724 - val_mae: 0.4276\n","\n","Epoch 00202: val_loss did not improve from 0.18088\n","Epoch 203/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0147 - mae: 0.0502 - val_loss: 0.2487 - val_mae: 0.4004\n","\n","Epoch 00203: val_loss did not improve from 0.18088\n","Epoch 204/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0138 - mae: 0.0451 - val_loss: 0.2498 - val_mae: 0.4022\n","\n","Epoch 00204: val_loss did not improve from 0.18088\n","Epoch 205/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0139 - mae: 0.0444 - val_loss: 0.2508 - val_mae: 0.4019\n","\n","Epoch 00205: val_loss did not improve from 0.18088\n","Epoch 206/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0141 - mae: 0.0458 - val_loss: 0.2430 - val_mae: 0.3977\n","\n","Epoch 00206: val_loss did not improve from 0.18088\n","Epoch 207/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0133 - mae: 0.0431 - val_loss: 0.2347 - val_mae: 0.3861\n","\n","Epoch 00207: val_loss did not improve from 0.18088\n","Epoch 208/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0136 - mae: 0.0438 - val_loss: 0.2378 - val_mae: 0.3954\n","\n","Epoch 00208: val_loss did not improve from 0.18088\n","Epoch 209/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0130 - mae: 0.0417 - val_loss: 0.2400 - val_mae: 0.3952\n","\n","Epoch 00209: val_loss did not improve from 0.18088\n","Epoch 210/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0135 - mae: 0.0451 - val_loss: 0.2418 - val_mae: 0.3972\n","\n","Epoch 00210: val_loss did not improve from 0.18088\n","Epoch 211/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0128 - mae: 0.0403 - val_loss: 0.2383 - val_mae: 0.3913\n","\n","Epoch 00211: val_loss did not improve from 0.18088\n","Epoch 212/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0135 - mae: 0.0435 - val_loss: 0.2393 - val_mae: 0.3956\n","\n","Epoch 00212: val_loss did not improve from 0.18088\n","Epoch 213/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0129 - mae: 0.0422 - val_loss: 0.2443 - val_mae: 0.3993\n","\n","Epoch 00213: val_loss did not improve from 0.18088\n","Epoch 214/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0132 - mae: 0.0428 - val_loss: 0.2377 - val_mae: 0.3950\n","\n","Epoch 00214: val_loss did not improve from 0.18088\n","Epoch 215/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0134 - mae: 0.0443 - val_loss: 0.2367 - val_mae: 0.3924\n","\n","Epoch 00215: val_loss did not improve from 0.18088\n","Epoch 216/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0128 - mae: 0.0423 - val_loss: 0.2430 - val_mae: 0.4009\n","\n","Epoch 00216: val_loss did not improve from 0.18088\n","Epoch 217/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0131 - mae: 0.0445 - val_loss: 0.2377 - val_mae: 0.3925\n","\n","Epoch 00217: val_loss did not improve from 0.18088\n","Epoch 218/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0128 - mae: 0.0422 - val_loss: 0.2363 - val_mae: 0.3910\n","\n","Epoch 00218: val_loss did not improve from 0.18088\n","Epoch 219/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0128 - mae: 0.0401 - val_loss: 0.2528 - val_mae: 0.4075\n","\n","Epoch 00219: val_loss did not improve from 0.18088\n","Epoch 220/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0130 - mae: 0.0421 - val_loss: 0.2535 - val_mae: 0.4091\n","\n","Epoch 00220: val_loss did not improve from 0.18088\n","Epoch 221/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0127 - mae: 0.0415 - val_loss: 0.2426 - val_mae: 0.3975\n","\n","Epoch 00221: val_loss did not improve from 0.18088\n","Epoch 222/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0127 - mae: 0.0410 - val_loss: 0.2592 - val_mae: 0.4158\n","\n","Epoch 00222: val_loss did not improve from 0.18088\n","Epoch 223/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0123 - mae: 0.0396 - val_loss: 0.2492 - val_mae: 0.4003\n","\n","Epoch 00223: val_loss did not improve from 0.18088\n","Epoch 224/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0129 - mae: 0.0421 - val_loss: 0.2413 - val_mae: 0.3967\n","\n","Epoch 00224: val_loss did not improve from 0.18088\n","Epoch 225/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0127 - mae: 0.0438 - val_loss: 0.2527 - val_mae: 0.3987\n","\n","Epoch 00225: val_loss did not improve from 0.18088\n","Epoch 226/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0140 - mae: 0.0511 - val_loss: 0.2471 - val_mae: 0.4013\n","\n","Epoch 00226: val_loss did not improve from 0.18088\n","Epoch 227/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0144 - mae: 0.0536 - val_loss: 0.2405 - val_mae: 0.3857\n","\n","Epoch 00227: val_loss did not improve from 0.18088\n","Epoch 228/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0130 - mae: 0.0469 - val_loss: 0.2604 - val_mae: 0.4156\n","\n","Epoch 00228: val_loss did not improve from 0.18088\n","Epoch 229/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0134 - mae: 0.0501 - val_loss: 0.2507 - val_mae: 0.4034\n","\n","Epoch 00229: val_loss did not improve from 0.18088\n","Epoch 230/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0130 - mae: 0.0457 - val_loss: 0.2599 - val_mae: 0.4140\n","\n","Epoch 00230: val_loss did not improve from 0.18088\n","Epoch 231/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0128 - mae: 0.0447 - val_loss: 0.2611 - val_mae: 0.4141\n","\n","Epoch 00231: val_loss did not improve from 0.18088\n","Epoch 232/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0133 - mae: 0.0482 - val_loss: 0.2473 - val_mae: 0.4007\n","\n","Epoch 00232: val_loss did not improve from 0.18088\n","Epoch 233/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0137 - mae: 0.0510 - val_loss: 0.2460 - val_mae: 0.3975\n","\n","Epoch 00233: val_loss did not improve from 0.18088\n","Epoch 234/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0132 - mae: 0.0464 - val_loss: 0.2546 - val_mae: 0.4071\n","\n","Epoch 00234: val_loss did not improve from 0.18088\n","Epoch 235/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0135 - mae: 0.0446 - val_loss: 0.2354 - val_mae: 0.3851\n","\n","Epoch 00235: val_loss did not improve from 0.18088\n","Epoch 236/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0144 - mae: 0.0531 - val_loss: 0.2431 - val_mae: 0.3996\n","\n","Epoch 00236: val_loss did not improve from 0.18088\n","Epoch 237/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0138 - mae: 0.0528 - val_loss: 0.2666 - val_mae: 0.4182\n","\n","Epoch 00237: val_loss did not improve from 0.18088\n","Epoch 238/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0128 - mae: 0.0462 - val_loss: 0.2518 - val_mae: 0.4022\n","\n","Epoch 00238: val_loss did not improve from 0.18088\n","Epoch 239/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0121 - mae: 0.0422 - val_loss: 0.2532 - val_mae: 0.4053\n","\n","Epoch 00239: val_loss did not improve from 0.18088\n","Epoch 240/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0124 - mae: 0.0421 - val_loss: 0.2546 - val_mae: 0.4057\n","\n","Epoch 00240: val_loss did not improve from 0.18088\n","Epoch 241/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0125 - mae: 0.0428 - val_loss: 0.2397 - val_mae: 0.3942\n","\n","Epoch 00241: val_loss did not improve from 0.18088\n","Epoch 242/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0121 - mae: 0.0432 - val_loss: 0.2460 - val_mae: 0.3974\n","\n","Epoch 00242: val_loss did not improve from 0.18088\n","Epoch 243/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0120 - mae: 0.0413 - val_loss: 0.2584 - val_mae: 0.4142\n","\n","Epoch 00243: val_loss did not improve from 0.18088\n","Epoch 244/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0121 - mae: 0.0455 - val_loss: 0.2518 - val_mae: 0.4045\n","\n","Epoch 00244: val_loss did not improve from 0.18088\n","Epoch 245/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0117 - mae: 0.0388 - val_loss: 0.2569 - val_mae: 0.4110\n","\n","Epoch 00245: val_loss did not improve from 0.18088\n","Epoch 246/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0117 - mae: 0.0408 - val_loss: 0.2614 - val_mae: 0.4158\n","\n","Epoch 00246: val_loss did not improve from 0.18088\n","Epoch 247/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0120 - mae: 0.0413 - val_loss: 0.2556 - val_mae: 0.4088\n","\n","Epoch 00247: val_loss did not improve from 0.18088\n","Epoch 248/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0116 - mae: 0.0386 - val_loss: 0.2552 - val_mae: 0.4125\n","\n","Epoch 00248: val_loss did not improve from 0.18088\n","Epoch 249/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0123 - mae: 0.0438 - val_loss: 0.2568 - val_mae: 0.4104\n","\n","Epoch 00249: val_loss did not improve from 0.18088\n","Epoch 250/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0114 - mae: 0.0408 - val_loss: 0.2631 - val_mae: 0.4158\n","\n","Epoch 00250: val_loss did not improve from 0.18088\n","Epoch 251/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0125 - mae: 0.0451 - val_loss: 0.2560 - val_mae: 0.4082\n","\n","Epoch 00251: val_loss did not improve from 0.18088\n","Epoch 252/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0113 - mae: 0.0387 - val_loss: 0.2511 - val_mae: 0.4041\n","\n","Epoch 00252: val_loss did not improve from 0.18088\n","Epoch 253/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0118 - mae: 0.0414 - val_loss: 0.2540 - val_mae: 0.4026\n","\n","Epoch 00253: val_loss did not improve from 0.18088\n","Epoch 254/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0116 - mae: 0.0414 - val_loss: 0.2500 - val_mae: 0.4024\n","\n","Epoch 00254: val_loss did not improve from 0.18088\n","Epoch 255/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0113 - mae: 0.0399 - val_loss: 0.2507 - val_mae: 0.3993\n","\n","Epoch 00255: val_loss did not improve from 0.18088\n","Epoch 256/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0113 - mae: 0.0409 - val_loss: 0.2569 - val_mae: 0.4083\n","\n","Epoch 00256: val_loss did not improve from 0.18088\n","Epoch 257/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0111 - mae: 0.0381 - val_loss: 0.2517 - val_mae: 0.4005\n","\n","Epoch 00257: val_loss did not improve from 0.18088\n","Epoch 258/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0119 - mae: 0.0444 - val_loss: 0.2542 - val_mae: 0.4109\n","\n","Epoch 00258: val_loss did not improve from 0.18088\n","Epoch 259/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0116 - mae: 0.0425 - val_loss: 0.2560 - val_mae: 0.4104\n","\n","Epoch 00259: val_loss did not improve from 0.18088\n","Epoch 260/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0119 - mae: 0.0453 - val_loss: 0.2404 - val_mae: 0.3975\n","\n","Epoch 00260: val_loss did not improve from 0.18088\n","Epoch 261/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0118 - mae: 0.0427 - val_loss: 0.2454 - val_mae: 0.3993\n","\n","Epoch 00261: val_loss did not improve from 0.18088\n","Epoch 262/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0120 - mae: 0.0441 - val_loss: 0.2470 - val_mae: 0.3989\n","\n","Epoch 00262: val_loss did not improve from 0.18088\n","Epoch 263/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0114 - mae: 0.0420 - val_loss: 0.2610 - val_mae: 0.4109\n","\n","Epoch 00263: val_loss did not improve from 0.18088\n","Epoch 264/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0114 - mae: 0.0416 - val_loss: 0.2492 - val_mae: 0.4022\n","\n","Epoch 00264: val_loss did not improve from 0.18088\n","Epoch 265/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0113 - mae: 0.0431 - val_loss: 0.2484 - val_mae: 0.3960\n","\n","Epoch 00265: val_loss did not improve from 0.18088\n","Epoch 266/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0116 - mae: 0.0458 - val_loss: 0.2603 - val_mae: 0.4150\n","\n","Epoch 00266: val_loss did not improve from 0.18088\n","Epoch 267/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0120 - mae: 0.0484 - val_loss: 0.2467 - val_mae: 0.3934\n","\n","Epoch 00267: val_loss did not improve from 0.18088\n","Epoch 268/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0128 - mae: 0.0517 - val_loss: 0.2540 - val_mae: 0.4100\n","\n","Epoch 00268: val_loss did not improve from 0.18088\n","Epoch 269/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0125 - mae: 0.0528 - val_loss: 0.2571 - val_mae: 0.4061\n","\n","Epoch 00269: val_loss did not improve from 0.18088\n","Epoch 270/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0117 - mae: 0.0459 - val_loss: 0.2466 - val_mae: 0.3980\n","\n","Epoch 00270: val_loss did not improve from 0.18088\n","Epoch 271/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0115 - mae: 0.0423 - val_loss: 0.2632 - val_mae: 0.4172\n","\n","Epoch 00271: val_loss did not improve from 0.18088\n","Epoch 272/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0116 - mae: 0.0429 - val_loss: 0.2527 - val_mae: 0.4031\n","\n","Epoch 00272: val_loss did not improve from 0.18088\n","Epoch 273/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0111 - mae: 0.0416 - val_loss: 0.2527 - val_mae: 0.4045\n","\n","Epoch 00273: val_loss did not improve from 0.18088\n","Epoch 274/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0108 - mae: 0.0391 - val_loss: 0.2671 - val_mae: 0.4153\n","\n","Epoch 00274: val_loss did not improve from 0.18088\n","Epoch 275/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0114 - mae: 0.0417 - val_loss: 0.2471 - val_mae: 0.3965\n","\n","Epoch 00275: val_loss did not improve from 0.18088\n","Epoch 276/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0117 - mae: 0.0438 - val_loss: 0.2545 - val_mae: 0.4062\n","\n","Epoch 00276: val_loss did not improve from 0.18088\n","Epoch 277/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0108 - mae: 0.0408 - val_loss: 0.2613 - val_mae: 0.4154\n","\n","Epoch 00277: val_loss did not improve from 0.18088\n","Epoch 278/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0110 - mae: 0.0412 - val_loss: 0.2428 - val_mae: 0.3983\n","\n","Epoch 00278: val_loss did not improve from 0.18088\n","Epoch 279/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0113 - mae: 0.0432 - val_loss: 0.2575 - val_mae: 0.4109\n","\n","Epoch 00279: val_loss did not improve from 0.18088\n","Epoch 280/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0109 - mae: 0.0411 - val_loss: 0.2585 - val_mae: 0.4097\n","\n","Epoch 00280: val_loss did not improve from 0.18088\n","Epoch 281/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0107 - mae: 0.0401 - val_loss: 0.2562 - val_mae: 0.4046\n","\n","Epoch 00281: val_loss did not improve from 0.18088\n","Epoch 282/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0111 - mae: 0.0426 - val_loss: 0.2520 - val_mae: 0.3978\n","\n","Epoch 00282: val_loss did not improve from 0.18088\n","Epoch 283/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0111 - mae: 0.0439 - val_loss: 0.2479 - val_mae: 0.3986\n","\n","Epoch 00283: val_loss did not improve from 0.18088\n","Epoch 284/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0113 - mae: 0.0442 - val_loss: 0.2630 - val_mae: 0.4153\n","\n","Epoch 00284: val_loss did not improve from 0.18088\n","Epoch 285/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0116 - mae: 0.0457 - val_loss: 0.2483 - val_mae: 0.3997\n","\n","Epoch 00285: val_loss did not improve from 0.18088\n","Epoch 286/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0110 - mae: 0.0440 - val_loss: 0.2446 - val_mae: 0.3931\n","\n","Epoch 00286: val_loss did not improve from 0.18088\n","Epoch 287/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0111 - mae: 0.0449 - val_loss: 0.2690 - val_mae: 0.4190\n","\n","Epoch 00287: val_loss did not improve from 0.18088\n","Epoch 288/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0107 - mae: 0.0428 - val_loss: 0.2464 - val_mae: 0.3942\n","\n","Epoch 00288: val_loss did not improve from 0.18088\n","Epoch 289/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0116 - mae: 0.0442 - val_loss: 0.2425 - val_mae: 0.3911\n","\n","Epoch 00289: val_loss did not improve from 0.18088\n","Epoch 290/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0107 - mae: 0.0416 - val_loss: 0.2676 - val_mae: 0.4190\n","\n","Epoch 00290: val_loss did not improve from 0.18088\n","Epoch 291/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0111 - mae: 0.0424 - val_loss: 0.2442 - val_mae: 0.3969\n","\n","Epoch 00291: val_loss did not improve from 0.18088\n","Epoch 292/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0106 - mae: 0.0425 - val_loss: 0.2350 - val_mae: 0.3917\n","\n","Epoch 00292: val_loss did not improve from 0.18088\n","Epoch 293/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0103 - mae: 0.0392 - val_loss: 0.2547 - val_mae: 0.4062\n","\n","Epoch 00293: val_loss did not improve from 0.18088\n","Epoch 294/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0108 - mae: 0.0429 - val_loss: 0.2385 - val_mae: 0.3915\n","\n","Epoch 00294: val_loss did not improve from 0.18088\n","Epoch 295/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0102 - mae: 0.0389 - val_loss: 0.2367 - val_mae: 0.3864\n","\n","Epoch 00295: val_loss did not improve from 0.18088\n","Epoch 296/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0104 - mae: 0.0381 - val_loss: 0.2650 - val_mae: 0.4177\n","\n","Epoch 00296: val_loss did not improve from 0.18088\n","Epoch 297/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0104 - mae: 0.0400 - val_loss: 0.2503 - val_mae: 0.4018\n","\n","Epoch 00297: val_loss did not improve from 0.18088\n","Epoch 298/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0104 - mae: 0.0406 - val_loss: 0.2429 - val_mae: 0.3932\n","\n","Epoch 00298: val_loss did not improve from 0.18088\n","Epoch 299/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0100 - mae: 0.0385 - val_loss: 0.2561 - val_mae: 0.4094\n","\n","Epoch 00299: val_loss did not improve from 0.18088\n","Epoch 300/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0101 - mae: 0.0400 - val_loss: 0.2539 - val_mae: 0.4035\n","\n","Epoch 00300: val_loss did not improve from 0.18088\n","Epoch 301/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0105 - mae: 0.0421 - val_loss: 0.2482 - val_mae: 0.3981\n","\n","Epoch 00301: val_loss did not improve from 0.18088\n","Epoch 302/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0099 - mae: 0.0388 - val_loss: 0.2530 - val_mae: 0.4004\n","\n","Epoch 00302: val_loss did not improve from 0.18088\n","Epoch 303/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0105 - mae: 0.0409 - val_loss: 0.2497 - val_mae: 0.3987\n","\n","Epoch 00303: val_loss did not improve from 0.18088\n","Epoch 304/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0097 - mae: 0.0353 - val_loss: 0.2572 - val_mae: 0.4078\n","\n","Epoch 00304: val_loss did not improve from 0.18088\n","Epoch 305/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0097 - mae: 0.0387 - val_loss: 0.2574 - val_mae: 0.4050\n","\n","Epoch 00305: val_loss did not improve from 0.18088\n","Epoch 306/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0098 - mae: 0.0390 - val_loss: 0.2540 - val_mae: 0.4080\n","\n","Epoch 00306: val_loss did not improve from 0.18088\n","Epoch 307/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0100 - mae: 0.0383 - val_loss: 0.2553 - val_mae: 0.4079\n","\n","Epoch 00307: val_loss did not improve from 0.18088\n","Epoch 308/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0096 - mae: 0.0360 - val_loss: 0.2461 - val_mae: 0.4012\n","\n","Epoch 00308: val_loss did not improve from 0.18088\n","Epoch 309/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0097 - mae: 0.0380 - val_loss: 0.2567 - val_mae: 0.4111\n","\n","Epoch 00309: val_loss did not improve from 0.18088\n","Epoch 310/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0094 - mae: 0.0347 - val_loss: 0.2495 - val_mae: 0.3993\n","\n","Epoch 00310: val_loss did not improve from 0.18088\n","Epoch 311/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0098 - mae: 0.0386 - val_loss: 0.2422 - val_mae: 0.3958\n","\n","Epoch 00311: val_loss did not improve from 0.18088\n","Epoch 312/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0103 - mae: 0.0410 - val_loss: 0.2526 - val_mae: 0.4040\n","\n","Epoch 00312: val_loss did not improve from 0.18088\n","Epoch 313/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0106 - mae: 0.0407 - val_loss: 0.2641 - val_mae: 0.4166\n","\n","Epoch 00313: val_loss did not improve from 0.18088\n","Epoch 314/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0100 - mae: 0.0407 - val_loss: 0.2597 - val_mae: 0.4061\n","\n","Epoch 00314: val_loss did not improve from 0.18088\n","Epoch 315/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0108 - mae: 0.0427 - val_loss: 0.2373 - val_mae: 0.3896\n","\n","Epoch 00315: val_loss did not improve from 0.18088\n","Epoch 316/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0104 - mae: 0.0442 - val_loss: 0.2519 - val_mae: 0.4030\n","\n","Epoch 00316: val_loss did not improve from 0.18088\n","Epoch 317/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0096 - mae: 0.0380 - val_loss: 0.2561 - val_mae: 0.4113\n","\n","Epoch 00317: val_loss did not improve from 0.18088\n","Epoch 318/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0096 - mae: 0.0394 - val_loss: 0.2434 - val_mae: 0.3903\n","\n","Epoch 00318: val_loss did not improve from 0.18088\n","Epoch 319/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0098 - mae: 0.0406 - val_loss: 0.2516 - val_mae: 0.4042\n","\n","Epoch 00319: val_loss did not improve from 0.18088\n","Epoch 320/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0095 - mae: 0.0397 - val_loss: 0.2476 - val_mae: 0.3989\n","\n","Epoch 00320: val_loss did not improve from 0.18088\n","Epoch 321/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0099 - mae: 0.0403 - val_loss: 0.2484 - val_mae: 0.4034\n","\n","Epoch 00321: val_loss did not improve from 0.18088\n","Epoch 322/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0098 - mae: 0.0425 - val_loss: 0.2555 - val_mae: 0.4068\n","\n","Epoch 00322: val_loss did not improve from 0.18088\n","Epoch 323/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0100 - mae: 0.0436 - val_loss: 0.2465 - val_mae: 0.4005\n","\n","Epoch 00323: val_loss did not improve from 0.18088\n","Epoch 324/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0108 - mae: 0.0478 - val_loss: 0.2428 - val_mae: 0.3901\n","\n","Epoch 00324: val_loss did not improve from 0.18088\n","Epoch 325/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0105 - mae: 0.0463 - val_loss: 0.2729 - val_mae: 0.4241\n","\n","Epoch 00325: val_loss did not improve from 0.18088\n","Epoch 326/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0104 - mae: 0.0495 - val_loss: 0.2615 - val_mae: 0.4083\n","\n","Epoch 00326: val_loss did not improve from 0.18088\n","Epoch 327/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0100 - mae: 0.0452 - val_loss: 0.2549 - val_mae: 0.4016\n","\n","Epoch 00327: val_loss did not improve from 0.18088\n","Epoch 328/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0093 - mae: 0.0377 - val_loss: 0.2601 - val_mae: 0.4107\n","\n","Epoch 00328: val_loss did not improve from 0.18088\n","Epoch 329/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0094 - mae: 0.0409 - val_loss: 0.2454 - val_mae: 0.3946\n","\n","Epoch 00329: val_loss did not improve from 0.18088\n","Epoch 330/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0094 - mae: 0.0402 - val_loss: 0.2426 - val_mae: 0.3948\n","\n","Epoch 00330: val_loss did not improve from 0.18088\n","Epoch 331/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0098 - mae: 0.0416 - val_loss: 0.2580 - val_mae: 0.4046\n","\n","Epoch 00331: val_loss did not improve from 0.18088\n","Epoch 332/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0096 - mae: 0.0399 - val_loss: 0.2568 - val_mae: 0.4068\n","\n","Epoch 00332: val_loss did not improve from 0.18088\n","Epoch 333/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0087 - mae: 0.0343 - val_loss: 0.2547 - val_mae: 0.4037\n","\n","Epoch 00333: val_loss did not improve from 0.18088\n","Epoch 334/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0096 - mae: 0.0397 - val_loss: 0.2532 - val_mae: 0.4043\n","\n","Epoch 00334: val_loss did not improve from 0.18088\n","Epoch 335/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0089 - mae: 0.0370 - val_loss: 0.2517 - val_mae: 0.3984\n","\n","Epoch 00335: val_loss did not improve from 0.18088\n","Epoch 336/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0088 - mae: 0.0347 - val_loss: 0.2579 - val_mae: 0.4050\n","\n","Epoch 00336: val_loss did not improve from 0.18088\n","Epoch 337/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0091 - mae: 0.0376 - val_loss: 0.2581 - val_mae: 0.4053\n","\n","Epoch 00337: val_loss did not improve from 0.18088\n","Epoch 338/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0089 - mae: 0.0384 - val_loss: 0.2584 - val_mae: 0.4068\n","\n","Epoch 00338: val_loss did not improve from 0.18088\n","Epoch 339/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0093 - mae: 0.0391 - val_loss: 0.2697 - val_mae: 0.4196\n","\n","Epoch 00339: val_loss did not improve from 0.18088\n","Epoch 340/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0098 - mae: 0.0419 - val_loss: 0.2515 - val_mae: 0.3983\n","\n","Epoch 00340: val_loss did not improve from 0.18088\n","Epoch 341/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0088 - mae: 0.0381 - val_loss: 0.2466 - val_mae: 0.3999\n","\n","Epoch 00341: val_loss did not improve from 0.18088\n","Epoch 342/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0089 - mae: 0.0383 - val_loss: 0.2556 - val_mae: 0.4066\n","\n","Epoch 00342: val_loss did not improve from 0.18088\n","Epoch 343/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0097 - mae: 0.0410 - val_loss: 0.2420 - val_mae: 0.3936\n","\n","Epoch 00343: val_loss did not improve from 0.18088\n","Epoch 344/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0091 - mae: 0.0384 - val_loss: 0.2481 - val_mae: 0.4016\n","\n","Epoch 00344: val_loss did not improve from 0.18088\n","Epoch 345/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0090 - mae: 0.0388 - val_loss: 0.2499 - val_mae: 0.3986\n","\n","Epoch 00345: val_loss did not improve from 0.18088\n","Epoch 346/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0086 - mae: 0.0358 - val_loss: 0.2645 - val_mae: 0.4150\n","\n","Epoch 00346: val_loss did not improve from 0.18088\n","Epoch 347/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0089 - mae: 0.0392 - val_loss: 0.2592 - val_mae: 0.4077\n","\n","Epoch 00347: val_loss did not improve from 0.18088\n","Epoch 348/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0086 - mae: 0.0366 - val_loss: 0.2521 - val_mae: 0.4003\n","\n","Epoch 00348: val_loss did not improve from 0.18088\n","Epoch 349/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0087 - mae: 0.0364 - val_loss: 0.2674 - val_mae: 0.4150\n","\n","Epoch 00349: val_loss did not improve from 0.18088\n","Epoch 350/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0089 - mae: 0.0390 - val_loss: 0.2587 - val_mae: 0.4130\n","\n","Epoch 00350: val_loss did not improve from 0.18088\n","Epoch 351/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0090 - mae: 0.0403 - val_loss: 0.2410 - val_mae: 0.3892\n","\n","Epoch 00351: val_loss did not improve from 0.18088\n","Epoch 352/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0095 - mae: 0.0419 - val_loss: 0.2506 - val_mae: 0.4043\n","\n","Epoch 00352: val_loss did not improve from 0.18088\n","Epoch 353/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0086 - mae: 0.0373 - val_loss: 0.2640 - val_mae: 0.4156\n","\n","Epoch 00353: val_loss did not improve from 0.18088\n","Epoch 354/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0083 - mae: 0.0349 - val_loss: 0.2490 - val_mae: 0.4018\n","\n","Epoch 00354: val_loss did not improve from 0.18088\n","Epoch 355/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0084 - mae: 0.0344 - val_loss: 0.2515 - val_mae: 0.4048\n","\n","Epoch 00355: val_loss did not improve from 0.18088\n","Epoch 356/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0086 - mae: 0.0372 - val_loss: 0.2569 - val_mae: 0.4089\n","\n","Epoch 00356: val_loss did not improve from 0.18088\n","Epoch 357/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0081 - mae: 0.0347 - val_loss: 0.2519 - val_mae: 0.4049\n","\n","Epoch 00357: val_loss did not improve from 0.18088\n","Epoch 358/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0085 - mae: 0.0358 - val_loss: 0.2609 - val_mae: 0.4150\n","\n","Epoch 00358: val_loss did not improve from 0.18088\n","Epoch 359/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0089 - mae: 0.0371 - val_loss: 0.2545 - val_mae: 0.4075\n","\n","Epoch 00359: val_loss did not improve from 0.18088\n","Epoch 360/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0083 - mae: 0.0353 - val_loss: 0.2547 - val_mae: 0.4068\n","\n","Epoch 00360: val_loss did not improve from 0.18088\n","Epoch 361/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0089 - mae: 0.0389 - val_loss: 0.2474 - val_mae: 0.4028\n","\n","Epoch 00361: val_loss did not improve from 0.18088\n","Epoch 362/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0088 - mae: 0.0396 - val_loss: 0.2414 - val_mae: 0.3882\n","\n","Epoch 00362: val_loss did not improve from 0.18088\n","Epoch 363/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0091 - mae: 0.0419 - val_loss: 0.2513 - val_mae: 0.4055\n","\n","Epoch 00363: val_loss did not improve from 0.18088\n","Epoch 364/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0087 - mae: 0.0410 - val_loss: 0.2438 - val_mae: 0.3946\n","\n","Epoch 00364: val_loss did not improve from 0.18088\n","Epoch 365/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0090 - mae: 0.0401 - val_loss: 0.2467 - val_mae: 0.3977\n","\n","Epoch 00365: val_loss did not improve from 0.18088\n","Epoch 366/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0090 - mae: 0.0417 - val_loss: 0.2557 - val_mae: 0.4022\n","\n","Epoch 00366: val_loss did not improve from 0.18088\n","Epoch 367/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0090 - mae: 0.0416 - val_loss: 0.2483 - val_mae: 0.3999\n","\n","Epoch 00367: val_loss did not improve from 0.18088\n","Epoch 368/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0085 - mae: 0.0385 - val_loss: 0.2546 - val_mae: 0.4042\n","\n","Epoch 00368: val_loss did not improve from 0.18088\n","Epoch 369/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0083 - mae: 0.0371 - val_loss: 0.2494 - val_mae: 0.3940\n","\n","Epoch 00369: val_loss did not improve from 0.18088\n","Epoch 370/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0084 - mae: 0.0385 - val_loss: 0.2528 - val_mae: 0.4009\n","\n","Epoch 00370: val_loss did not improve from 0.18088\n","Epoch 371/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0092 - mae: 0.0395 - val_loss: 0.2574 - val_mae: 0.4007\n","\n","Epoch 00371: val_loss did not improve from 0.18088\n","Epoch 372/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0081 - mae: 0.0352 - val_loss: 0.2505 - val_mae: 0.3968\n","\n","Epoch 00372: val_loss did not improve from 0.18088\n","Epoch 373/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0090 - mae: 0.0417 - val_loss: 0.2709 - val_mae: 0.4166\n","\n","Epoch 00373: val_loss did not improve from 0.18088\n","Epoch 374/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0082 - mae: 0.0387 - val_loss: 0.2586 - val_mae: 0.4042\n","\n","Epoch 00374: val_loss did not improve from 0.18088\n","Epoch 375/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0084 - mae: 0.0371 - val_loss: 0.2496 - val_mae: 0.3979\n","\n","Epoch 00375: val_loss did not improve from 0.18088\n","Epoch 376/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0080 - mae: 0.0358 - val_loss: 0.2582 - val_mae: 0.4097\n","\n","Epoch 00376: val_loss did not improve from 0.18088\n","Epoch 377/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0083 - mae: 0.0384 - val_loss: 0.2501 - val_mae: 0.3994\n","\n","Epoch 00377: val_loss did not improve from 0.18088\n","Epoch 378/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0078 - mae: 0.0342 - val_loss: 0.2491 - val_mae: 0.4013\n","\n","Epoch 00378: val_loss did not improve from 0.18088\n","Epoch 379/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0078 - mae: 0.0350 - val_loss: 0.2500 - val_mae: 0.3970\n","\n","Epoch 00379: val_loss did not improve from 0.18088\n","Epoch 380/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0082 - mae: 0.0384 - val_loss: 0.2466 - val_mae: 0.3978\n","\n","Epoch 00380: val_loss did not improve from 0.18088\n","Epoch 381/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0080 - mae: 0.0378 - val_loss: 0.2515 - val_mae: 0.3988\n","\n","Epoch 00381: val_loss did not improve from 0.18088\n","Epoch 382/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0081 - mae: 0.0392 - val_loss: 0.2473 - val_mae: 0.3992\n","\n","Epoch 00382: val_loss did not improve from 0.18088\n","Epoch 383/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0084 - mae: 0.0384 - val_loss: 0.2543 - val_mae: 0.4057\n","\n","Epoch 00383: val_loss did not improve from 0.18088\n","Epoch 384/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0082 - mae: 0.0374 - val_loss: 0.2546 - val_mae: 0.4015\n","\n","Epoch 00384: val_loss did not improve from 0.18088\n","Epoch 385/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0081 - mae: 0.0371 - val_loss: 0.2506 - val_mae: 0.3979\n","\n","Epoch 00385: val_loss did not improve from 0.18088\n","Epoch 386/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0077 - mae: 0.0349 - val_loss: 0.2549 - val_mae: 0.4009\n","\n","Epoch 00386: val_loss did not improve from 0.18088\n","Epoch 387/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0081 - mae: 0.0374 - val_loss: 0.2531 - val_mae: 0.3982\n","\n","Epoch 00387: val_loss did not improve from 0.18088\n","Epoch 388/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0078 - mae: 0.0359 - val_loss: 0.2516 - val_mae: 0.3965\n","\n","Epoch 00388: val_loss did not improve from 0.18088\n","Epoch 389/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0077 - mae: 0.0357 - val_loss: 0.2615 - val_mae: 0.4076\n","\n","Epoch 00389: val_loss did not improve from 0.18088\n","Epoch 390/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0082 - mae: 0.0361 - val_loss: 0.2526 - val_mae: 0.4022\n","\n","Epoch 00390: val_loss did not improve from 0.18088\n","Epoch 391/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0087 - mae: 0.0421 - val_loss: 0.2570 - val_mae: 0.3977\n","\n","Epoch 00391: val_loss did not improve from 0.18088\n","Epoch 392/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0079 - mae: 0.0396 - val_loss: 0.2544 - val_mae: 0.4021\n","\n","Epoch 00392: val_loss did not improve from 0.18088\n","Epoch 393/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0088 - mae: 0.0434 - val_loss: 0.2599 - val_mae: 0.4047\n","\n","Epoch 00393: val_loss did not improve from 0.18088\n","Epoch 394/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0078 - mae: 0.0372 - val_loss: 0.2503 - val_mae: 0.3994\n","\n","Epoch 00394: val_loss did not improve from 0.18088\n","Epoch 395/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0083 - mae: 0.0370 - val_loss: 0.2580 - val_mae: 0.4086\n","\n","Epoch 00395: val_loss did not improve from 0.18088\n","Epoch 396/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0083 - mae: 0.0395 - val_loss: 0.2542 - val_mae: 0.4069\n","\n","Epoch 00396: val_loss did not improve from 0.18088\n","Epoch 397/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0078 - mae: 0.0376 - val_loss: 0.2582 - val_mae: 0.4115\n","\n","Epoch 00397: val_loss did not improve from 0.18088\n","Epoch 398/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0078 - mae: 0.0365 - val_loss: 0.2547 - val_mae: 0.4065\n","\n","Epoch 00398: val_loss did not improve from 0.18088\n","Epoch 399/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0082 - mae: 0.0376 - val_loss: 0.2543 - val_mae: 0.4049\n","\n","Epoch 00399: val_loss did not improve from 0.18088\n","Epoch 400/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0076 - mae: 0.0360 - val_loss: 0.2443 - val_mae: 0.3962\n","\n","Epoch 00400: val_loss did not improve from 0.18088\n","Epoch 401/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0079 - mae: 0.0373 - val_loss: 0.2538 - val_mae: 0.4065\n","\n","Epoch 00401: val_loss did not improve from 0.18088\n","Epoch 402/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0085 - mae: 0.0415 - val_loss: 0.2666 - val_mae: 0.4179\n","\n","Epoch 00402: val_loss did not improve from 0.18088\n","Epoch 403/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0076 - mae: 0.0364 - val_loss: 0.2564 - val_mae: 0.4044\n","\n","Epoch 00403: val_loss did not improve from 0.18088\n","Epoch 404/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0079 - mae: 0.0375 - val_loss: 0.2666 - val_mae: 0.4157\n","\n","Epoch 00404: val_loss did not improve from 0.18088\n","Epoch 405/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0081 - mae: 0.0395 - val_loss: 0.2540 - val_mae: 0.3987\n","\n","Epoch 00405: val_loss did not improve from 0.18088\n","Epoch 406/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0076 - mae: 0.0373 - val_loss: 0.2518 - val_mae: 0.3994\n","\n","Epoch 00406: val_loss did not improve from 0.18088\n","Epoch 407/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0081 - mae: 0.0390 - val_loss: 0.2532 - val_mae: 0.4021\n","\n","Epoch 00407: val_loss did not improve from 0.18088\n","Epoch 408/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0075 - mae: 0.0373 - val_loss: 0.2515 - val_mae: 0.4066\n","\n","Epoch 00408: val_loss did not improve from 0.18088\n","Epoch 409/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0081 - mae: 0.0430 - val_loss: 0.2475 - val_mae: 0.3957\n","\n","Epoch 00409: val_loss did not improve from 0.18088\n","Epoch 410/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0079 - mae: 0.0401 - val_loss: 0.2530 - val_mae: 0.4045\n","\n","Epoch 00410: val_loss did not improve from 0.18088\n","Epoch 411/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0072 - mae: 0.0334 - val_loss: 0.2573 - val_mae: 0.4054\n","\n","Epoch 00411: val_loss did not improve from 0.18088\n","Epoch 412/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0083 - mae: 0.0407 - val_loss: 0.2542 - val_mae: 0.4079\n","\n","Epoch 00412: val_loss did not improve from 0.18088\n","Epoch 413/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0082 - mae: 0.0395 - val_loss: 0.2655 - val_mae: 0.4148\n","\n","Epoch 00413: val_loss did not improve from 0.18088\n","Epoch 414/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0076 - mae: 0.0374 - val_loss: 0.2565 - val_mae: 0.4046\n","\n","Epoch 00414: val_loss did not improve from 0.18088\n","Epoch 415/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0080 - mae: 0.0401 - val_loss: 0.2503 - val_mae: 0.3990\n","\n","Epoch 00415: val_loss did not improve from 0.18088\n","Epoch 416/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0075 - mae: 0.0367 - val_loss: 0.2535 - val_mae: 0.4044\n","\n","Epoch 00416: val_loss did not improve from 0.18088\n","Epoch 417/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0074 - mae: 0.0379 - val_loss: 0.2455 - val_mae: 0.3896\n","\n","Epoch 00417: val_loss did not improve from 0.18088\n","Epoch 418/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0077 - mae: 0.0390 - val_loss: 0.2574 - val_mae: 0.3996\n","\n","Epoch 00418: val_loss did not improve from 0.18088\n","Epoch 419/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0074 - mae: 0.0371 - val_loss: 0.2569 - val_mae: 0.4004\n","\n","Epoch 00419: val_loss did not improve from 0.18088\n","Epoch 420/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0073 - mae: 0.0373 - val_loss: 0.2535 - val_mae: 0.3929\n","\n","Epoch 00420: val_loss did not improve from 0.18088\n","Epoch 421/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0081 - mae: 0.0420 - val_loss: 0.2542 - val_mae: 0.4003\n","\n","Epoch 00421: val_loss did not improve from 0.18088\n","Epoch 422/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0079 - mae: 0.0391 - val_loss: 0.2461 - val_mae: 0.3944\n","\n","Epoch 00422: val_loss did not improve from 0.18088\n","Epoch 423/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0079 - mae: 0.0393 - val_loss: 0.2583 - val_mae: 0.4117\n","\n","Epoch 00423: val_loss did not improve from 0.18088\n","Epoch 424/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0080 - mae: 0.0417 - val_loss: 0.2629 - val_mae: 0.4107\n","\n","Epoch 00424: val_loss did not improve from 0.18088\n","Epoch 425/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0079 - mae: 0.0403 - val_loss: 0.2440 - val_mae: 0.3931\n","\n","Epoch 00425: val_loss did not improve from 0.18088\n","Epoch 426/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0083 - mae: 0.0434 - val_loss: 0.2587 - val_mae: 0.4076\n","\n","Epoch 00426: val_loss did not improve from 0.18088\n","Epoch 427/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0080 - mae: 0.0404 - val_loss: 0.2592 - val_mae: 0.4081\n","\n","Epoch 00427: val_loss did not improve from 0.18088\n","Epoch 428/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0080 - mae: 0.0416 - val_loss: 0.2399 - val_mae: 0.3825\n","\n","Epoch 00428: val_loss did not improve from 0.18088\n","Epoch 429/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0085 - mae: 0.0457 - val_loss: 0.2552 - val_mae: 0.4075\n","\n","Epoch 00429: val_loss did not improve from 0.18088\n","Epoch 430/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0082 - mae: 0.0462 - val_loss: 0.2700 - val_mae: 0.4158\n","\n","Epoch 00430: val_loss did not improve from 0.18088\n","Epoch 431/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0086 - mae: 0.0444 - val_loss: 0.2486 - val_mae: 0.3993\n","\n","Epoch 00431: val_loss did not improve from 0.18088\n","Epoch 432/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0082 - mae: 0.0433 - val_loss: 0.2664 - val_mae: 0.4098\n","\n","Epoch 00432: val_loss did not improve from 0.18088\n","Epoch 433/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0083 - mae: 0.0473 - val_loss: 0.2735 - val_mae: 0.4240\n","\n","Epoch 00433: val_loss did not improve from 0.18088\n","Epoch 434/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0082 - mae: 0.0462 - val_loss: 0.2493 - val_mae: 0.3957\n","\n","Epoch 00434: val_loss did not improve from 0.18088\n","Epoch 435/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0086 - mae: 0.0462 - val_loss: 0.2551 - val_mae: 0.4036\n","\n","Epoch 00435: val_loss did not improve from 0.18088\n","Epoch 436/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0076 - mae: 0.0394 - val_loss: 0.2683 - val_mae: 0.4113\n","\n","Epoch 00436: val_loss did not improve from 0.18088\n","Epoch 437/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0075 - mae: 0.0391 - val_loss: 0.2529 - val_mae: 0.3975\n","\n","Epoch 00437: val_loss did not improve from 0.18088\n","Epoch 438/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0069 - mae: 0.0360 - val_loss: 0.2477 - val_mae: 0.3950\n","\n","Epoch 00438: val_loss did not improve from 0.18088\n","Epoch 439/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0073 - mae: 0.0376 - val_loss: 0.2596 - val_mae: 0.4071\n","\n","Epoch 00439: val_loss did not improve from 0.18088\n","Epoch 440/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0076 - mae: 0.0399 - val_loss: 0.2590 - val_mae: 0.4032\n","\n","Epoch 00440: val_loss did not improve from 0.18088\n","Epoch 441/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0071 - mae: 0.0372 - val_loss: 0.2562 - val_mae: 0.4031\n","\n","Epoch 00441: val_loss did not improve from 0.18088\n","Epoch 442/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0072 - mae: 0.0375 - val_loss: 0.2684 - val_mae: 0.4141\n","\n","Epoch 00442: val_loss did not improve from 0.18088\n","Epoch 443/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0068 - mae: 0.0342 - val_loss: 0.2590 - val_mae: 0.4061\n","\n","Epoch 00443: val_loss did not improve from 0.18088\n","Epoch 444/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0074 - mae: 0.0389 - val_loss: 0.2637 - val_mae: 0.4108\n","\n","Epoch 00444: val_loss did not improve from 0.18088\n","Epoch 445/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0070 - mae: 0.0365 - val_loss: 0.2593 - val_mae: 0.4018\n","\n","Epoch 00445: val_loss did not improve from 0.18088\n","Epoch 446/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0070 - mae: 0.0369 - val_loss: 0.2503 - val_mae: 0.3966\n","\n","Epoch 00446: val_loss did not improve from 0.18088\n","Epoch 447/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0072 - mae: 0.0378 - val_loss: 0.2692 - val_mae: 0.4132\n","\n","Epoch 00447: val_loss did not improve from 0.18088\n","Epoch 448/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0075 - mae: 0.0411 - val_loss: 0.2580 - val_mae: 0.4048\n","\n","Epoch 00448: val_loss did not improve from 0.18088\n","Epoch 449/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0067 - mae: 0.0350 - val_loss: 0.2408 - val_mae: 0.3920\n","\n","Epoch 00449: val_loss did not improve from 0.18088\n","Epoch 450/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0070 - mae: 0.0381 - val_loss: 0.2673 - val_mae: 0.4207\n","\n","Epoch 00450: val_loss did not improve from 0.18088\n","Epoch 451/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0074 - mae: 0.0394 - val_loss: 0.2591 - val_mae: 0.4093\n","\n","Epoch 00451: val_loss did not improve from 0.18088\n","Epoch 452/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0074 - mae: 0.0381 - val_loss: 0.2436 - val_mae: 0.3954\n","\n","Epoch 00452: val_loss did not improve from 0.18088\n","Epoch 453/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0074 - mae: 0.0396 - val_loss: 0.2738 - val_mae: 0.4202\n","\n","Epoch 00453: val_loss did not improve from 0.18088\n","Epoch 454/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0074 - mae: 0.0399 - val_loss: 0.2575 - val_mae: 0.4027\n","\n","Epoch 00454: val_loss did not improve from 0.18088\n","Epoch 455/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0070 - mae: 0.0376 - val_loss: 0.2466 - val_mae: 0.3943\n","\n","Epoch 00455: val_loss did not improve from 0.18088\n","Epoch 456/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0071 - mae: 0.0386 - val_loss: 0.2626 - val_mae: 0.4102\n","\n","Epoch 00456: val_loss did not improve from 0.18088\n","Epoch 457/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0068 - mae: 0.0381 - val_loss: 0.2572 - val_mae: 0.4040\n","\n","Epoch 00457: val_loss did not improve from 0.18088\n","Epoch 458/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0068 - mae: 0.0360 - val_loss: 0.2430 - val_mae: 0.3906\n","\n","Epoch 00458: val_loss did not improve from 0.18088\n","Epoch 459/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0073 - mae: 0.0390 - val_loss: 0.2497 - val_mae: 0.4028\n","\n","Epoch 00459: val_loss did not improve from 0.18088\n","Epoch 460/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0067 - mae: 0.0374 - val_loss: 0.2553 - val_mae: 0.4073\n","\n","Epoch 00460: val_loss did not improve from 0.18088\n","Epoch 461/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0064 - mae: 0.0351 - val_loss: 0.2497 - val_mae: 0.4008\n","\n","Epoch 00461: val_loss did not improve from 0.18088\n","Epoch 462/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0065 - mae: 0.0343 - val_loss: 0.2533 - val_mae: 0.4039\n","\n","Epoch 00462: val_loss did not improve from 0.18088\n","Epoch 463/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0071 - mae: 0.0373 - val_loss: 0.2581 - val_mae: 0.4114\n","\n","Epoch 00463: val_loss did not improve from 0.18088\n","Epoch 464/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0068 - mae: 0.0368 - val_loss: 0.2432 - val_mae: 0.3994\n","\n","Epoch 00464: val_loss did not improve from 0.18088\n","Epoch 465/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0068 - mae: 0.0366 - val_loss: 0.2561 - val_mae: 0.4092\n","\n","Epoch 00465: val_loss did not improve from 0.18088\n","Epoch 466/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0067 - mae: 0.0353 - val_loss: 0.2580 - val_mae: 0.4072\n","\n","Epoch 00466: val_loss did not improve from 0.18088\n","Epoch 467/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0070 - mae: 0.0387 - val_loss: 0.2404 - val_mae: 0.3915\n","\n","Epoch 00467: val_loss did not improve from 0.18088\n","Epoch 468/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0069 - mae: 0.0378 - val_loss: 0.2451 - val_mae: 0.3970\n","\n","Epoch 00468: val_loss did not improve from 0.18088\n","Epoch 469/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0068 - mae: 0.0375 - val_loss: 0.2479 - val_mae: 0.3975\n","\n","Epoch 00469: val_loss did not improve from 0.18088\n","Epoch 470/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0072 - mae: 0.0391 - val_loss: 0.2535 - val_mae: 0.4005\n","\n","Epoch 00470: val_loss did not improve from 0.18088\n","Epoch 471/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0065 - mae: 0.0352 - val_loss: 0.2591 - val_mae: 0.4046\n","\n","Epoch 00471: val_loss did not improve from 0.18088\n","Epoch 472/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0064 - mae: 0.0353 - val_loss: 0.2543 - val_mae: 0.4040\n","\n","Epoch 00472: val_loss did not improve from 0.18088\n","Epoch 473/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0065 - mae: 0.0368 - val_loss: 0.2519 - val_mae: 0.3967\n","\n","Epoch 00473: val_loss did not improve from 0.18088\n","Epoch 474/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0066 - mae: 0.0358 - val_loss: 0.2487 - val_mae: 0.3975\n","\n","Epoch 00474: val_loss did not improve from 0.18088\n","Epoch 475/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0069 - mae: 0.0402 - val_loss: 0.2588 - val_mae: 0.4036\n","\n","Epoch 00475: val_loss did not improve from 0.18088\n","Epoch 476/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0061 - mae: 0.0334 - val_loss: 0.2584 - val_mae: 0.4049\n","\n","Epoch 00476: val_loss did not improve from 0.18088\n","Epoch 477/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0065 - mae: 0.0346 - val_loss: 0.2470 - val_mae: 0.3950\n","\n","Epoch 00477: val_loss did not improve from 0.18088\n","Epoch 478/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0070 - mae: 0.0393 - val_loss: 0.2503 - val_mae: 0.3981\n","\n","Epoch 00478: val_loss did not improve from 0.18088\n","Epoch 479/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0071 - mae: 0.0391 - val_loss: 0.2627 - val_mae: 0.4137\n","\n","Epoch 00479: val_loss did not improve from 0.18088\n","Epoch 480/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0071 - mae: 0.0422 - val_loss: 0.2548 - val_mae: 0.4003\n","\n","Epoch 00480: val_loss did not improve from 0.18088\n","Epoch 481/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0069 - mae: 0.0401 - val_loss: 0.2514 - val_mae: 0.4002\n","\n","Epoch 00481: val_loss did not improve from 0.18088\n","Epoch 482/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0068 - mae: 0.0382 - val_loss: 0.2482 - val_mae: 0.3985\n","\n","Epoch 00482: val_loss did not improve from 0.18088\n","Epoch 483/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0067 - mae: 0.0377 - val_loss: 0.2516 - val_mae: 0.4016\n","\n","Epoch 00483: val_loss did not improve from 0.18088\n","Epoch 484/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0066 - mae: 0.0356 - val_loss: 0.2532 - val_mae: 0.4009\n","\n","Epoch 00484: val_loss did not improve from 0.18088\n","Epoch 485/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0066 - mae: 0.0373 - val_loss: 0.2486 - val_mae: 0.3922\n","\n","Epoch 00485: val_loss did not improve from 0.18088\n","Epoch 486/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0070 - mae: 0.0404 - val_loss: 0.2636 - val_mae: 0.4128\n","\n","Epoch 00486: val_loss did not improve from 0.18088\n","Epoch 487/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0072 - mae: 0.0444 - val_loss: 0.2671 - val_mae: 0.4095\n","\n","Epoch 00487: val_loss did not improve from 0.18088\n","Epoch 488/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0070 - mae: 0.0413 - val_loss: 0.2588 - val_mae: 0.4050\n","\n","Epoch 00488: val_loss did not improve from 0.18088\n","Epoch 489/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0065 - mae: 0.0368 - val_loss: 0.2523 - val_mae: 0.4025\n","\n","Epoch 00489: val_loss did not improve from 0.18088\n","Epoch 490/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0062 - mae: 0.0343 - val_loss: 0.2658 - val_mae: 0.4139\n","\n","Epoch 00490: val_loss did not improve from 0.18088\n","Epoch 491/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0063 - mae: 0.0337 - val_loss: 0.2582 - val_mae: 0.4095\n","\n","Epoch 00491: val_loss did not improve from 0.18088\n","Epoch 492/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0064 - mae: 0.0374 - val_loss: 0.2617 - val_mae: 0.4073\n","\n","Epoch 00492: val_loss did not improve from 0.18088\n","Epoch 493/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0061 - mae: 0.0361 - val_loss: 0.2594 - val_mae: 0.4082\n","\n","Epoch 00493: val_loss did not improve from 0.18088\n","Epoch 494/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0068 - mae: 0.0397 - val_loss: 0.2502 - val_mae: 0.3987\n","\n","Epoch 00494: val_loss did not improve from 0.18088\n","Epoch 495/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0064 - mae: 0.0368 - val_loss: 0.2615 - val_mae: 0.4053\n","\n","Epoch 00495: val_loss did not improve from 0.18088\n","Epoch 496/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0060 - mae: 0.0331 - val_loss: 0.2646 - val_mae: 0.4102\n","\n","Epoch 00496: val_loss did not improve from 0.18088\n","Epoch 497/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0064 - mae: 0.0362 - val_loss: 0.2446 - val_mae: 0.3910\n","\n","Epoch 00497: val_loss did not improve from 0.18088\n","Epoch 498/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0068 - mae: 0.0389 - val_loss: 0.2550 - val_mae: 0.4047\n","\n","Epoch 00498: val_loss did not improve from 0.18088\n","Epoch 499/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0066 - mae: 0.0392 - val_loss: 0.2583 - val_mae: 0.4061\n","\n","Epoch 00499: val_loss did not improve from 0.18088\n","Epoch 500/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0064 - mae: 0.0372 - val_loss: 0.2441 - val_mae: 0.3878\n","\n","Epoch 00500: val_loss did not improve from 0.18088\n","Epoch 501/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0062 - mae: 0.0372 - val_loss: 0.2572 - val_mae: 0.4038\n","\n","Epoch 00501: val_loss did not improve from 0.18088\n","Epoch 502/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0064 - mae: 0.0366 - val_loss: 0.2634 - val_mae: 0.4079\n","\n","Epoch 00502: val_loss did not improve from 0.18088\n","Epoch 503/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0061 - mae: 0.0346 - val_loss: 0.2485 - val_mae: 0.3925\n","\n","Epoch 00503: val_loss did not improve from 0.18088\n","Epoch 504/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0066 - mae: 0.0370 - val_loss: 0.2636 - val_mae: 0.4110\n","\n","Epoch 00504: val_loss did not improve from 0.18088\n","Epoch 505/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0326 - val_loss: 0.2586 - val_mae: 0.4034\n","\n","Epoch 00505: val_loss did not improve from 0.18088\n","Epoch 506/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0328 - val_loss: 0.2529 - val_mae: 0.3991\n","\n","Epoch 00506: val_loss did not improve from 0.18088\n","Epoch 507/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0060 - mae: 0.0346 - val_loss: 0.2657 - val_mae: 0.4139\n","\n","Epoch 00507: val_loss did not improve from 0.18088\n","Epoch 508/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0063 - mae: 0.0362 - val_loss: 0.2510 - val_mae: 0.3950\n","\n","Epoch 00508: val_loss did not improve from 0.18088\n","Epoch 509/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0066 - mae: 0.0379 - val_loss: 0.2498 - val_mae: 0.3989\n","\n","Epoch 00509: val_loss did not improve from 0.18088\n","Epoch 510/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0067 - mae: 0.0409 - val_loss: 0.2641 - val_mae: 0.4082\n","\n","Epoch 00510: val_loss did not improve from 0.18088\n","Epoch 511/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0064 - mae: 0.0375 - val_loss: 0.2571 - val_mae: 0.3998\n","\n","Epoch 00511: val_loss did not improve from 0.18088\n","Epoch 512/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0063 - mae: 0.0368 - val_loss: 0.2646 - val_mae: 0.4106\n","\n","Epoch 00512: val_loss did not improve from 0.18088\n","Epoch 513/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0063 - mae: 0.0383 - val_loss: 0.2586 - val_mae: 0.4047\n","\n","Epoch 00513: val_loss did not improve from 0.18088\n","Epoch 514/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0061 - mae: 0.0359 - val_loss: 0.2421 - val_mae: 0.3903\n","\n","Epoch 00514: val_loss did not improve from 0.18088\n","Epoch 515/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0060 - mae: 0.0354 - val_loss: 0.2602 - val_mae: 0.4077\n","\n","Epoch 00515: val_loss did not improve from 0.18088\n","Epoch 516/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0059 - mae: 0.0359 - val_loss: 0.2582 - val_mae: 0.4056\n","\n","Epoch 00516: val_loss did not improve from 0.18088\n","Epoch 517/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0057 - mae: 0.0330 - val_loss: 0.2515 - val_mae: 0.3988\n","\n","Epoch 00517: val_loss did not improve from 0.18088\n","Epoch 518/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0060 - mae: 0.0350 - val_loss: 0.2563 - val_mae: 0.4037\n","\n","Epoch 00518: val_loss did not improve from 0.18088\n","Epoch 519/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0065 - mae: 0.0367 - val_loss: 0.2423 - val_mae: 0.3904\n","\n","Epoch 00519: val_loss did not improve from 0.18088\n","Epoch 520/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0063 - mae: 0.0365 - val_loss: 0.2537 - val_mae: 0.4025\n","\n","Epoch 00520: val_loss did not improve from 0.18088\n","Epoch 521/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0351 - val_loss: 0.2577 - val_mae: 0.4029\n","\n","Epoch 00521: val_loss did not improve from 0.18088\n","Epoch 522/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0059 - mae: 0.0353 - val_loss: 0.2436 - val_mae: 0.3913\n","\n","Epoch 00522: val_loss did not improve from 0.18088\n","Epoch 523/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0060 - mae: 0.0356 - val_loss: 0.2534 - val_mae: 0.3980\n","\n","Epoch 00523: val_loss did not improve from 0.18088\n","Epoch 524/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0344 - val_loss: 0.2635 - val_mae: 0.4115\n","\n","Epoch 00524: val_loss did not improve from 0.18088\n","Epoch 525/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0057 - mae: 0.0349 - val_loss: 0.2522 - val_mae: 0.3943\n","\n","Epoch 00525: val_loss did not improve from 0.18088\n","Epoch 526/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0061 - mae: 0.0385 - val_loss: 0.2537 - val_mae: 0.4021\n","\n","Epoch 00526: val_loss did not improve from 0.18088\n","Epoch 527/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0061 - mae: 0.0372 - val_loss: 0.2634 - val_mae: 0.4104\n","\n","Epoch 00527: val_loss did not improve from 0.18088\n","Epoch 528/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0056 - mae: 0.0339 - val_loss: 0.2482 - val_mae: 0.3979\n","\n","Epoch 00528: val_loss did not improve from 0.18088\n","Epoch 529/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0059 - mae: 0.0332 - val_loss: 0.2572 - val_mae: 0.4097\n","\n","Epoch 00529: val_loss did not improve from 0.18088\n","Epoch 530/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0341 - val_loss: 0.2643 - val_mae: 0.4131\n","\n","Epoch 00530: val_loss did not improve from 0.18088\n","Epoch 531/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0342 - val_loss: 0.2484 - val_mae: 0.3953\n","\n","Epoch 00531: val_loss did not improve from 0.18088\n","Epoch 532/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0057 - mae: 0.0357 - val_loss: 0.2522 - val_mae: 0.4007\n","\n","Epoch 00532: val_loss did not improve from 0.18088\n","Epoch 533/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0345 - val_loss: 0.2538 - val_mae: 0.4029\n","\n","Epoch 00533: val_loss did not improve from 0.18088\n","Epoch 534/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0056 - mae: 0.0333 - val_loss: 0.2439 - val_mae: 0.3882\n","\n","Epoch 00534: val_loss did not improve from 0.18088\n","Epoch 535/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0062 - mae: 0.0386 - val_loss: 0.2466 - val_mae: 0.3986\n","\n","Epoch 00535: val_loss did not improve from 0.18088\n","Epoch 536/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0063 - mae: 0.0416 - val_loss: 0.2529 - val_mae: 0.3968\n","\n","Epoch 00536: val_loss did not improve from 0.18088\n","Epoch 537/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0061 - mae: 0.0377 - val_loss: 0.2468 - val_mae: 0.3938\n","\n","Epoch 00537: val_loss did not improve from 0.18088\n","Epoch 538/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0065 - mae: 0.0385 - val_loss: 0.2459 - val_mae: 0.3944\n","\n","Epoch 00538: val_loss did not improve from 0.18088\n","Epoch 539/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0064 - mae: 0.0382 - val_loss: 0.2556 - val_mae: 0.4034\n","\n","Epoch 00539: val_loss did not improve from 0.18088\n","Epoch 540/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0063 - mae: 0.0405 - val_loss: 0.2649 - val_mae: 0.4093\n","\n","Epoch 00540: val_loss did not improve from 0.18088\n","Epoch 541/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0059 - mae: 0.0367 - val_loss: 0.2527 - val_mae: 0.3990\n","\n","Epoch 00541: val_loss did not improve from 0.18088\n","Epoch 542/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0056 - mae: 0.0340 - val_loss: 0.2457 - val_mae: 0.3970\n","\n","Epoch 00542: val_loss did not improve from 0.18088\n","Epoch 543/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0061 - mae: 0.0369 - val_loss: 0.2490 - val_mae: 0.4002\n","\n","Epoch 00543: val_loss did not improve from 0.18088\n","Epoch 544/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0359 - val_loss: 0.2513 - val_mae: 0.4035\n","\n","Epoch 00544: val_loss did not improve from 0.18088\n","Epoch 545/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0064 - mae: 0.0395 - val_loss: 0.2617 - val_mae: 0.4013\n","\n","Epoch 00545: val_loss did not improve from 0.18088\n","Epoch 546/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0066 - mae: 0.0439 - val_loss: 0.2560 - val_mae: 0.4026\n","\n","Epoch 00546: val_loss did not improve from 0.18088\n","Epoch 547/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0061 - mae: 0.0396 - val_loss: 0.2604 - val_mae: 0.4066\n","\n","Epoch 00547: val_loss did not improve from 0.18088\n","Epoch 548/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0364 - val_loss: 0.2552 - val_mae: 0.4039\n","\n","Epoch 00548: val_loss did not improve from 0.18088\n","Epoch 549/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0060 - mae: 0.0384 - val_loss: 0.2600 - val_mae: 0.4082\n","\n","Epoch 00549: val_loss did not improve from 0.18088\n","Epoch 550/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0057 - mae: 0.0369 - val_loss: 0.2699 - val_mae: 0.4173\n","\n","Epoch 00550: val_loss did not improve from 0.18088\n","Epoch 551/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0362 - val_loss: 0.2567 - val_mae: 0.4098\n","\n","Epoch 00551: val_loss did not improve from 0.18088\n","Epoch 552/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0061 - mae: 0.0387 - val_loss: 0.2556 - val_mae: 0.4020\n","\n","Epoch 00552: val_loss did not improve from 0.18088\n","Epoch 553/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0058 - mae: 0.0365 - val_loss: 0.2714 - val_mae: 0.4184\n","\n","Epoch 00553: val_loss did not improve from 0.18088\n","Epoch 554/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0057 - mae: 0.0342 - val_loss: 0.2622 - val_mae: 0.4079\n","\n","Epoch 00554: val_loss did not improve from 0.18088\n","Epoch 555/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0054 - mae: 0.0334 - val_loss: 0.2581 - val_mae: 0.4094\n","\n","Epoch 00555: val_loss did not improve from 0.18088\n","Epoch 556/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0057 - mae: 0.0383 - val_loss: 0.2602 - val_mae: 0.4073\n","\n","Epoch 00556: val_loss did not improve from 0.18088\n","Epoch 557/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0383 - val_loss: 0.2529 - val_mae: 0.3988\n","\n","Epoch 00557: val_loss did not improve from 0.18088\n","Epoch 558/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0327 - val_loss: 0.2498 - val_mae: 0.3969\n","\n","Epoch 00558: val_loss did not improve from 0.18088\n","Epoch 559/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0334 - val_loss: 0.2472 - val_mae: 0.3954\n","\n","Epoch 00559: val_loss did not improve from 0.18088\n","Epoch 560/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0330 - val_loss: 0.2518 - val_mae: 0.3959\n","\n","Epoch 00560: val_loss did not improve from 0.18088\n","Epoch 561/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0054 - mae: 0.0337 - val_loss: 0.2576 - val_mae: 0.4029\n","\n","Epoch 00561: val_loss did not improve from 0.18088\n","Epoch 562/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0054 - mae: 0.0332 - val_loss: 0.2555 - val_mae: 0.3999\n","\n","Epoch 00562: val_loss did not improve from 0.18088\n","Epoch 563/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0059 - mae: 0.0367 - val_loss: 0.2640 - val_mae: 0.4020\n","\n","Epoch 00563: val_loss did not improve from 0.18088\n","Epoch 564/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0056 - mae: 0.0353 - val_loss: 0.2595 - val_mae: 0.4022\n","\n","Epoch 00564: val_loss did not improve from 0.18088\n","Epoch 565/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0331 - val_loss: 0.2565 - val_mae: 0.4012\n","\n","Epoch 00565: val_loss did not improve from 0.18088\n","Epoch 566/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0051 - mae: 0.0330 - val_loss: 0.2566 - val_mae: 0.4019\n","\n","Epoch 00566: val_loss did not improve from 0.18088\n","Epoch 567/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0338 - val_loss: 0.2661 - val_mae: 0.4130\n","\n","Epoch 00567: val_loss did not improve from 0.18088\n","Epoch 568/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0054 - mae: 0.0327 - val_loss: 0.2508 - val_mae: 0.3991\n","\n","Epoch 00568: val_loss did not improve from 0.18088\n","Epoch 569/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0060 - mae: 0.0377 - val_loss: 0.2596 - val_mae: 0.4074\n","\n","Epoch 00569: val_loss did not improve from 0.18088\n","Epoch 570/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0050 - mae: 0.0320 - val_loss: 0.2780 - val_mae: 0.4248\n","\n","Epoch 00570: val_loss did not improve from 0.18088\n","Epoch 571/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0342 - val_loss: 0.2650 - val_mae: 0.4077\n","\n","Epoch 00571: val_loss did not improve from 0.18088\n","Epoch 572/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0382 - val_loss: 0.2634 - val_mae: 0.4075\n","\n","Epoch 00572: val_loss did not improve from 0.18088\n","Epoch 573/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0054 - mae: 0.0333 - val_loss: 0.2711 - val_mae: 0.4171\n","\n","Epoch 00573: val_loss did not improve from 0.18088\n","Epoch 574/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0056 - mae: 0.0351 - val_loss: 0.2591 - val_mae: 0.4018\n","\n","Epoch 00574: val_loss did not improve from 0.18088\n","Epoch 575/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0328 - val_loss: 0.2648 - val_mae: 0.4058\n","\n","Epoch 00575: val_loss did not improve from 0.18088\n","Epoch 576/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0339 - val_loss: 0.2637 - val_mae: 0.4070\n","\n","Epoch 00576: val_loss did not improve from 0.18088\n","Epoch 577/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0307 - val_loss: 0.2516 - val_mae: 0.3985\n","\n","Epoch 00577: val_loss did not improve from 0.18088\n","Epoch 578/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0054 - mae: 0.0354 - val_loss: 0.2524 - val_mae: 0.3990\n","\n","Epoch 00578: val_loss did not improve from 0.18088\n","Epoch 579/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0051 - mae: 0.0345 - val_loss: 0.2648 - val_mae: 0.4087\n","\n","Epoch 00579: val_loss did not improve from 0.18088\n","Epoch 580/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0338 - val_loss: 0.2486 - val_mae: 0.3956\n","\n","Epoch 00580: val_loss did not improve from 0.18088\n","Epoch 581/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0056 - mae: 0.0373 - val_loss: 0.2480 - val_mae: 0.3967\n","\n","Epoch 00581: val_loss did not improve from 0.18088\n","Epoch 582/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0054 - mae: 0.0353 - val_loss: 0.2654 - val_mae: 0.4131\n","\n","Epoch 00582: val_loss did not improve from 0.18088\n","Epoch 583/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0351 - val_loss: 0.2629 - val_mae: 0.4041\n","\n","Epoch 00583: val_loss did not improve from 0.18088\n","Epoch 584/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0051 - mae: 0.0354 - val_loss: 0.2620 - val_mae: 0.4074\n","\n","Epoch 00584: val_loss did not improve from 0.18088\n","Epoch 585/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0345 - val_loss: 0.2607 - val_mae: 0.4077\n","\n","Epoch 00585: val_loss did not improve from 0.18088\n","Epoch 586/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0341 - val_loss: 0.2499 - val_mae: 0.3978\n","\n","Epoch 00586: val_loss did not improve from 0.18088\n","Epoch 587/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0055 - mae: 0.0364 - val_loss: 0.2696 - val_mae: 0.4114\n","\n","Epoch 00587: val_loss did not improve from 0.18088\n","Epoch 588/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0059 - mae: 0.0388 - val_loss: 0.2550 - val_mae: 0.4024\n","\n","Epoch 00588: val_loss did not improve from 0.18088\n","Epoch 589/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0056 - mae: 0.0370 - val_loss: 0.2439 - val_mae: 0.3883\n","\n","Epoch 00589: val_loss did not improve from 0.18088\n","Epoch 590/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0350 - val_loss: 0.2748 - val_mae: 0.4207\n","\n","Epoch 00590: val_loss did not improve from 0.18088\n","Epoch 591/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0383 - val_loss: 0.2653 - val_mae: 0.4084\n","\n","Epoch 00591: val_loss did not improve from 0.18088\n","Epoch 592/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0353 - val_loss: 0.2618 - val_mae: 0.4035\n","\n","Epoch 00592: val_loss did not improve from 0.18088\n","Epoch 593/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0049 - mae: 0.0323 - val_loss: 0.2675 - val_mae: 0.4111\n","\n","Epoch 00593: val_loss did not improve from 0.18088\n","Epoch 594/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0051 - mae: 0.0334 - val_loss: 0.2503 - val_mae: 0.4002\n","\n","Epoch 00594: val_loss did not improve from 0.18088\n","Epoch 595/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0315 - val_loss: 0.2460 - val_mae: 0.3927\n","\n","Epoch 00595: val_loss did not improve from 0.18088\n","Epoch 596/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0055 - mae: 0.0370 - val_loss: 0.2570 - val_mae: 0.4062\n","\n","Epoch 00596: val_loss did not improve from 0.18088\n","Epoch 597/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0050 - mae: 0.0340 - val_loss: 0.2425 - val_mae: 0.3912\n","\n","Epoch 00597: val_loss did not improve from 0.18088\n","Epoch 598/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0050 - mae: 0.0328 - val_loss: 0.2498 - val_mae: 0.3945\n","\n","Epoch 00598: val_loss did not improve from 0.18088\n","Epoch 599/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0050 - mae: 0.0324 - val_loss: 0.2685 - val_mae: 0.4114\n","\n","Epoch 00599: val_loss did not improve from 0.18088\n","Epoch 600/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0049 - mae: 0.0326 - val_loss: 0.2624 - val_mae: 0.4050\n","\n","Epoch 00600: val_loss did not improve from 0.18088\n","Epoch 601/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0309 - val_loss: 0.2633 - val_mae: 0.4075\n","\n","Epoch 00601: val_loss did not improve from 0.18088\n","Epoch 602/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0318 - val_loss: 0.2484 - val_mae: 0.4002\n","\n","Epoch 00602: val_loss did not improve from 0.18088\n","Epoch 603/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0054 - mae: 0.0375 - val_loss: 0.2518 - val_mae: 0.3949\n","\n","Epoch 00603: val_loss did not improve from 0.18088\n","Epoch 604/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0050 - mae: 0.0352 - val_loss: 0.2705 - val_mae: 0.4180\n","\n","Epoch 00604: val_loss did not improve from 0.18088\n","Epoch 605/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0049 - mae: 0.0326 - val_loss: 0.2552 - val_mae: 0.4027\n","\n","Epoch 00605: val_loss did not improve from 0.18088\n","Epoch 606/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0047 - mae: 0.0324 - val_loss: 0.2543 - val_mae: 0.3977\n","\n","Epoch 00606: val_loss did not improve from 0.18088\n","Epoch 607/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0357 - val_loss: 0.2718 - val_mae: 0.4170\n","\n","Epoch 00607: val_loss did not improve from 0.18088\n","Epoch 608/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0054 - mae: 0.0366 - val_loss: 0.2554 - val_mae: 0.3998\n","\n","Epoch 00608: val_loss did not improve from 0.18088\n","Epoch 609/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0052 - mae: 0.0356 - val_loss: 0.2504 - val_mae: 0.3966\n","\n","Epoch 00609: val_loss did not improve from 0.18088\n","Epoch 610/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0047 - mae: 0.0309 - val_loss: 0.2697 - val_mae: 0.4109\n","\n","Epoch 00610: val_loss did not improve from 0.18088\n","Epoch 611/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0055 - mae: 0.0354 - val_loss: 0.2425 - val_mae: 0.3900\n","\n","Epoch 00611: val_loss did not improve from 0.18088\n","Epoch 612/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0055 - mae: 0.0376 - val_loss: 0.2502 - val_mae: 0.3964\n","\n","Epoch 00612: val_loss did not improve from 0.18088\n","Epoch 613/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0049 - mae: 0.0343 - val_loss: 0.2735 - val_mae: 0.4185\n","\n","Epoch 00613: val_loss did not improve from 0.18088\n","Epoch 614/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0057 - mae: 0.0373 - val_loss: 0.2537 - val_mae: 0.3992\n","\n","Epoch 00614: val_loss did not improve from 0.18088\n","Epoch 615/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0054 - mae: 0.0377 - val_loss: 0.2523 - val_mae: 0.4002\n","\n","Epoch 00615: val_loss did not improve from 0.18088\n","Epoch 616/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0344 - val_loss: 0.2685 - val_mae: 0.4155\n","\n","Epoch 00616: val_loss did not improve from 0.18088\n","Epoch 617/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0298 - val_loss: 0.2519 - val_mae: 0.3968\n","\n","Epoch 00617: val_loss did not improve from 0.18088\n","Epoch 618/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0054 - mae: 0.0378 - val_loss: 0.2593 - val_mae: 0.4027\n","\n","Epoch 00618: val_loss did not improve from 0.18088\n","Epoch 619/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0343 - val_loss: 0.2681 - val_mae: 0.4166\n","\n","Epoch 00619: val_loss did not improve from 0.18088\n","Epoch 620/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0366 - val_loss: 0.2625 - val_mae: 0.4100\n","\n","Epoch 00620: val_loss did not improve from 0.18088\n","Epoch 621/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0049 - mae: 0.0340 - val_loss: 0.2571 - val_mae: 0.4049\n","\n","Epoch 00621: val_loss did not improve from 0.18088\n","Epoch 622/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0370 - val_loss: 0.2655 - val_mae: 0.4109\n","\n","Epoch 00622: val_loss did not improve from 0.18088\n","Epoch 623/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0337 - val_loss: 0.2518 - val_mae: 0.4011\n","\n","Epoch 00623: val_loss did not improve from 0.18088\n","Epoch 624/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0049 - mae: 0.0361 - val_loss: 0.2545 - val_mae: 0.4008\n","\n","Epoch 00624: val_loss did not improve from 0.18088\n","Epoch 625/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0323 - val_loss: 0.2576 - val_mae: 0.4056\n","\n","Epoch 00625: val_loss did not improve from 0.18088\n","Epoch 626/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0326 - val_loss: 0.2601 - val_mae: 0.4061\n","\n","Epoch 00626: val_loss did not improve from 0.18088\n","Epoch 627/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0050 - mae: 0.0355 - val_loss: 0.2667 - val_mae: 0.4130\n","\n","Epoch 00627: val_loss did not improve from 0.18088\n","Epoch 628/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0317 - val_loss: 0.2611 - val_mae: 0.4104\n","\n","Epoch 00628: val_loss did not improve from 0.18088\n","Epoch 629/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0320 - val_loss: 0.2666 - val_mae: 0.4113\n","\n","Epoch 00629: val_loss did not improve from 0.18088\n","Epoch 630/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0329 - val_loss: 0.2656 - val_mae: 0.4132\n","\n","Epoch 00630: val_loss did not improve from 0.18088\n","Epoch 631/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0312 - val_loss: 0.2671 - val_mae: 0.4117\n","\n","Epoch 00631: val_loss did not improve from 0.18088\n","Epoch 632/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0328 - val_loss: 0.2559 - val_mae: 0.4037\n","\n","Epoch 00632: val_loss did not improve from 0.18088\n","Epoch 633/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0311 - val_loss: 0.2610 - val_mae: 0.4070\n","\n","Epoch 00633: val_loss did not improve from 0.18088\n","Epoch 634/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0328 - val_loss: 0.2696 - val_mae: 0.4147\n","\n","Epoch 00634: val_loss did not improve from 0.18088\n","Epoch 635/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0047 - mae: 0.0332 - val_loss: 0.2597 - val_mae: 0.4013\n","\n","Epoch 00635: val_loss did not improve from 0.18088\n","Epoch 636/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0050 - mae: 0.0374 - val_loss: 0.2621 - val_mae: 0.4105\n","\n","Epoch 00636: val_loss did not improve from 0.18088\n","Epoch 637/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0048 - mae: 0.0346 - val_loss: 0.2641 - val_mae: 0.4112\n","\n","Epoch 00637: val_loss did not improve from 0.18088\n","Epoch 638/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0301 - val_loss: 0.2561 - val_mae: 0.4041\n","\n","Epoch 00638: val_loss did not improve from 0.18088\n","Epoch 639/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0325 - val_loss: 0.2579 - val_mae: 0.4049\n","\n","Epoch 00639: val_loss did not improve from 0.18088\n","Epoch 640/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0310 - val_loss: 0.2602 - val_mae: 0.4071\n","\n","Epoch 00640: val_loss did not improve from 0.18088\n","Epoch 641/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0320 - val_loss: 0.2594 - val_mae: 0.4064\n","\n","Epoch 00641: val_loss did not improve from 0.18088\n","Epoch 642/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0304 - val_loss: 0.2565 - val_mae: 0.4028\n","\n","Epoch 00642: val_loss did not improve from 0.18088\n","Epoch 643/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0330 - val_loss: 0.2553 - val_mae: 0.4014\n","\n","Epoch 00643: val_loss did not improve from 0.18088\n","Epoch 644/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0318 - val_loss: 0.2618 - val_mae: 0.4052\n","\n","Epoch 00644: val_loss did not improve from 0.18088\n","Epoch 645/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0328 - val_loss: 0.2618 - val_mae: 0.4056\n","\n","Epoch 00645: val_loss did not improve from 0.18088\n","Epoch 646/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0327 - val_loss: 0.2572 - val_mae: 0.4025\n","\n","Epoch 00646: val_loss did not improve from 0.18088\n","Epoch 647/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0053 - mae: 0.0350 - val_loss: 0.2604 - val_mae: 0.4077\n","\n","Epoch 00647: val_loss did not improve from 0.18088\n","Epoch 648/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0344 - val_loss: 0.2688 - val_mae: 0.4095\n","\n","Epoch 00648: val_loss did not improve from 0.18088\n","Epoch 649/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0361 - val_loss: 0.2651 - val_mae: 0.4102\n","\n","Epoch 00649: val_loss did not improve from 0.18088\n","Epoch 650/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0356 - val_loss: 0.2581 - val_mae: 0.4040\n","\n","Epoch 00650: val_loss did not improve from 0.18088\n","Epoch 651/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0043 - mae: 0.0315 - val_loss: 0.2601 - val_mae: 0.4036\n","\n","Epoch 00651: val_loss did not improve from 0.18088\n","Epoch 652/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0324 - val_loss: 0.2591 - val_mae: 0.4045\n","\n","Epoch 00652: val_loss did not improve from 0.18088\n","Epoch 653/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0326 - val_loss: 0.2583 - val_mae: 0.4054\n","\n","Epoch 00653: val_loss did not improve from 0.18088\n","Epoch 654/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0336 - val_loss: 0.2647 - val_mae: 0.4107\n","\n","Epoch 00654: val_loss did not improve from 0.18088\n","Epoch 655/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0326 - val_loss: 0.2746 - val_mae: 0.4141\n","\n","Epoch 00655: val_loss did not improve from 0.18088\n","Epoch 656/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0323 - val_loss: 0.2673 - val_mae: 0.4138\n","\n","Epoch 00656: val_loss did not improve from 0.18088\n","Epoch 657/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0049 - mae: 0.0360 - val_loss: 0.2666 - val_mae: 0.4107\n","\n","Epoch 00657: val_loss did not improve from 0.18088\n","Epoch 658/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0336 - val_loss: 0.2651 - val_mae: 0.4138\n","\n","Epoch 00658: val_loss did not improve from 0.18088\n","Epoch 659/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0040 - mae: 0.0293 - val_loss: 0.2712 - val_mae: 0.4191\n","\n","Epoch 00659: val_loss did not improve from 0.18088\n","Epoch 660/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0316 - val_loss: 0.2581 - val_mae: 0.4087\n","\n","Epoch 00660: val_loss did not improve from 0.18088\n","Epoch 661/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0326 - val_loss: 0.2480 - val_mae: 0.3987\n","\n","Epoch 00661: val_loss did not improve from 0.18088\n","Epoch 662/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0047 - mae: 0.0342 - val_loss: 0.2692 - val_mae: 0.4190\n","\n","Epoch 00662: val_loss did not improve from 0.18088\n","Epoch 663/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0047 - mae: 0.0372 - val_loss: 0.2699 - val_mae: 0.4129\n","\n","Epoch 00663: val_loss did not improve from 0.18088\n","Epoch 664/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0374 - val_loss: 0.2485 - val_mae: 0.3961\n","\n","Epoch 00664: val_loss did not improve from 0.18088\n","Epoch 665/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0051 - mae: 0.0400 - val_loss: 0.2725 - val_mae: 0.4172\n","\n","Epoch 00665: val_loss did not improve from 0.18088\n","Epoch 666/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0051 - mae: 0.0378 - val_loss: 0.2674 - val_mae: 0.4106\n","\n","Epoch 00666: val_loss did not improve from 0.18088\n","Epoch 667/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0357 - val_loss: 0.2601 - val_mae: 0.4059\n","\n","Epoch 00667: val_loss did not improve from 0.18088\n","Epoch 668/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0342 - val_loss: 0.2699 - val_mae: 0.4170\n","\n","Epoch 00668: val_loss did not improve from 0.18088\n","Epoch 669/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0339 - val_loss: 0.2707 - val_mae: 0.4176\n","\n","Epoch 00669: val_loss did not improve from 0.18088\n","Epoch 670/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0319 - val_loss: 0.2578 - val_mae: 0.4045\n","\n","Epoch 00670: val_loss did not improve from 0.18088\n","Epoch 671/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0342 - val_loss: 0.2723 - val_mae: 0.4206\n","\n","Epoch 00671: val_loss did not improve from 0.18088\n","Epoch 672/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0050 - mae: 0.0384 - val_loss: 0.2769 - val_mae: 0.4244\n","\n","Epoch 00672: val_loss did not improve from 0.18088\n","Epoch 673/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0333 - val_loss: 0.2641 - val_mae: 0.4107\n","\n","Epoch 00673: val_loss did not improve from 0.18088\n","Epoch 674/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0047 - mae: 0.0357 - val_loss: 0.2695 - val_mae: 0.4192\n","\n","Epoch 00674: val_loss did not improve from 0.18088\n","Epoch 675/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0337 - val_loss: 0.2632 - val_mae: 0.4164\n","\n","Epoch 00675: val_loss did not improve from 0.18088\n","Epoch 676/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0318 - val_loss: 0.2622 - val_mae: 0.4111\n","\n","Epoch 00676: val_loss did not improve from 0.18088\n","Epoch 677/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0333 - val_loss: 0.2733 - val_mae: 0.4218\n","\n","Epoch 00677: val_loss did not improve from 0.18088\n","Epoch 678/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0332 - val_loss: 0.2584 - val_mae: 0.4079\n","\n","Epoch 00678: val_loss did not improve from 0.18088\n","Epoch 679/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0324 - val_loss: 0.2495 - val_mae: 0.3975\n","\n","Epoch 00679: val_loss did not improve from 0.18088\n","Epoch 680/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0339 - val_loss: 0.2627 - val_mae: 0.4083\n","\n","Epoch 00680: val_loss did not improve from 0.18088\n","Epoch 681/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0330 - val_loss: 0.2687 - val_mae: 0.4136\n","\n","Epoch 00681: val_loss did not improve from 0.18088\n","Epoch 682/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0333 - val_loss: 0.2463 - val_mae: 0.3928\n","\n","Epoch 00682: val_loss did not improve from 0.18088\n","Epoch 683/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0047 - mae: 0.0368 - val_loss: 0.2559 - val_mae: 0.4027\n","\n","Epoch 00683: val_loss did not improve from 0.18088\n","Epoch 684/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0333 - val_loss: 0.2621 - val_mae: 0.4096\n","\n","Epoch 00684: val_loss did not improve from 0.18088\n","Epoch 685/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0338 - val_loss: 0.2543 - val_mae: 0.4003\n","\n","Epoch 00685: val_loss did not improve from 0.18088\n","Epoch 686/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0340 - val_loss: 0.2620 - val_mae: 0.4080\n","\n","Epoch 00686: val_loss did not improve from 0.18088\n","Epoch 687/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0316 - val_loss: 0.2644 - val_mae: 0.4088\n","\n","Epoch 00687: val_loss did not improve from 0.18088\n","Epoch 688/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0040 - mae: 0.0298 - val_loss: 0.2656 - val_mae: 0.4106\n","\n","Epoch 00688: val_loss did not improve from 0.18088\n","Epoch 689/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0337 - val_loss: 0.2620 - val_mae: 0.4073\n","\n","Epoch 00689: val_loss did not improve from 0.18088\n","Epoch 690/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0328 - val_loss: 0.2616 - val_mae: 0.4090\n","\n","Epoch 00690: val_loss did not improve from 0.18088\n","Epoch 691/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0362 - val_loss: 0.2645 - val_mae: 0.4128\n","\n","Epoch 00691: val_loss did not improve from 0.18088\n","Epoch 692/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0338 - val_loss: 0.2600 - val_mae: 0.4090\n","\n","Epoch 00692: val_loss did not improve from 0.18088\n","Epoch 693/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0353 - val_loss: 0.2454 - val_mae: 0.4013\n","\n","Epoch 00693: val_loss did not improve from 0.18088\n","Epoch 694/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0048 - mae: 0.0369 - val_loss: 0.2653 - val_mae: 0.4164\n","\n","Epoch 00694: val_loss did not improve from 0.18088\n","Epoch 695/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0375 - val_loss: 0.2595 - val_mae: 0.4117\n","\n","Epoch 00695: val_loss did not improve from 0.18088\n","Epoch 696/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0050 - mae: 0.0399 - val_loss: 0.2543 - val_mae: 0.4038\n","\n","Epoch 00696: val_loss did not improve from 0.18088\n","Epoch 697/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0368 - val_loss: 0.2641 - val_mae: 0.4138\n","\n","Epoch 00697: val_loss did not improve from 0.18088\n","Epoch 698/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0330 - val_loss: 0.2640 - val_mae: 0.4125\n","\n","Epoch 00698: val_loss did not improve from 0.18088\n","Epoch 699/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0042 - mae: 0.0310 - val_loss: 0.2654 - val_mae: 0.4118\n","\n","Epoch 00699: val_loss did not improve from 0.18088\n","Epoch 700/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0373 - val_loss: 0.2615 - val_mae: 0.4098\n","\n","Epoch 00700: val_loss did not improve from 0.18088\n","Epoch 701/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0349 - val_loss: 0.2580 - val_mae: 0.4047\n","\n","Epoch 00701: val_loss did not improve from 0.18088\n","Epoch 702/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0376 - val_loss: 0.2635 - val_mae: 0.4131\n","\n","Epoch 00702: val_loss did not improve from 0.18088\n","Epoch 703/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0359 - val_loss: 0.2630 - val_mae: 0.4054\n","\n","Epoch 00703: val_loss did not improve from 0.18088\n","Epoch 704/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0351 - val_loss: 0.2617 - val_mae: 0.4106\n","\n","Epoch 00704: val_loss did not improve from 0.18088\n","Epoch 705/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0300 - val_loss: 0.2675 - val_mae: 0.4157\n","\n","Epoch 00705: val_loss did not improve from 0.18088\n","Epoch 706/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0348 - val_loss: 0.2684 - val_mae: 0.4169\n","\n","Epoch 00706: val_loss did not improve from 0.18088\n","Epoch 707/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0332 - val_loss: 0.2776 - val_mae: 0.4203\n","\n","Epoch 00707: val_loss did not improve from 0.18088\n","Epoch 708/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0356 - val_loss: 0.2683 - val_mae: 0.4169\n","\n","Epoch 00708: val_loss did not improve from 0.18088\n","Epoch 709/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0326 - val_loss: 0.2699 - val_mae: 0.4165\n","\n","Epoch 00709: val_loss did not improve from 0.18088\n","Epoch 710/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0309 - val_loss: 0.2746 - val_mae: 0.4246\n","\n","Epoch 00710: val_loss did not improve from 0.18088\n","Epoch 711/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0323 - val_loss: 0.2616 - val_mae: 0.4090\n","\n","Epoch 00711: val_loss did not improve from 0.18088\n","Epoch 712/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0342 - val_loss: 0.2642 - val_mae: 0.4160\n","\n","Epoch 00712: val_loss did not improve from 0.18088\n","Epoch 713/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0300 - val_loss: 0.2665 - val_mae: 0.4137\n","\n","Epoch 00713: val_loss did not improve from 0.18088\n","Epoch 714/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0306 - val_loss: 0.2670 - val_mae: 0.4125\n","\n","Epoch 00714: val_loss did not improve from 0.18088\n","Epoch 715/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0319 - val_loss: 0.2565 - val_mae: 0.4066\n","\n","Epoch 00715: val_loss did not improve from 0.18088\n","Epoch 716/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0284 - val_loss: 0.2601 - val_mae: 0.4104\n","\n","Epoch 00716: val_loss did not improve from 0.18088\n","Epoch 717/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0324 - val_loss: 0.2583 - val_mae: 0.4098\n","\n","Epoch 00717: val_loss did not improve from 0.18088\n","Epoch 718/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0355 - val_loss: 0.2585 - val_mae: 0.4059\n","\n","Epoch 00718: val_loss did not improve from 0.18088\n","Epoch 719/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0343 - val_loss: 0.2598 - val_mae: 0.4139\n","\n","Epoch 00719: val_loss did not improve from 0.18088\n","Epoch 720/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0398 - val_loss: 0.2642 - val_mae: 0.4108\n","\n","Epoch 00720: val_loss did not improve from 0.18088\n","Epoch 721/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0049 - mae: 0.0398 - val_loss: 0.2570 - val_mae: 0.4066\n","\n","Epoch 00721: val_loss did not improve from 0.18088\n","Epoch 722/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0365 - val_loss: 0.2705 - val_mae: 0.4209\n","\n","Epoch 00722: val_loss did not improve from 0.18088\n","Epoch 723/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0348 - val_loss: 0.2704 - val_mae: 0.4220\n","\n","Epoch 00723: val_loss did not improve from 0.18088\n","Epoch 724/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0315 - val_loss: 0.2631 - val_mae: 0.4156\n","\n","Epoch 00724: val_loss did not improve from 0.18088\n","Epoch 725/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0325 - val_loss: 0.2743 - val_mae: 0.4227\n","\n","Epoch 00725: val_loss did not improve from 0.18088\n","Epoch 726/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0300 - val_loss: 0.2722 - val_mae: 0.4224\n","\n","Epoch 00726: val_loss did not improve from 0.18088\n","Epoch 727/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0328 - val_loss: 0.2653 - val_mae: 0.4102\n","\n","Epoch 00727: val_loss did not improve from 0.18088\n","Epoch 728/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0334 - val_loss: 0.2633 - val_mae: 0.4101\n","\n","Epoch 00728: val_loss did not improve from 0.18088\n","Epoch 729/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0353 - val_loss: 0.2640 - val_mae: 0.4088\n","\n","Epoch 00729: val_loss did not improve from 0.18088\n","Epoch 730/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0319 - val_loss: 0.2504 - val_mae: 0.3971\n","\n","Epoch 00730: val_loss did not improve from 0.18088\n","Epoch 731/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0310 - val_loss: 0.2532 - val_mae: 0.4018\n","\n","Epoch 00731: val_loss did not improve from 0.18088\n","Epoch 732/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0310 - val_loss: 0.2608 - val_mae: 0.4080\n","\n","Epoch 00732: val_loss did not improve from 0.18088\n","Epoch 733/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0330 - val_loss: 0.2615 - val_mae: 0.4072\n","\n","Epoch 00733: val_loss did not improve from 0.18088\n","Epoch 734/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0339 - val_loss: 0.2661 - val_mae: 0.4126\n","\n","Epoch 00734: val_loss did not improve from 0.18088\n","Epoch 735/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0313 - val_loss: 0.2643 - val_mae: 0.4121\n","\n","Epoch 00735: val_loss did not improve from 0.18088\n","Epoch 736/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0315 - val_loss: 0.2685 - val_mae: 0.4163\n","\n","Epoch 00736: val_loss did not improve from 0.18088\n","Epoch 737/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0323 - val_loss: 0.2779 - val_mae: 0.4241\n","\n","Epoch 00737: val_loss did not improve from 0.18088\n","Epoch 738/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0326 - val_loss: 0.2692 - val_mae: 0.4198\n","\n","Epoch 00738: val_loss did not improve from 0.18088\n","Epoch 739/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0299 - val_loss: 0.2607 - val_mae: 0.4108\n","\n","Epoch 00739: val_loss did not improve from 0.18088\n","Epoch 740/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0313 - val_loss: 0.2608 - val_mae: 0.4111\n","\n","Epoch 00740: val_loss did not improve from 0.18088\n","Epoch 741/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0323 - val_loss: 0.2513 - val_mae: 0.4031\n","\n","Epoch 00741: val_loss did not improve from 0.18088\n","Epoch 742/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0330 - val_loss: 0.2467 - val_mae: 0.3990\n","\n","Epoch 00742: val_loss did not improve from 0.18088\n","Epoch 743/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0307 - val_loss: 0.2679 - val_mae: 0.4139\n","\n","Epoch 00743: val_loss did not improve from 0.18088\n","Epoch 744/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0329 - val_loss: 0.2615 - val_mae: 0.4069\n","\n","Epoch 00744: val_loss did not improve from 0.18088\n","Epoch 745/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0340 - val_loss: 0.2528 - val_mae: 0.4021\n","\n","Epoch 00745: val_loss did not improve from 0.18088\n","Epoch 746/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0310 - val_loss: 0.2586 - val_mae: 0.4076\n","\n","Epoch 00746: val_loss did not improve from 0.18088\n","Epoch 747/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0306 - val_loss: 0.2590 - val_mae: 0.4084\n","\n","Epoch 00747: val_loss did not improve from 0.18088\n","Epoch 748/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0324 - val_loss: 0.2565 - val_mae: 0.4062\n","\n","Epoch 00748: val_loss did not improve from 0.18088\n","Epoch 749/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0304 - val_loss: 0.2625 - val_mae: 0.4108\n","\n","Epoch 00749: val_loss did not improve from 0.18088\n","Epoch 750/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0305 - val_loss: 0.2566 - val_mae: 0.4051\n","\n","Epoch 00750: val_loss did not improve from 0.18088\n","Epoch 751/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0295 - val_loss: 0.2525 - val_mae: 0.4000\n","\n","Epoch 00751: val_loss did not improve from 0.18088\n","Epoch 752/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0314 - val_loss: 0.2531 - val_mae: 0.4041\n","\n","Epoch 00752: val_loss did not improve from 0.18088\n","Epoch 753/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0308 - val_loss: 0.2591 - val_mae: 0.4072\n","\n","Epoch 00753: val_loss did not improve from 0.18088\n","Epoch 754/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0305 - val_loss: 0.2612 - val_mae: 0.4097\n","\n","Epoch 00754: val_loss did not improve from 0.18088\n","Epoch 755/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0306 - val_loss: 0.2605 - val_mae: 0.4093\n","\n","Epoch 00755: val_loss did not improve from 0.18088\n","Epoch 756/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0304 - val_loss: 0.2565 - val_mae: 0.4065\n","\n","Epoch 00756: val_loss did not improve from 0.18088\n","Epoch 757/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0308 - val_loss: 0.2644 - val_mae: 0.4144\n","\n","Epoch 00757: val_loss did not improve from 0.18088\n","Epoch 758/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0311 - val_loss: 0.2711 - val_mae: 0.4178\n","\n","Epoch 00758: val_loss did not improve from 0.18088\n","Epoch 759/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0314 - val_loss: 0.2587 - val_mae: 0.4090\n","\n","Epoch 00759: val_loss did not improve from 0.18088\n","Epoch 760/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0300 - val_loss: 0.2577 - val_mae: 0.4108\n","\n","Epoch 00760: val_loss did not improve from 0.18088\n","Epoch 761/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0316 - val_loss: 0.2574 - val_mae: 0.4069\n","\n","Epoch 00761: val_loss did not improve from 0.18088\n","Epoch 762/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0305 - val_loss: 0.2584 - val_mae: 0.4111\n","\n","Epoch 00762: val_loss did not improve from 0.18088\n","Epoch 763/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0326 - val_loss: 0.2646 - val_mae: 0.4118\n","\n","Epoch 00763: val_loss did not improve from 0.18088\n","Epoch 764/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0317 - val_loss: 0.2647 - val_mae: 0.4150\n","\n","Epoch 00764: val_loss did not improve from 0.18088\n","Epoch 765/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0312 - val_loss: 0.2513 - val_mae: 0.4029\n","\n","Epoch 00765: val_loss did not improve from 0.18088\n","Epoch 766/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0329 - val_loss: 0.2621 - val_mae: 0.4092\n","\n","Epoch 00766: val_loss did not improve from 0.18088\n","Epoch 767/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0300 - val_loss: 0.2681 - val_mae: 0.4191\n","\n","Epoch 00767: val_loss did not improve from 0.18088\n","Epoch 768/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0324 - val_loss: 0.2579 - val_mae: 0.4087\n","\n","Epoch 00768: val_loss did not improve from 0.18088\n","Epoch 769/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0309 - val_loss: 0.2604 - val_mae: 0.4122\n","\n","Epoch 00769: val_loss did not improve from 0.18088\n","Epoch 770/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0329 - val_loss: 0.2699 - val_mae: 0.4215\n","\n","Epoch 00770: val_loss did not improve from 0.18088\n","Epoch 771/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0300 - val_loss: 0.2599 - val_mae: 0.4078\n","\n","Epoch 00771: val_loss did not improve from 0.18088\n","Epoch 772/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0298 - val_loss: 0.2599 - val_mae: 0.4135\n","\n","Epoch 00772: val_loss did not improve from 0.18088\n","Epoch 773/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0331 - val_loss: 0.2623 - val_mae: 0.4121\n","\n","Epoch 00773: val_loss did not improve from 0.18088\n","Epoch 774/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0310 - val_loss: 0.2689 - val_mae: 0.4162\n","\n","Epoch 00774: val_loss did not improve from 0.18088\n","Epoch 775/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0337 - val_loss: 0.2539 - val_mae: 0.4047\n","\n","Epoch 00775: val_loss did not improve from 0.18088\n","Epoch 776/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0301 - val_loss: 0.2569 - val_mae: 0.4054\n","\n","Epoch 00776: val_loss did not improve from 0.18088\n","Epoch 777/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0035 - mae: 0.0301 - val_loss: 0.2678 - val_mae: 0.4147\n","\n","Epoch 00777: val_loss did not improve from 0.18088\n","Epoch 778/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0319 - val_loss: 0.2601 - val_mae: 0.4039\n","\n","Epoch 00778: val_loss did not improve from 0.18088\n","Epoch 779/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0335 - val_loss: 0.2593 - val_mae: 0.4101\n","\n","Epoch 00779: val_loss did not improve from 0.18088\n","Epoch 780/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0377 - val_loss: 0.2607 - val_mae: 0.4106\n","\n","Epoch 00780: val_loss did not improve from 0.18088\n","Epoch 781/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0309 - val_loss: 0.2658 - val_mae: 0.4071\n","\n","Epoch 00781: val_loss did not improve from 0.18088\n","Epoch 782/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0339 - val_loss: 0.2653 - val_mae: 0.4112\n","\n","Epoch 00782: val_loss did not improve from 0.18088\n","Epoch 783/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0324 - val_loss: 0.2540 - val_mae: 0.3992\n","\n","Epoch 00783: val_loss did not improve from 0.18088\n","Epoch 784/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0348 - val_loss: 0.2541 - val_mae: 0.4038\n","\n","Epoch 00784: val_loss did not improve from 0.18088\n","Epoch 785/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0038 - mae: 0.0330 - val_loss: 0.2688 - val_mae: 0.4129\n","\n","Epoch 00785: val_loss did not improve from 0.18088\n","Epoch 786/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0351 - val_loss: 0.2563 - val_mae: 0.4086\n","\n","Epoch 00786: val_loss did not improve from 0.18088\n","Epoch 787/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0040 - mae: 0.0340 - val_loss: 0.2630 - val_mae: 0.4117\n","\n","Epoch 00787: val_loss did not improve from 0.18088\n","Epoch 788/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0333 - val_loss: 0.2662 - val_mae: 0.4142\n","\n","Epoch 00788: val_loss did not improve from 0.18088\n","Epoch 789/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0380 - val_loss: 0.2600 - val_mae: 0.4008\n","\n","Epoch 00789: val_loss did not improve from 0.18088\n","Epoch 790/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0378 - val_loss: 0.2710 - val_mae: 0.4155\n","\n","Epoch 00790: val_loss did not improve from 0.18088\n","Epoch 791/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0335 - val_loss: 0.2617 - val_mae: 0.4083\n","\n","Epoch 00791: val_loss did not improve from 0.18088\n","Epoch 792/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0330 - val_loss: 0.2692 - val_mae: 0.4108\n","\n","Epoch 00792: val_loss did not improve from 0.18088\n","Epoch 793/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0373 - val_loss: 0.2629 - val_mae: 0.4160\n","\n","Epoch 00793: val_loss did not improve from 0.18088\n","Epoch 794/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0402 - val_loss: 0.2606 - val_mae: 0.4054\n","\n","Epoch 00794: val_loss did not improve from 0.18088\n","Epoch 795/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0423 - val_loss: 0.2704 - val_mae: 0.4188\n","\n","Epoch 00795: val_loss did not improve from 0.18088\n","Epoch 796/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0041 - mae: 0.0369 - val_loss: 0.2667 - val_mae: 0.4164\n","\n","Epoch 00796: val_loss did not improve from 0.18088\n","Epoch 797/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0036 - mae: 0.0329 - val_loss: 0.2609 - val_mae: 0.4078\n","\n","Epoch 00797: val_loss did not improve from 0.18088\n","Epoch 798/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0317 - val_loss: 0.2625 - val_mae: 0.4107\n","\n","Epoch 00798: val_loss did not improve from 0.18088\n","Epoch 799/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0038 - mae: 0.0321 - val_loss: 0.2634 - val_mae: 0.4086\n","\n","Epoch 00799: val_loss did not improve from 0.18088\n","Epoch 800/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0293 - val_loss: 0.2627 - val_mae: 0.4079\n","\n","Epoch 00800: val_loss did not improve from 0.18088\n","Epoch 801/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0336 - val_loss: 0.2634 - val_mae: 0.4026\n","\n","Epoch 00801: val_loss did not improve from 0.18088\n","Epoch 802/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0366 - val_loss: 0.2741 - val_mae: 0.4138\n","\n","Epoch 00802: val_loss did not improve from 0.18088\n","Epoch 803/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0353 - val_loss: 0.2652 - val_mae: 0.4094\n","\n","Epoch 00803: val_loss did not improve from 0.18088\n","Epoch 804/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0337 - val_loss: 0.2624 - val_mae: 0.4058\n","\n","Epoch 00804: val_loss did not improve from 0.18088\n","Epoch 805/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0339 - val_loss: 0.2882 - val_mae: 0.4296\n","\n","Epoch 00805: val_loss did not improve from 0.18088\n","Epoch 806/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0376 - val_loss: 0.2692 - val_mae: 0.4120\n","\n","Epoch 00806: val_loss did not improve from 0.18088\n","Epoch 807/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0334 - val_loss: 0.2527 - val_mae: 0.4034\n","\n","Epoch 00807: val_loss did not improve from 0.18088\n","Epoch 808/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0378 - val_loss: 0.2722 - val_mae: 0.4165\n","\n","Epoch 00808: val_loss did not improve from 0.18088\n","Epoch 809/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0035 - mae: 0.0321 - val_loss: 0.2717 - val_mae: 0.4171\n","\n","Epoch 00809: val_loss did not improve from 0.18088\n","Epoch 810/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0309 - val_loss: 0.2617 - val_mae: 0.4100\n","\n","Epoch 00810: val_loss did not improve from 0.18088\n","Epoch 811/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0333 - val_loss: 0.2645 - val_mae: 0.4106\n","\n","Epoch 00811: val_loss did not improve from 0.18088\n","Epoch 812/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0291 - val_loss: 0.2662 - val_mae: 0.4131\n","\n","Epoch 00812: val_loss did not improve from 0.18088\n","Epoch 813/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0300 - val_loss: 0.2613 - val_mae: 0.4086\n","\n","Epoch 00813: val_loss did not improve from 0.18088\n","Epoch 814/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0296 - val_loss: 0.2676 - val_mae: 0.4128\n","\n","Epoch 00814: val_loss did not improve from 0.18088\n","Epoch 815/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0041 - mae: 0.0353 - val_loss: 0.2654 - val_mae: 0.4117\n","\n","Epoch 00815: val_loss did not improve from 0.18088\n","Epoch 816/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0296 - val_loss: 0.2624 - val_mae: 0.4050\n","\n","Epoch 00816: val_loss did not improve from 0.18088\n","Epoch 817/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0319 - val_loss: 0.2677 - val_mae: 0.4144\n","\n","Epoch 00817: val_loss did not improve from 0.18088\n","Epoch 818/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0343 - val_loss: 0.2598 - val_mae: 0.4034\n","\n","Epoch 00818: val_loss did not improve from 0.18088\n","Epoch 819/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0302 - val_loss: 0.2523 - val_mae: 0.3988\n","\n","Epoch 00819: val_loss did not improve from 0.18088\n","Epoch 820/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0328 - val_loss: 0.2566 - val_mae: 0.4069\n","\n","Epoch 00820: val_loss did not improve from 0.18088\n","Epoch 821/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0041 - mae: 0.0373 - val_loss: 0.2737 - val_mae: 0.4160\n","\n","Epoch 00821: val_loss did not improve from 0.18088\n","Epoch 822/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0341 - val_loss: 0.2731 - val_mae: 0.4145\n","\n","Epoch 00822: val_loss did not improve from 0.18088\n","Epoch 823/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0321 - val_loss: 0.2629 - val_mae: 0.4083\n","\n","Epoch 00823: val_loss did not improve from 0.18088\n","Epoch 824/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0345 - val_loss: 0.2636 - val_mae: 0.4092\n","\n","Epoch 00824: val_loss did not improve from 0.18088\n","Epoch 825/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0318 - val_loss: 0.2639 - val_mae: 0.4063\n","\n","Epoch 00825: val_loss did not improve from 0.18088\n","Epoch 826/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0346 - val_loss: 0.2714 - val_mae: 0.4125\n","\n","Epoch 00826: val_loss did not improve from 0.18088\n","Epoch 827/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0034 - mae: 0.0308 - val_loss: 0.2619 - val_mae: 0.4064\n","\n","Epoch 00827: val_loss did not improve from 0.18088\n","Epoch 828/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0338 - val_loss: 0.2555 - val_mae: 0.4018\n","\n","Epoch 00828: val_loss did not improve from 0.18088\n","Epoch 829/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0317 - val_loss: 0.2779 - val_mae: 0.4225\n","\n","Epoch 00829: val_loss did not improve from 0.18088\n","Epoch 830/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0357 - val_loss: 0.2792 - val_mae: 0.4183\n","\n","Epoch 00830: val_loss did not improve from 0.18088\n","Epoch 831/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0343 - val_loss: 0.2621 - val_mae: 0.4091\n","\n","Epoch 00831: val_loss did not improve from 0.18088\n","Epoch 832/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0343 - val_loss: 0.2636 - val_mae: 0.4135\n","\n","Epoch 00832: val_loss did not improve from 0.18088\n","Epoch 833/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0032 - mae: 0.0308 - val_loss: 0.2618 - val_mae: 0.4076\n","\n","Epoch 00833: val_loss did not improve from 0.18088\n","Epoch 834/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0332 - val_loss: 0.2644 - val_mae: 0.4103\n","\n","Epoch 00834: val_loss did not improve from 0.18088\n","Epoch 835/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0371 - val_loss: 0.2647 - val_mae: 0.4036\n","\n","Epoch 00835: val_loss did not improve from 0.18088\n","Epoch 836/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0342 - val_loss: 0.2466 - val_mae: 0.3984\n","\n","Epoch 00836: val_loss did not improve from 0.18088\n","Epoch 837/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0390 - val_loss: 0.2515 - val_mae: 0.3975\n","\n","Epoch 00837: val_loss did not improve from 0.18088\n","Epoch 838/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0326 - val_loss: 0.2709 - val_mae: 0.4127\n","\n","Epoch 00838: val_loss did not improve from 0.18088\n","Epoch 839/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0311 - val_loss: 0.2577 - val_mae: 0.4038\n","\n","Epoch 00839: val_loss did not improve from 0.18088\n","Epoch 840/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0321 - val_loss: 0.2584 - val_mae: 0.4039\n","\n","Epoch 00840: val_loss did not improve from 0.18088\n","Epoch 841/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0292 - val_loss: 0.2784 - val_mae: 0.4239\n","\n","Epoch 00841: val_loss did not improve from 0.18088\n","Epoch 842/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0368 - val_loss: 0.2685 - val_mae: 0.4113\n","\n","Epoch 00842: val_loss did not improve from 0.18088\n","Epoch 843/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0331 - val_loss: 0.2572 - val_mae: 0.4038\n","\n","Epoch 00843: val_loss did not improve from 0.18088\n","Epoch 844/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0035 - mae: 0.0335 - val_loss: 0.2714 - val_mae: 0.4161\n","\n","Epoch 00844: val_loss did not improve from 0.18088\n","Epoch 845/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0330 - val_loss: 0.2640 - val_mae: 0.4108\n","\n","Epoch 00845: val_loss did not improve from 0.18088\n","Epoch 846/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0331 - val_loss: 0.2626 - val_mae: 0.4095\n","\n","Epoch 00846: val_loss did not improve from 0.18088\n","Epoch 847/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0313 - val_loss: 0.2746 - val_mae: 0.4181\n","\n","Epoch 00847: val_loss did not improve from 0.18088\n","Epoch 848/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0033 - mae: 0.0301 - val_loss: 0.2614 - val_mae: 0.4062\n","\n","Epoch 00848: val_loss did not improve from 0.18088\n","Epoch 849/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0331 - val_loss: 0.2702 - val_mae: 0.4156\n","\n","Epoch 00849: val_loss did not improve from 0.18088\n","Epoch 850/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0035 - mae: 0.0307 - val_loss: 0.2718 - val_mae: 0.4178\n","\n","Epoch 00850: val_loss did not improve from 0.18088\n","Epoch 851/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0324 - val_loss: 0.2761 - val_mae: 0.4173\n","\n","Epoch 00851: val_loss did not improve from 0.18088\n","Epoch 852/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0352 - val_loss: 0.2796 - val_mae: 0.4249\n","\n","Epoch 00852: val_loss did not improve from 0.18088\n","Epoch 853/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0322 - val_loss: 0.2697 - val_mae: 0.4161\n","\n","Epoch 00853: val_loss did not improve from 0.18088\n","Epoch 854/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0314 - val_loss: 0.2614 - val_mae: 0.4084\n","\n","Epoch 00854: val_loss did not improve from 0.18088\n","Epoch 855/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0305 - val_loss: 0.2677 - val_mae: 0.4160\n","\n","Epoch 00855: val_loss did not improve from 0.18088\n","Epoch 856/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0346 - val_loss: 0.2584 - val_mae: 0.4067\n","\n","Epoch 00856: val_loss did not improve from 0.18088\n","Epoch 857/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0313 - val_loss: 0.2520 - val_mae: 0.4008\n","\n","Epoch 00857: val_loss did not improve from 0.18088\n","Epoch 858/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0347 - val_loss: 0.2504 - val_mae: 0.4019\n","\n","Epoch 00858: val_loss did not improve from 0.18088\n","Epoch 859/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0390 - val_loss: 0.2702 - val_mae: 0.4161\n","\n","Epoch 00859: val_loss did not improve from 0.18088\n","Epoch 860/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0350 - val_loss: 0.2705 - val_mae: 0.4157\n","\n","Epoch 00860: val_loss did not improve from 0.18088\n","Epoch 861/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0327 - val_loss: 0.2578 - val_mae: 0.4064\n","\n","Epoch 00861: val_loss did not improve from 0.18088\n","Epoch 862/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0330 - val_loss: 0.2683 - val_mae: 0.4139\n","\n","Epoch 00862: val_loss did not improve from 0.18088\n","Epoch 863/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0338 - val_loss: 0.2754 - val_mae: 0.4188\n","\n","Epoch 00863: val_loss did not improve from 0.18088\n","Epoch 864/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0318 - val_loss: 0.2599 - val_mae: 0.4055\n","\n","Epoch 00864: val_loss did not improve from 0.18088\n","Epoch 865/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0362 - val_loss: 0.2552 - val_mae: 0.4032\n","\n","Epoch 00865: val_loss did not improve from 0.18088\n","Epoch 866/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0341 - val_loss: 0.2517 - val_mae: 0.3980\n","\n","Epoch 00866: val_loss did not improve from 0.18088\n","Epoch 867/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0328 - val_loss: 0.2592 - val_mae: 0.4049\n","\n","Epoch 00867: val_loss did not improve from 0.18088\n","Epoch 868/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0314 - val_loss: 0.2669 - val_mae: 0.4072\n","\n","Epoch 00868: val_loss did not improve from 0.18088\n","Epoch 869/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0327 - val_loss: 0.2652 - val_mae: 0.4089\n","\n","Epoch 00869: val_loss did not improve from 0.18088\n","Epoch 870/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0371 - val_loss: 0.2619 - val_mae: 0.4044\n","\n","Epoch 00870: val_loss did not improve from 0.18088\n","Epoch 871/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0353 - val_loss: 0.2776 - val_mae: 0.4216\n","\n","Epoch 00871: val_loss did not improve from 0.18088\n","Epoch 872/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0351 - val_loss: 0.2688 - val_mae: 0.4146\n","\n","Epoch 00872: val_loss did not improve from 0.18088\n","Epoch 873/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0036 - mae: 0.0342 - val_loss: 0.2681 - val_mae: 0.4109\n","\n","Epoch 00873: val_loss did not improve from 0.18088\n","Epoch 874/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0355 - val_loss: 0.2661 - val_mae: 0.4130\n","\n","Epoch 00874: val_loss did not improve from 0.18088\n","Epoch 875/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0353 - val_loss: 0.2687 - val_mae: 0.4131\n","\n","Epoch 00875: val_loss did not improve from 0.18088\n","Epoch 876/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0320 - val_loss: 0.2880 - val_mae: 0.4293\n","\n","Epoch 00876: val_loss did not improve from 0.18088\n","Epoch 877/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0321 - val_loss: 0.2816 - val_mae: 0.4240\n","\n","Epoch 00877: val_loss did not improve from 0.18088\n","Epoch 878/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0360 - val_loss: 0.2651 - val_mae: 0.4124\n","\n","Epoch 00878: val_loss did not improve from 0.18088\n","Epoch 879/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0330 - val_loss: 0.2790 - val_mae: 0.4225\n","\n","Epoch 00879: val_loss did not improve from 0.18088\n","Epoch 880/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0328 - val_loss: 0.2919 - val_mae: 0.4329\n","\n","Epoch 00880: val_loss did not improve from 0.18088\n","Epoch 881/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0319 - val_loss: 0.2739 - val_mae: 0.4188\n","\n","Epoch 00881: val_loss did not improve from 0.18088\n","Epoch 882/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0315 - val_loss: 0.2703 - val_mae: 0.4165\n","\n","Epoch 00882: val_loss did not improve from 0.18088\n","Epoch 883/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0279 - val_loss: 0.2756 - val_mae: 0.4194\n","\n","Epoch 00883: val_loss did not improve from 0.18088\n","Epoch 884/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0322 - val_loss: 0.2766 - val_mae: 0.4188\n","\n","Epoch 00884: val_loss did not improve from 0.18088\n","Epoch 885/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0319 - val_loss: 0.2691 - val_mae: 0.4129\n","\n","Epoch 00885: val_loss did not improve from 0.18088\n","Epoch 886/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0311 - val_loss: 0.2705 - val_mae: 0.4150\n","\n","Epoch 00886: val_loss did not improve from 0.18088\n","Epoch 887/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0296 - val_loss: 0.2805 - val_mae: 0.4244\n","\n","Epoch 00887: val_loss did not improve from 0.18088\n","Epoch 888/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0304 - val_loss: 0.2717 - val_mae: 0.4171\n","\n","Epoch 00888: val_loss did not improve from 0.18088\n","Epoch 889/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0031 - mae: 0.0310 - val_loss: 0.2719 - val_mae: 0.4172\n","\n","Epoch 00889: val_loss did not improve from 0.18088\n","Epoch 890/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0312 - val_loss: 0.2756 - val_mae: 0.4216\n","\n","Epoch 00890: val_loss did not improve from 0.18088\n","Epoch 891/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0303 - val_loss: 0.2573 - val_mae: 0.4079\n","\n","Epoch 00891: val_loss did not improve from 0.18088\n","Epoch 892/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0347 - val_loss: 0.2776 - val_mae: 0.4236\n","\n","Epoch 00892: val_loss did not improve from 0.18088\n","Epoch 893/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0340 - val_loss: 0.2852 - val_mae: 0.4282\n","\n","Epoch 00893: val_loss did not improve from 0.18088\n","Epoch 894/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0327 - val_loss: 0.2656 - val_mae: 0.4137\n","\n","Epoch 00894: val_loss did not improve from 0.18088\n","Epoch 895/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0339 - val_loss: 0.2741 - val_mae: 0.4219\n","\n","Epoch 00895: val_loss did not improve from 0.18088\n","Epoch 896/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0343 - val_loss: 0.2727 - val_mae: 0.4224\n","\n","Epoch 00896: val_loss did not improve from 0.18088\n","Epoch 897/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0305 - val_loss: 0.2595 - val_mae: 0.4108\n","\n","Epoch 00897: val_loss did not improve from 0.18088\n","Epoch 898/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0317 - val_loss: 0.2728 - val_mae: 0.4200\n","\n","Epoch 00898: val_loss did not improve from 0.18088\n","Epoch 899/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0323 - val_loss: 0.2762 - val_mae: 0.4215\n","\n","Epoch 00899: val_loss did not improve from 0.18088\n","Epoch 900/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0295 - val_loss: 0.2595 - val_mae: 0.4097\n","\n","Epoch 00900: val_loss did not improve from 0.18088\n","Epoch 901/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0329 - val_loss: 0.2737 - val_mae: 0.4207\n","\n","Epoch 00901: val_loss did not improve from 0.18088\n","Epoch 902/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0309 - val_loss: 0.2640 - val_mae: 0.4129\n","\n","Epoch 00902: val_loss did not improve from 0.18088\n","Epoch 903/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0319 - val_loss: 0.2618 - val_mae: 0.4094\n","\n","Epoch 00903: val_loss did not improve from 0.18088\n","Epoch 904/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0341 - val_loss: 0.2631 - val_mae: 0.4114\n","\n","Epoch 00904: val_loss did not improve from 0.18088\n","Epoch 905/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0035 - mae: 0.0353 - val_loss: 0.2540 - val_mae: 0.4033\n","\n","Epoch 00905: val_loss did not improve from 0.18088\n","Epoch 906/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0324 - val_loss: 0.2571 - val_mae: 0.4071\n","\n","Epoch 00906: val_loss did not improve from 0.18088\n","Epoch 907/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0307 - val_loss: 0.2603 - val_mae: 0.4106\n","\n","Epoch 00907: val_loss did not improve from 0.18088\n","Epoch 908/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0346 - val_loss: 0.2700 - val_mae: 0.4155\n","\n","Epoch 00908: val_loss did not improve from 0.18088\n","Epoch 909/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0319 - val_loss: 0.2649 - val_mae: 0.4125\n","\n","Epoch 00909: val_loss did not improve from 0.18088\n","Epoch 910/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0328 - val_loss: 0.2642 - val_mae: 0.4108\n","\n","Epoch 00910: val_loss did not improve from 0.18088\n","Epoch 911/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0340 - val_loss: 0.2723 - val_mae: 0.4192\n","\n","Epoch 00911: val_loss did not improve from 0.18088\n","Epoch 912/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0314 - val_loss: 0.2685 - val_mae: 0.4118\n","\n","Epoch 00912: val_loss did not improve from 0.18088\n","Epoch 913/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0308 - val_loss: 0.2675 - val_mae: 0.4128\n","\n","Epoch 00913: val_loss did not improve from 0.18088\n","Epoch 914/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0296 - val_loss: 0.2732 - val_mae: 0.4158\n","\n","Epoch 00914: val_loss did not improve from 0.18088\n","Epoch 915/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0340 - val_loss: 0.2532 - val_mae: 0.4049\n","\n","Epoch 00915: val_loss did not improve from 0.18088\n","Epoch 916/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0038 - mae: 0.0343 - val_loss: 0.2651 - val_mae: 0.4140\n","\n","Epoch 00916: val_loss did not improve from 0.18088\n","Epoch 917/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0371 - val_loss: 0.2772 - val_mae: 0.4251\n","\n","Epoch 00917: val_loss did not improve from 0.18088\n","Epoch 918/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0354 - val_loss: 0.2571 - val_mae: 0.4086\n","\n","Epoch 00918: val_loss did not improve from 0.18088\n","Epoch 919/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0361 - val_loss: 0.2656 - val_mae: 0.4136\n","\n","Epoch 00919: val_loss did not improve from 0.18088\n","Epoch 920/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0331 - val_loss: 0.2935 - val_mae: 0.4381\n","\n","Epoch 00920: val_loss did not improve from 0.18088\n","Epoch 921/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0337 - val_loss: 0.2713 - val_mae: 0.4182\n","\n","Epoch 00921: val_loss did not improve from 0.18088\n","Epoch 922/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0328 - val_loss: 0.2712 - val_mae: 0.4206\n","\n","Epoch 00922: val_loss did not improve from 0.18088\n","Epoch 923/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0369 - val_loss: 0.2767 - val_mae: 0.4242\n","\n","Epoch 00923: val_loss did not improve from 0.18088\n","Epoch 924/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0339 - val_loss: 0.2703 - val_mae: 0.4199\n","\n","Epoch 00924: val_loss did not improve from 0.18088\n","Epoch 925/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0330 - val_loss: 0.2765 - val_mae: 0.4250\n","\n","Epoch 00925: val_loss did not improve from 0.18088\n","Epoch 926/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0328 - val_loss: 0.2878 - val_mae: 0.4323\n","\n","Epoch 00926: val_loss did not improve from 0.18088\n","Epoch 927/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0330 - val_loss: 0.2714 - val_mae: 0.4195\n","\n","Epoch 00927: val_loss did not improve from 0.18088\n","Epoch 928/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0340 - val_loss: 0.2729 - val_mae: 0.4210\n","\n","Epoch 00928: val_loss did not improve from 0.18088\n","Epoch 929/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0325 - val_loss: 0.2660 - val_mae: 0.4174\n","\n","Epoch 00929: val_loss did not improve from 0.18088\n","Epoch 930/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0315 - val_loss: 0.2603 - val_mae: 0.4116\n","\n","Epoch 00930: val_loss did not improve from 0.18088\n","Epoch 931/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0322 - val_loss: 0.2617 - val_mae: 0.4118\n","\n","Epoch 00931: val_loss did not improve from 0.18088\n","Epoch 932/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0302 - val_loss: 0.2670 - val_mae: 0.4149\n","\n","Epoch 00932: val_loss did not improve from 0.18088\n","Epoch 933/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0326 - val_loss: 0.2550 - val_mae: 0.4057\n","\n","Epoch 00933: val_loss did not improve from 0.18088\n","Epoch 934/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0337 - val_loss: 0.2498 - val_mae: 0.4024\n","\n","Epoch 00934: val_loss did not improve from 0.18088\n","Epoch 935/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0354 - val_loss: 0.2862 - val_mae: 0.4297\n","\n","Epoch 00935: val_loss did not improve from 0.18088\n","Epoch 936/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0044 - mae: 0.0406 - val_loss: 0.2675 - val_mae: 0.4136\n","\n","Epoch 00936: val_loss did not improve from 0.18088\n","Epoch 937/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0389 - val_loss: 0.2495 - val_mae: 0.3981\n","\n","Epoch 00937: val_loss did not improve from 0.18088\n","Epoch 938/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0045 - mae: 0.0409 - val_loss: 0.2742 - val_mae: 0.4193\n","\n","Epoch 00938: val_loss did not improve from 0.18088\n","Epoch 939/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0431 - val_loss: 0.2802 - val_mae: 0.4244\n","\n","Epoch 00939: val_loss did not improve from 0.18088\n","Epoch 940/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0354 - val_loss: 0.2602 - val_mae: 0.4050\n","\n","Epoch 00940: val_loss did not improve from 0.18088\n","Epoch 941/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0400 - val_loss: 0.2809 - val_mae: 0.4266\n","\n","Epoch 00941: val_loss did not improve from 0.18088\n","Epoch 942/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0042 - mae: 0.0404 - val_loss: 0.2842 - val_mae: 0.4275\n","\n","Epoch 00942: val_loss did not improve from 0.18088\n","Epoch 943/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0337 - val_loss: 0.2602 - val_mae: 0.4039\n","\n","Epoch 00943: val_loss did not improve from 0.18088\n","Epoch 944/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0038 - mae: 0.0372 - val_loss: 0.2668 - val_mae: 0.4103\n","\n","Epoch 00944: val_loss did not improve from 0.18088\n","Epoch 945/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0328 - val_loss: 0.2737 - val_mae: 0.4184\n","\n","Epoch 00945: val_loss did not improve from 0.18088\n","Epoch 946/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0367 - val_loss: 0.2600 - val_mae: 0.4056\n","\n","Epoch 00946: val_loss did not improve from 0.18088\n","Epoch 947/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0322 - val_loss: 0.2678 - val_mae: 0.4080\n","\n","Epoch 00947: val_loss did not improve from 0.18088\n","Epoch 948/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0345 - val_loss: 0.2558 - val_mae: 0.4015\n","\n","Epoch 00948: val_loss did not improve from 0.18088\n","Epoch 949/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0344 - val_loss: 0.2641 - val_mae: 0.4095\n","\n","Epoch 00949: val_loss did not improve from 0.18088\n","Epoch 950/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0310 - val_loss: 0.2592 - val_mae: 0.4082\n","\n","Epoch 00950: val_loss did not improve from 0.18088\n","Epoch 951/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0339 - val_loss: 0.2592 - val_mae: 0.4044\n","\n","Epoch 00951: val_loss did not improve from 0.18088\n","Epoch 952/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0351 - val_loss: 0.2642 - val_mae: 0.4117\n","\n","Epoch 00952: val_loss did not improve from 0.18088\n","Epoch 953/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0377 - val_loss: 0.2558 - val_mae: 0.4070\n","\n","Epoch 00953: val_loss did not improve from 0.18088\n","Epoch 954/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0309 - val_loss: 0.2622 - val_mae: 0.4123\n","\n","Epoch 00954: val_loss did not improve from 0.18088\n","Epoch 955/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0317 - val_loss: 0.2604 - val_mae: 0.4112\n","\n","Epoch 00955: val_loss did not improve from 0.18088\n","Epoch 956/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0353 - val_loss: 0.2617 - val_mae: 0.4112\n","\n","Epoch 00956: val_loss did not improve from 0.18088\n","Epoch 957/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0332 - val_loss: 0.2593 - val_mae: 0.4083\n","\n","Epoch 00957: val_loss did not improve from 0.18088\n","Epoch 958/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0337 - val_loss: 0.2571 - val_mae: 0.4065\n","\n","Epoch 00958: val_loss did not improve from 0.18088\n","Epoch 959/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0031 - mae: 0.0313 - val_loss: 0.2604 - val_mae: 0.4073\n","\n","Epoch 00959: val_loss did not improve from 0.18088\n","Epoch 960/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0311 - val_loss: 0.2627 - val_mae: 0.4098\n","\n","Epoch 00960: val_loss did not improve from 0.18088\n","Epoch 961/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0308 - val_loss: 0.2627 - val_mae: 0.4087\n","\n","Epoch 00961: val_loss did not improve from 0.18088\n","Epoch 962/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0300 - val_loss: 0.2647 - val_mae: 0.4102\n","\n","Epoch 00962: val_loss did not improve from 0.18088\n","Epoch 963/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0310 - val_loss: 0.2775 - val_mae: 0.4213\n","\n","Epoch 00963: val_loss did not improve from 0.18088\n","Epoch 964/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0314 - val_loss: 0.2625 - val_mae: 0.4090\n","\n","Epoch 00964: val_loss did not improve from 0.18088\n","Epoch 965/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0327 - val_loss: 0.2624 - val_mae: 0.4098\n","\n","Epoch 00965: val_loss did not improve from 0.18088\n","Epoch 966/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0308 - val_loss: 0.2672 - val_mae: 0.4149\n","\n","Epoch 00966: val_loss did not improve from 0.18088\n","Epoch 967/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0028 - mae: 0.0293 - val_loss: 0.2723 - val_mae: 0.4175\n","\n","Epoch 00967: val_loss did not improve from 0.18088\n","Epoch 968/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0297 - val_loss: 0.2712 - val_mae: 0.4163\n","\n","Epoch 00968: val_loss did not improve from 0.18088\n","Epoch 969/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0308 - val_loss: 0.2667 - val_mae: 0.4117\n","\n","Epoch 00969: val_loss did not improve from 0.18088\n","Epoch 970/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0303 - val_loss: 0.2675 - val_mae: 0.4119\n","\n","Epoch 00970: val_loss did not improve from 0.18088\n","Epoch 971/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0308 - val_loss: 0.2662 - val_mae: 0.4131\n","\n","Epoch 00971: val_loss did not improve from 0.18088\n","Epoch 972/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0327 - val_loss: 0.2715 - val_mae: 0.4170\n","\n","Epoch 00972: val_loss did not improve from 0.18088\n","Epoch 973/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0309 - val_loss: 0.2789 - val_mae: 0.4207\n","\n","Epoch 00973: val_loss did not improve from 0.18088\n","Epoch 974/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0299 - val_loss: 0.2585 - val_mae: 0.4072\n","\n","Epoch 00974: val_loss did not improve from 0.18088\n","Epoch 975/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0298 - val_loss: 0.2551 - val_mae: 0.4074\n","\n","Epoch 00975: val_loss did not improve from 0.18088\n","Epoch 976/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0032 - mae: 0.0327 - val_loss: 0.2754 - val_mae: 0.4230\n","\n","Epoch 00976: val_loss did not improve from 0.18088\n","Epoch 977/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0332 - val_loss: 0.2705 - val_mae: 0.4194\n","\n","Epoch 00977: val_loss did not improve from 0.18088\n","Epoch 978/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0297 - val_loss: 0.2607 - val_mae: 0.4125\n","\n","Epoch 00978: val_loss did not improve from 0.18088\n","Epoch 979/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0292 - val_loss: 0.2629 - val_mae: 0.4142\n","\n","Epoch 00979: val_loss did not improve from 0.18088\n","Epoch 980/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0319 - val_loss: 0.2715 - val_mae: 0.4173\n","\n","Epoch 00980: val_loss did not improve from 0.18088\n","Epoch 981/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0031 - mae: 0.0320 - val_loss: 0.2667 - val_mae: 0.4119\n","\n","Epoch 00981: val_loss did not improve from 0.18088\n","Epoch 982/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0303 - val_loss: 0.2643 - val_mae: 0.4107\n","\n","Epoch 00982: val_loss did not improve from 0.18088\n","Epoch 983/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0314 - val_loss: 0.2655 - val_mae: 0.4109\n","\n","Epoch 00983: val_loss did not improve from 0.18088\n","Epoch 984/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0299 - val_loss: 0.2620 - val_mae: 0.4086\n","\n","Epoch 00984: val_loss did not improve from 0.18088\n","Epoch 985/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0028 - mae: 0.0289 - val_loss: 0.2779 - val_mae: 0.4223\n","\n","Epoch 00985: val_loss did not improve from 0.18088\n","Epoch 986/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0302 - val_loss: 0.2780 - val_mae: 0.4211\n","\n","Epoch 00986: val_loss did not improve from 0.18088\n","Epoch 987/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0303 - val_loss: 0.2685 - val_mae: 0.4158\n","\n","Epoch 00987: val_loss did not improve from 0.18088\n","Epoch 988/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0301 - val_loss: 0.2720 - val_mae: 0.4180\n","\n","Epoch 00988: val_loss did not improve from 0.18088\n","Epoch 989/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0303 - val_loss: 0.2712 - val_mae: 0.4167\n","\n","Epoch 00989: val_loss did not improve from 0.18088\n","Epoch 990/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0028 - mae: 0.0299 - val_loss: 0.2638 - val_mae: 0.4114\n","\n","Epoch 00990: val_loss did not improve from 0.18088\n","Epoch 991/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0292 - val_loss: 0.2713 - val_mae: 0.4175\n","\n","Epoch 00991: val_loss did not improve from 0.18088\n","Epoch 992/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0256 - val_loss: 0.2729 - val_mae: 0.4179\n","\n","Epoch 00992: val_loss did not improve from 0.18088\n","Epoch 993/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0029 - mae: 0.0300 - val_loss: 0.2717 - val_mae: 0.4176\n","\n","Epoch 00993: val_loss did not improve from 0.18088\n","Epoch 994/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0027 - mae: 0.0286 - val_loss: 0.2747 - val_mae: 0.4195\n","\n","Epoch 00994: val_loss did not improve from 0.18088\n","Epoch 995/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0285 - val_loss: 0.2707 - val_mae: 0.4165\n","\n","Epoch 00995: val_loss did not improve from 0.18088\n","Epoch 996/1000\n","350/350 [==============================] - 1s 4ms/step - loss: 0.0026 - mae: 0.0267 - val_loss: 0.2688 - val_mae: 0.4141\n","\n","Epoch 00996: val_loss did not improve from 0.18088\n","Epoch 997/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0321 - val_loss: 0.2776 - val_mae: 0.4203\n","\n","Epoch 00997: val_loss did not improve from 0.18088\n","Epoch 998/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0031 - mae: 0.0324 - val_loss: 0.2632 - val_mae: 0.4107\n","\n","Epoch 00998: val_loss did not improve from 0.18088\n","Epoch 999/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0313 - val_loss: 0.2738 - val_mae: 0.4195\n","\n","Epoch 00999: val_loss did not improve from 0.18088\n","Epoch 1000/1000\n","350/350 [==============================] - 1s 3ms/step - loss: 0.0028 - mae: 0.0285 - val_loss: 0.2813 - val_mae: 0.4240\n","\n","Epoch 01000: val_loss did not improve from 0.18088\n"]}],"source":["# Use the final model to get a single output\n","epochs = 1000\n","batch_size = 150\n","history = model.fit([seq_train, vae_train], y_train, batch_size=batch_size, epochs=epochs, callbacks=[checkpoint], validation_data=([seq_test, vae_test], y_test))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB/9klEQVR4nO3dd3hTZfsH8G+StukupaWDVVqG7NWyh6LIUBREBRHBASIiCPI6Xl7EwauiP0VQERQX+ipD3AOFokyLgEAZUtlQRktpoXsn5/fHIelJcrLTnJR+P9fVq83JycmT0zbnzv3cz/OoBEEQQERERFSPqJVuABEREZG3MQAiIiKieocBEBEREdU7DICIiIio3mEARERERPUOAyAiIiKqdxgAERERUb3jp3QDfJFer8eFCxcQFhYGlUqldHOIiIjIAYIgoKioCI0bN4ZabTvHwwBIxoULF9CsWTOlm0FEREQuOHv2LJo2bWpzHwZAMsLCwgCIJzA8PFzh1hAREZEjCgsL0axZM+N13BYGQDIM3V7h4eEMgIiIiOoYR8pXWARNRERE9Q4DICIiIqp3GAARERFRvaN4ALR06VIkJiYiMDAQycnJ2LZtm9V9t2/fjn79+iEqKgpBQUFo27YtFi1aZLHf119/jfbt20Or1aJ9+/b49ttva/MlEBERUR2jaAC0Zs0azJo1C3PnzsW+ffswYMAADB8+HJmZmbL7h4SEYPr06di6dSsyMjLw7LPP4tlnn8Xy5cuN++zYsQNjx47FhAkTsH//fkyYMAFjxozBzp07vfWyiIiIyMepBEEQlHryXr16oXv37li2bJlxW7t27TBq1CgsWLDAoWOMHj0aISEh+N///gcAGDt2LAoLC/HLL78Y9xk2bBgiIyOxatUq2WNUVFSgoqLCeNswjK6goICjwIiIiOqIwsJCREREOHT9ViwDVFlZiT179mDIkCEm24cMGYK0tDSHjrFv3z6kpaXh+uuvN27bsWOHxTGHDh1q85gLFixARESE8YuTIBIREV3bFAuAcnNzodPpEBsba7I9NjYW2dnZNh/btGlTaLVapKSk4LHHHsPkyZON92VnZzt9zDlz5qCgoMD4dfbsWRdeEREREdUVik+EaD5ZkSAIdicw2rZtG4qLi/Hnn3/i3//+N1q1aoVx48a5fEytVgutVutC64mIiKguUiwAio6OhkajscjM5OTkWGRwzCUmJgIAOnXqhIsXL+KFF14wBkBxcXEuHZOIiIjqD8W6wAICApCcnIzU1FST7ampqejbt6/DxxEEwaSAuU+fPhbH3LBhg1PHJCIiomubol1gs2fPxoQJE5CSkoI+ffpg+fLlyMzMxNSpUwGItTnnz5/HZ599BgB499130bx5c7Rt2xaAOC/QG2+8gRkzZhiPOXPmTAwcOBCvvfYaRo4cie+//x4bN27E9u3bvf8CiYiIyCcpGgCNHTsWeXl5mD9/PrKystCxY0esW7cOCQkJAICsrCyTOYH0ej3mzJmDU6dOwc/PDy1btsSrr76KRx55xLhP3759sXr1ajz77LOYN28eWrZsiTVr1qBXr15ef31EREQ+obIUCAhWuhU+RdF5gHyVM/MIEBER+bSTm4HPRgLX/xsYNEfp1tSqOjEPEBEREdkgCEDuMUCvd+84654Sv2951f02XUMYABEREfmiP5cBS1KAn2e7eSDbU8vUVwyAiIiIfNHv/xW/7/nEvePYmVuvvmIARERE5IsEN7u+jBgAyWEAREREZM4Xxgd5KgBiBkgWAyBfdOU0kL4K0FUr3RIiovonPxNY1AHY9qYyz19ZAqyZAOgqPXRASQCUewxIWwJUlXvo2HWX4muBkYy3uojfKwqBXo/Y3peIiDzr95eBwvPAby8CA9wtQHbB7g+BjB88dzxpBmhJivi9ohAY9B/PPUcdxAyQLzu9TekWEBHVP4JO2ecvL/TwAWW6wM7uFL9n7Qd+egIovuTh5/R9zAD5MpVG6RYQEdU/KoVzA/ZmbC44Dxz6Gug+AQiKtH88uRIgw2t8f6D4vSgbGLfKqWbWdQyAfJnS/4RERPWR0u+9/iG2719xi1grmrUfuOsjBw4oEwGZf8DOPghUV4izRif0A7ShDja27uIV1pepGZ8SEXmfwqOm/INs33/ltPj95CbHjic3CkxtFgAJemDDs8DKMcCPMx07bh3HAMiXmf+BEhFR7VM6A+TosHW/QEcPKLPJ7Pqi1wG7los/H/rKwePWbQyAfJnS/4RERPWR0vPm6Koc208T4PpzmL9GbxZ+V1cApZcdf521hFdYX8YAiIjI+3w1ADKfu8fRDJDc6zG/vuglAVBorGPHddXJLcD/JQIf3lS7z2MHi0x8GbvAiIi8r7Y+fOqqxK4ntZ3j62UCoNzjwNJeQMpDNdv8tA4+sQM1QGWXa34OiXHwuC6qLBK/B4TV7vPYwRSDL+MweCIi73P2vffP94Ad79rep6oceKc7sOJW+8eTywBtfR3QV9fU6QBuZoBsvEaNk7kRXTVwJk3s2nJExdUASMsAiKxhFxjRtSf/rGl3A1lXVSYuC+FtznSB5R4Dfn0GWP8fsb0GmxYAf7xdc/vsn+ISG5lpgN7OGl96mWWQ5K4HnswA2dvflt/nA58Mtxw9VpYPXDxsua5aRbH4XeGh9rzC+jJ2gRFdWzJ+BBZ3BL6erHRLnOfO4qDn/gJWjACyDjj+GL0eeL018GpzxzMLniINNuwFqyd+r/m5+mqNTsF5YMurQOq8mmyOdHbnakmgJHXpKPDVJODiIdttMnAkA1RZCuQds7+fM/58D9j6Rs3tP94Sv++XTKRYXSlmvJb1Af75qWb7sVRgw1zxZ2aAyCp2gRFdWwyLa/79jbLtcFbuceCNNkDaO649/uOh4tI+/7vD8cdUlYq1IvpqcV0ub5IGG/ZGKpXkWu4rXcTUEBSVF9RsqyyVP9YXd4pD0A9/b3lf+ueW2zT+YqBoK0v24WDT5zZvqxxbGTBdtZjx+v2/QOEF6/uVXQZK88Sfc/6p2f7FXTU/BzADRFLS1Ki9Qjkiqlvqarf2L08BJTniRHmuMHTplOba3k9K2p1kr8vI4yQBgL0V2aXdVYZ9pb9nw+sovijZJglYii7W1MTkZzrf1BW3AG9cB5Rdkb8/52/57a6uNF8tGYlWJZPJMmTrpMevshLwacNda4OH1NH/xmuYtPpf7s0yJwPI3Om99hCR5zjSrV1VBmxfbPqp2RtyjwGXjsjfV3pZfrsrSvIc208aJFi7gNYWaQZErh5HSi4Akm6rKgUu/g3kn5FsMwRFl4CFbYA3O7jWTn01kLlDzJSd2urcY20GQDYyQPa6I9/qevX4kmuZ4feXk2G6L2uAyIT0j8a8C0wQgKW9gY+H1MuVe+kaU11hv67kWKp4Yb5WOJIB2vYmsPF5ccizPXqdZyaT01UBS1KAd3vKd6cYMhSesLiT5baLfwNLegAHJTMQS7uJvBkAnd0F/Lm05rZcoFCSW5NxMQmAqiy37V8NLOsL7P2sZpvhtZ39U/xeIdNF5Yijv9b87Gx20VYAlJ9pPVCVZoDk6qOKLogZO2mgVFkinpulvU33ZRcYmbCVAZKmOMvzvdIc8lFF2cDlk0q3wnVFF8Xi1m8etr7PuT1ivcCSFO+1q7Y5cpG6sM/x4y2/HljUQSw4dUdlcc3PpTIXPmkA9N1jwMYXXX+uKpkAa+MLQO5R4OtJkv0k3SvS9tW2j242vW0eKFSWAu8ki1mb0svyGSBpUCo3PN5wDjxZ3L3mvprRVYD44eK3/1rf/+Rm6x9ASnKA15Pk79NVyP8sVZ5v1gVWBpzbbbkfM0BkQmclADq3B/h5ds1tjhCz7fJJcTSFM6NO6pKF1wFvd/Ns14Q37f1U/CR5cK31fbL3e6893uJIAOTI0ObqSvHilX1QrC3JOexeu6QzDBsuyln7gY+HAZl/mgZA6Z8D2990b1SYOemSDobjSgMlJYbCG/z9nent0lzxAl9VAhz+zvQ925gBkun+kTJkgEyyKXpA7e9eWw0fivLPAkv7ANvesL3/ub+cfw5p0LblNeDoBst9SnJNz8vFQ+IweXP2Vr2vZQyAfI30j0aQFP59eCPw97c1t71eFFjHrLpXHE2x/AalW1K7PN095K2/K0e6NOrqKMj9aywvmgbSAMhaF4O99Z02vwq81MjsE7WbwYj093Fys5hhXD1erC/5eKj8sG17tTHOiGxR83PJ1e59kwyQjb8XvU78oOPK3ErVlfYflzoP2Pu/mtvS9+hD3wB7PrG8T7qP3HmSywDpKt1b2wuoWc/r+2nApQzb+wLAhb12jifzdyUN2jJ+BFbebbnP/0YB//xYc/uSlXo2f0cXc60dDIB8jd5KAGSxnwfffK5Fhn9+by7w5y3SNyW5KfNddeWMmPa2lTb3FLnRI+bq4oipkjzg2ynA2vvlu6Wkr+n1JPn6HVtzuxz5Fdi8QPxZmhF2lzQAWvck8GY7+a4wKVdHEQGmf8M5GcCOJTW3y/LF79Ksj60usI0vAO8PAH5zsluuuhJ4q7PYjXjxMHDgS+tZrWPra36Wvu7T20z301WK2XrzbjRzlaVilkbalairdH4GZnOGDzDmxcbW2JtHSO537Ei3XeH5mrmBbPEPtr9PLaqD7zDXOJ0ksBF04j/k+rmW+12LF3aPUngxw9ok/cRq/gaVtR9Y97TjI22ktrwm1pnZS5u768ivwM73rN8vCFe7A+pYBujSUXHiNwO5LJd5UCedHA8QR2HtXyl//IoiYNXYmtvZB2t+ttUdVV4I7PnUdnepeUAq6O1n6dypX5EGft9NM73P0N0mbZOttqRdnW1ZesEVBHGyyd9fsv64SxlAUZZ4Hpf1EevRpEXFJu2VqfOR3a/Sdl2bQVWpOCGmtPhZV+V+F5iuQgwIDVk0eyoKbd8v9zuWZoDc5ehSHrWEi6H6Guk/l6AXU5TST0cGzADZplJ5tkbBU/Q6YOVYILo1MGyBa8eQBr86s7+D9weK30tzgbs+du643loBW3oRB8Tfk0olFnD6BwHfTAHO7QL6z7bcx5d9N9V0cEJVKRDUwHQf86DOPIP3bk/5Y188bLs2KPcY0Lib/Dn68XGx+/zgWuAByYy8giAGDbEdxAn1nJX2DtDhDiC+s/OP1VUAfle7e8y7YQxBgTTocbYG6NxfNfVll08CHe8C2t5y9VilwPZFQIPmlo87tc1yG2D6ezL/n5NydESe3OvRVVj/PfgFOhZ4VF19bdYMeQm4fEoscs74UX6CRJM2uZgBcpR/kOeO5QJmgHyN9B9Nr7f+B6rEWkK+GFDUNWd3AsdTxWG2eSdcO4Y0+LXWBZYtM5W+PWqFPg+9013sDljQBPjgRrF2Kz8TOCrpdqgLAb90RmBAvpvPPANkryuwulKc32VZH2D5IOv7fTsFeLGBfO2RoXbQvLvmzB/icPsv7nKsS9Lc9jfFrid7bE2WJ8eQFZMGCeUF4vILF61M6ieVexz49Laa24e+BlaPA05sEm9vWwhs/T/gh+kyz50vf0xdlfj/mp9pu+BcX+VY1+0/P8s8RyUQYKUo+MmjQIMEoOt9to9r7/cY2xEY8SbQqK14214AJFe7404A1PJG09sMgMiENLCxVQMkvS8nA7iQXmtNAgAU54jDbX+bX7vP4zEeyBa4G/Dt+kB8s5WSfqJ6p7v1T5y22OoCMzAEM7oqcSTPTw7Ui7hadFxV5l7x9OWTYtEmAGSl12w/+kvNz67UmxzdIHaBeKuw2/zvRe5TvvnF0d7F5O1u4gUccGyumLX317SlLN80iDQnDdjsXQjdkfGT5bbti6xP42DoApPWIO18X1x+YVlf+8/35QT5ou3/jRIDGGnXoTlr5+HiIfH/dXEn+cDJQFfpWNfteZnRVxf/BvKOy+8fGAHMOgCMsrPivK1icaDmfSEwQvye8aP1fQH5levdCYDiuwJtJKPBFO4CYwDka0wCIJ31i7DhE7FeL04utfz6muJBqZx/gL8+cT9j9MdbYmGb+QXdF1WVu18jtfN94PWWYteDK/R6sZj0t/lm09ubBWb7Vzt/bJMuMCsZIMMyKqe3iSN5/vrI/nFdqbkpzgFejgPmRwKbXnH+8UZ2AlZXAqCVdwNbXxdfu61g1hMTCQKWH1jM61aunAGOrDPdZq9bo/CcZZ2QI35/CXgtAVg5xvo+0ovPldPOP4ejDAtxdptQM/HdjiXW/14qCsWLrKG2B4BDo9wMAbytDE1Ohu33BmsBkL2CcANdle0PEgE2Fv9cfa9jz2GLvbotw/+4IQAqynL+OZytAWo1uOZnlaqmKxJgETSZEcwyQFYDoKv75Z+u2Sb9Jy3KvjpzdC/gp1lAupXCSkcp0eXmKkc+Jdrzy9Pi+fzpCdcebz4JmC0F58Xfl6McyQDJvQnby4S4kgE68GXNz1teE79XlYmTsu2TWbzRGnvdb85O9Cc9R+ueBDa9LL/f948BryY4d/4NBMFy0IKUeQboLZlaGcPF5MCXYtAtx9nJ4r6c6Fghu/Ri6Wp3LCBmHT65FfjhcfE171wudmn+8Tbwz7qaCVxDY0zrmOS6gQAxA7RnhfPtcGQI+coxwPGN1u+3VxRsj67SdhdYSJR7x7fHXvvNM0CucDYAMg9ypP+bjsx5VYtYBO1rpH8ceh2sfvI5v0dMl/74eM02Q3S/+yNxiOz1/66578JeoPsEjzfXZ+j14kU3oglw2Y03c4vjupgdkM6QausNsaoUWNRe/Pm5y/JZmNzjQGRCTYGk9G/EWjparREzTz8/WbOtPB8Ibmi9La5kgOSKbv/6WEytZ/wIdLNTs+DoczubASrOMb299XUgug2Q8QMw6r2aoMIQpK25DwhvAtw4D4huZXm8qnIxe5N0Q805XDVOXGjysV1iLYOtDJC1DxAfDxVrO6TrRJlzdm4YuZXEDXRVNX9H0gDNWteLIw6sAc5sF7/2fipu++Wpmvs7Xc1CBUWaZrMatZUPbAsvuNYeXaU4/5c75LLozlj3tHz3m4Gji3/2miqOSHM2M2cvU2UIgJxZhLQwS3w/M8zVZP6e88A64MRv1nsHCs+b3pb+nyg8sIEZIF/jaAYodZ5p8APA2I1gmB9ky6uSu9wdUuzjBdBZ6cCRn4Fdyz17XLkLlyM1JY52W0iHq8oFM4d/AJYkA2sfqNkm/Rux9mlM7ScOA5YGg/+XKD+lgoE0UHM04ycX3FlbldoWW/VugPMBkPmbLiAOT874UbxIXzoqjjYzOLdbnNXXfITa0fXAkV/E0XVfPSgWDBvv+0UMMg2LUJqfM0M9xuHvgQXNrLfVVvADeHZCyM9G1vwsDdAKL4jfmyQ7f0x7k+kdvJolDGxgOc/ZVw9a7r/3U3FZDGusZQMFnfge4A57vwt7bAU/AKC10QUmlfwAMPl3cfTaRBsBrTl7018Ynt+ZDNCbbYG3utT8Xxv+VgxCGgEdRttok9ngAHv/617EAMjXSN9E934KbLBxwTJnq29biTlVdFXAynvExR1rmyeHZkqZn9N1T4tvCLYWo806IM7xYWCo18o6AHx2u+m+0k9Achd5w6KM/0gKSU1Wmrbyhqv2kx8JJjelgvQxBo6eT7kASO6CXVEk/i1Iu8yk7AU4tpbMMCgvANKWiF2KxRet71eaB7zbQ8xcmJNmHnL+EbtMVt0D5F5dJf38HvG7NAg2vF6LDNDVDMuXE+XXv3KUJ+ddOfNHzc/SyQWLr3YBJt0gBirOuGQjWJEKijS9XV1u+nctlWVjGZTCc2LXWnVF3eqaBxyf3FMTIHaX3fWR+DtxVLqk23ng05b3G0aZudIFduW0+H7zp1khdnCU7WkUSi4BjdqJP3e4w/3Zrj2IAZCvMb/g2vokZM7Wm4ESywpk/Ch+SnZ2hlZX1NYwaZNZl3XArvfFi+tfNubYMZ98zVBku2qc5b7SN0S5IEButWS9Axkgldr6kFprpEGy3HErSywDI9kASGbb1jfEvwVrk8TZq/HZvMB27QYgdvdtmAusuMV20ODonDKGoEeO9JN+SQ6Qvsry3LgytFyOp1dC11UDJ7fIj+jUhjt/gTKsaG6P+UXX/HWFxVs+JvkBy21f3C0Oa/9tvmdXqfcGR7Mf7s6CHhID3Cjz4dkYADVw/pjLb6iZhVwqqIHtGr6qUmDKJmDmfiCuE9B5DNCsl2mJhkIYAPkad4bs/rHYdDVgKSUyQOYXGkEQi4q3L/b8c3liZuzCLHH9o5NbJMe9+vvY/ZFZN4ZZl+CRX4G9n4k/m78ZvD8AOL9XvFCas1fPI5cyl76J2soAWQuAjvxi+hqNx5W8JrmL+avNgUUdTbfL9eHLdaXZq8tyJENyZoft+49dXZTxymnbAZWjGRVbI8ek5/27R8VJEM1fgytdgXLsDW12+nhFlplIg8AI2xez0R+4/rzBZgXAVWa/hyf+BnqbzQotXSPMwJCl27FEfoFNd/kFAoNfsL9ffBfgZienBXF0wklnanTkWJtfx7D4aKCLxzfOtq0CkgYBNz0nXlvkXlfnq93J/Z8Q22P4XfoHAZM2AIPmuNYGD2IA5GvcuZDv+9x6l5m7AZD5xaC6QkxT27pImH/ayUoXMycbn3evLXLcTYXv/Z/YtfXPT8AaSbG44bg/zza9wJl/Qls1FvhhBrC4s3zhovl0/+bHB+QzQNIRQIaLujTbtWNJzRIH0mOpNfLZI0Ds0vnsdstzJq3PMK9lyDsuPm9JjlgXU5hl+ZwG0qDIEATbm2fGkZope5kb6ZuwzkYXnr3nMq5ubeNv25Es0tbXxd+NuxNM2loHyxXW/hYB8cJoq72dxwAtHJj80NzgF4DY9sCdHwGRieI28w8Eao1p9sk/WLzI2mJryLur7vtavGg3SKjZFhorfk+8vmZb9HWm+9xiY+Rdl3uB2E7A6A/tP//EH9wfLWbtw49hrTFXZv6Wuv0dYOJ3wIB/ibfllvAYuRSYslkcWOCjGAD5Gne7ck78Lr/d011gq8eLhaG2uoKkFxDzIcO2ppN3hSsBUNkVsWsmP9N0cjPphHPWUtbSi7w0CMw/I44MsmBnPidAPgDyk3ySMxRMm7/WX54Rv0uzEiqN/eHT5t0H0t+JRTZK8npXjgGWpFzdz+xTvCDA5LUaujnsja5xpPhULhA4/htwJu3q2mHSAMjG6D1rs/0arLxbfB02M0AOZmX+eKvmU7er3OlKu+4Wy23mcxFJBUbY/7Bkbe6WO23MNdVvlvi9013AgzaeXzosOq6TmGWpbY3aAo27i7U2w/8PaNFf3C79H//XEeDfZ03rcTQBppmUuE5AOyuZtVFLgUe3A6GNgNtsLBLauDuQdL31+x3lSLF1TAfXjx/dxvS2eUA1/P/EYKtxN59e048BkK9xN5Nh7U3b03+Ex1PF7/YWtTR4q4vpRcO8u6DwAvDBTfITA5Zdsb2QI+Ba5uyn2cDv/wU+GmK6Xdo/LujlC3elF1hHJtK79I98gKO3FXTANMAwnD/zIPnoejF4kWZZ1Br7k4yZzxkizQCd3m79PkAMRk5utuzm0VWZvg5HM0COqCwWu00u/i12C5XkAp+PFrtBXm8JFElGp9gq4rb2IUGqKMv279XRAKi8wPl5fFx9LnON2jqffdLa6QIDatbwMmdrWQNpMGFrP2kApA0TH5csM1LMUwLCxFFWUzaJ33s9Ir+fSiUGO9LAQuNnWtek9rOeWTF5/TYCYmf/VmI7ym+PsDHq0OD+Hy27GCMTgUe2And/avuxDcyOL/2bSX7A+nn0MQyAfI27tSwFZ+W3Zx0QVwm+ZKOw0yYrgZU0Q1J4QQwWjBcOs8yINFskrWsQBGDDs+L08N+a/ePoqoHXWohDuG3VdRz8ypEXYerkZvG7+Wyo0mBR0MkX7kprrWx1t9gjyHSBnd4OnL46WkcaABkCH/O/kYoCsVtLOuuvvtp+mts8KDn+W83P654UR1MZyGUhPhtpufBidblpfdH5PcCFfZ4pVq0sEYtfl/UFXok3/VspMwuQXZk5WurgWnF9LattcTAo0VfLD8m/x4mJSV09dw2TnA+eQqIsA6CY9qa3rS1foHFwUjs/GwGQ9BiGLlxni/mlppjVunUdb3r7xmeBsDjHjyftVtYEmH5YUvs5VkBu6/U4W/sz+TexuHh2BnCrZB4euYVezYVEWQZQCX3FrFuHUbYfa+gSNJAGtea1XT6MEyH6mtpat+joL+LX9kXA8/k1n0h0VeIU/XKTvzlCmuV5r784xLjgrNg3bJ6Nkl5EDW/MVWXAsn7yRbLFOaZztRRny/9j66rEBTSdZS1AkF4ArHU/lBcAX94vTlDYd6bzz21gXgR9+AdxLSO1H9DjYdPAzhBYyv2NGDJy0n3tTTImrYU5u9vyd3D5hDixJOD4hfTSEXEldwNro75cUVliOozb1qgwdwOg1Ods3+9ot9S+/8lvj+0gFtDaex7A9blpGiaJwac9iQPFC3nS9eJjzAOgng+LgxfajxJvW8vgyGWGmvcB2o80289GoGSSAQq1/Xz2NGpreoGP7wI07QGkf1GzzeaHBJn/H61ZACQNWFQqxzJutgqQrdXtSRkmzlT7A/6BkuJiSWDlSAAEWAZsjo5SM+9RkP7ebE1B4WMYAPkaT4xmsudMmlg82GMy8O1UMXi4ZyXQVmbhO0BcYVo6waC1BVsNs5D+Nv/qvA9mAZBOpmvkxO/WRwj9/hJwclPNbWsXHXvdY9bIFe4BjgVAp7bUZNsMq227Qtqd9ekIoMu4mu07l5nu+/4AYNJGxy6IJzfJj6CRKi8QX98/PwPZByzvlwawjl7wpYuZepozQU1tzQtl4M68PoB4sarthSAbJll2ZZrr+zgw5L+m28wvbpGJwH+yagIRa104ctmPh3613CYNzMd8Jk7Y2e7q6u3SC6lh3SxH14u67S3g1//U/G4eTTN9LX6BlsGUoxMTGttkngGSBDNV5abn4Ob54lxc5nVM0qCpQXNxvh5DDaIjXWDjvxKnFhn4lOn2AMl5kguAhr1quc08ALS3AHRsR/vZIfNZ2H0YAyBf442JvVZcLYwMbFCTOflzmTjC4eBa8RObdMkEwwrTxjZK1z+y8olh9TjLURFytSG2PjGZT+su7Xba+ob4xthnmmX3h6OsffqTPq+1tXWk/+Qmi5066dI/prf3r7K9/0eDbd8vZW8a/ax0MVCyNnu2IRjP2g+se0p+H3OeHrEkdW634/t6ag6e2jp+QHDtBEAtb6ypcWqYJH7I+WE60PImMRuz9f9MA0nz4Aew/J9U+5leXK2OMHJi/qBR74n/N+1uF4uLDYGPRiYDZK8LrPM94vtAfBfxw4iha9s8kAuLtzzn1oqWAfkMqjRgCok2Ddg0Zl1g0W2AfjLZYWndUGAD8fdk4EgGqFEb4J4vLLebZIASTO9r2BLo/ajlYyzeA2UCIJVGfC9oO0L+ec0ZJtWsAxgA+RpvZIAMTm+r+Tmukzjr8KaXgR3vAjP+sv44kwDIiSUypAGQ4VOarRS0eT+zYXTWlTNi8TIgvsG7mgGy9tyOzBPjTt2Pr9jymu3VqStLgR1LgfVOzNdRmGV/H2tuf0ecI8oTa7mV5trfx1X5Z60Pg4/vIn5KDo4yXc08IFS8AG19XbztF1Q7AZD04hrVUhy1FNdR7A7yDxIvyBcPAmsmAjdbmaBULgCSstZuZxa27CqZFNRfcjw/mRoge11goyWLyNp6PwpvbHqse1aZPrcFmQBIGqCExIjfh78u/s027m6aDbaWYZb+jgTB9H3OnYJ56XtSRFPT+6wNgjH/XUrP3+PpYg1fm2FiF3srOx++ej4iThQ7yInVCxTGAMiX6Kq9O7W7dI0WbRhw6Bvx57xj4hu8tU9ejmSAAMs3I+maQWX54ro11t4kAHGNGSlDzYo0+/JKPNDnMevHsObSEedm2TaY8C3wvzucf5yvUtsYB1FZ4lzwA4hvgK7yD/bcNPmOLJ3hqsUda+phpKb9KX7qV2tq/pcMbnsLyD5Yc1utrp2VsKUFqOFNxCxG42412/wCxPW+ZstN1WBom8bObZm/mf5PWBZB3/isY22Wkq0BcrALDLD9ftQk2TTYCI1xrm3SNgHikHYA6CWpU5T+/WqsXF6lWaTqMiBM0iZ3piuRFnObB3bWMu3mRdfS89cwUfwCxCUs7Bn2qjj6S5rR8nEMgHzF6e3A/0YDUS4WI7tCWthaXWG6yF3aO+JqxPd9Y/k4azVA5n6x0W3y9STx++021qYyZ+iOknZ56asls5M64b3+zj8G8O7vxxtsfWKuze4sOX5a6xcNX3P4O8ttkYk1wYJ5bUlgA8vpC1wt7k0aZFobJyWdXNDVqS/sPc78YtokBbjpedMRqNc/Awx40vnnlgYQhhFWTgVAMn/P930tFoN3vFMMCO/8SPxbs7fwq1yAKs0Aya2nJf1AZ7XGUHJ+q8pMj+lO12qTZHHywejWNdsMBdPWuvqCGphtcGPRa7VazDrWIYoPg1+6dCkSExMRGBiI5ORkbNu2zeq+33zzDW6++WY0atQI4eHh6NOnD9avX2+yz4oVK6BSqSy+yst9fGje2gfEFKbsJHq1RPrPtvsj0wkANy8Q3zS2yyxkajI/ipurxNvKGJgXvRqGbRd5oI/Z1VFCwdHuP7cvsVbjBDg2X44n+QX51EKJzlGZXjDN17UKamAZALkaoJh3b0h5Yr4leyOZzLMUDZPEwEKaATJsc5a0S8ZQyBtgFgDd+RHQa6r48wizaRjkPpC1GiwWDBva0+kusejaXvvueF/8PY5cWrNNGtjKrV0m7VZ3ZLblimLTdri77lu38UCznjW3J28UZ582zNhsznxNMB9aqd0bFA2A1qxZg1mzZmHu3LnYt28fBgwYgOHDhyMzU76odOvWrbj55puxbt067NmzB4MGDcJtt92GfftMh3qGh4cjKyvL5CswsJZHXLhLiT886UiWSitzjcjNQSJ9I3e3y87WvETmQYqhLc4Os9zxrv19HDH6A8s3Y18jN/Ovq+RW6pZ+qpderFz5tG/OT+v5AChpEHCHlSJvT/IPMr2QmY/AC4q0nFgxqrXtRS+tnQtrNTg9JotzwfgF2Z5t2B57AZD5/YZ2Wpsg0SmSD1SGJTOkxb3DXxcDmJv/K9aopDxk+vBYN2Y3NhffGfjXP2JQYaDWiKOwxnwmP3+QNOhxpIvT8KHTsORH13tdb6+c0Big893WfzfmGSBnajqvAYoGQG+++SYmTZqEyZMno127dli8eDGaNWuGZcuWye6/ePFiPP300+jRowdat26NV155Ba1bt8aPP/5osp9KpUJcXJzJly0VFRUoLCw0+fI6RQIgB9KtcktzfHRzzc/utlsuE2Molja/z9BeZz/lrv+P8+0yF91GXAcJAFImuX88T0t+AJi+Bxj6iuV9ncaY3u4yzrLA3BEjFgGDJOdSegFIul68OBk4MhOtOb9A29kNVzRJBrqMde8YjtRlGC7WBtpQ0wLz0BixCwaoWUYgMgF4zMbINmvBkXntSqubgRcKxOAn6QZgzjn5VdQdZR7gmF8UzTNXxvWlJBd8Vy+k0seFXM22SkekGp7bL6CmPkXqpnnigqoP12L2svXNlnMbGdsnCYCCGsrvAwAJ/cTvhuBx/FfAv456NoBzhHk3HjNA3lFZWYk9e/ZgyBDTZQiGDBmCtLQ0h46h1+tRVFSEhg1N/9CKi4uRkJCApk2bYsSIERYZInMLFixARESE8atZMxfevN2lxB+eYVVlW+QyQCYz29bCJ4aXYoDPRlkOzzaMznKln9zdTJU0VXzLG+LChg2TgI53uXdcT9Foxcks5Qo7zVfhbpDg/IyzY/4nftpWa8Rix8SBQB/J+mn+waYBkdycI/b4B4oBnDM1H/YYuvhulenKBWpG8tjiyOR2ja6z3CadIyYgFGjRD3hsl7hApIGtCUitDYkOaSRmIAzMM0Xu1lFZdM2Z/Y+bD04wZoCkAZCL72cJ/cSlL0YsrsmoSZ/P3lqJgRHAsAX263tqi3Qklvn/ndTdK8RC+glXR41p/EyLob3FfCboOlbD4y7FAqDc3FzodDrExpr+0mNjY5Gd7ViNx8KFC1FSUoIxY2o+4bZt2xYrVqzADz/8gFWrViEwMBD9+vXDsWPHrB5nzpw5KCgoMH6dPWtlOYna5Kupx8Pf276/tgI3uSJPQ+DjSj+5I6t32yJ9c1erxfVypv1peTHwhPAmzj/GkOI2Dx7C4i2zKh1Gyc9G23qoOCeLNLAxaC8pouz9qLiOUIikHso8AIpp51h3ljRroNKIAdxEO39zzjB8wu0xCeg+0fL+0BhxGYHHdlneZ+BqACStFzFczBtdZ310pdofmC6ZfiLYSgYhLN40A+FqMbU11rq4DNrdZnouDfebLCHj4vuCWg3cthhIkaz/JT2Pnqhxqk3S2dVtdZeHxgBjPq1ZeFUpIdHi+9io98S6KvPJFa9xihdBq8wK0QRBsNgmZ9WqVXjhhRewZs0axMTUfIrr3bs37rvvPnTp0gUDBgzAl19+iTZt2uCdd96xeiytVovw8HCTL6+rq6lHb7Z73//EeWLkAiCtzIgMKbcDIPNhpVeHMXuk7sGMM+tEGRguQub/O+aByN0rxG1yGaB7vhADo6Evi7PY2iMNtgKCTVP+wQ3tBw5DXwHmSucNuvohwFbxqNw6UvfKLFYLiEN3+86ouS2XBbzrY3F+GLkAxqD3VOv3GZhPPAc4NqkdIE5QCIhdddIRPObBbHQbccRVyxtNt9ucy8YF0oty53tMh9EDYqBzu+T9VO735cn3BenfdFm+545bG2wNKvBVMe3EeZmGv+beumt1kGJjTqOjo6HRaCyyPTk5ORZZIXNr1qzBpEmTsHbtWgwebHtyJrVajR49etjMAPmEOhsAeTlztfF5oPUQy+1NulsfGgy4P6TbWkGjNLjwD7adnbrvG3H1clse2Wo5db4jrC1EqQ0zvUA17i5+N7+4Tv7NdD/pBT2qNWRJz4l/MBARJXYN+geJXYb2AiDD/E39nxAXXjUsumkrc6QNFedOMVKJNTCDngU2vSRu+tcRMWA1L/A0L0Kestl24GPQYbRYRxXZQlyUV+53LFe71HMK8O1fNQGONRO+FdenajPMdLt5Zmfs5/Lt9fSEiskPin9PCX0d6xKRG+5dW+9nvv4+6YlFf8lrFMsABQQEIDk5Gamppos4pqamom/fvlYft2rVKjzwwANYuXIlbr3VytpVEoIgID09HfHxMkMWfYk7/9hyAYEcldqxdL4zrLU7wsHF+FwhVwNkrxtAGgDZWnDW2twdjqyA3ffxmmBBpQGm/mH6ad38k7ucaAcuyLLtkLRbOuTVL8j0d24IfMzrPMyLllsPEWucYjua1qxISYt0/YPFYz6yFZi04erCkA4O8x78AnDnBzWf9G0FQOYZoIimYjauz2PiXDTTdopdcRbzmwDQmwVAtkZgSfkHATFtxUyLtQBXbkh05zHAA+uAcavtH7/HZMsgyryI1tq6VR7vAtMA3Sc4Xg/SNMVym6cDlVveEGer7z/Ls8f1tL6Pi9+73adsO8ghinaBzZ49Gx9++CE+/vhjZGRk4IknnkBmZiamThVTznPmzMHEiTV9zatWrcLEiROxcOFC9O7dG9nZ2cjOzkZBQU2/8Isvvoj169fj5MmTSE9Px6RJk5Cenm48ps9y9A1DbmSBI7UWvR4V6ztcGf1ji6Hd5uth1WYqVbqEh4G1wM4wgqeiWOwCyTpge6mLKVaySNa6GaSBR+JAYPpu4Pl84D8XxCUIOt0taYsD86IYfpdT7Sxiae1xAHCTZIVx/0DTwlHDxdK828K8eDogGJixF3j0D+vT80uzf4bjqtU1r9NQS9R2hBjkOMq8bdKFHc0zcYZ6qYBgYMBsMVCxxl4BrTXWirIT+otZoajW8gvPqlRi4bNcMOaIuI6m805ZC4DkugW9Ydqf4hwzch/A4jp79rl6Piz+T8gNPfclcR2BOeedm+CVFKPotKtjx45FXl4e5s+fj6ysLHTs2BHr1q1DQoKYfs/KyjKZE+j9999HdXU1HnvsMTz2WM3yB/fffz9WrFgBAMjPz8eUKVOQnZ2NiIgIdOvWDVu3bkXPnj3h0xwNgHpPq0n1G9ibcCumPTD86qic4IZmo7jcJAhiRmZxJ9Pt3p4vx1oAFBYnvt7KEnGds20LbQ9jj+sk1seY9+Vbu8hIA4/wxjUXf0PAZP57lS5WKfs61DXt6HgncOhr6/tKWatx8gsyC4AMGSCzvxm54MxewCa9sMtle/o/IY7qadxVDJA2vmD7eMZjmbXNpJvRLBCVFmLb03ookCGZMsPhDJBM8OsXBDz489VuNVXtzGCt14n1WN8+crUdVj5UeLoGyFEx7cQvqcd2AZdPAc16KNMmX+DOel7kVYrPOz9t2jRMmzZN9j5DUGOwefNmu8dbtGgRFi1aZHc/nyEIwMGvHP902v8J8VPlqa3ibM2OkAYHro5aSnkI+Otjy+2C3nQJDQN3MkDRbZxfp8taEBjZ4moAVCwGPwDw10d2DiZz4bd2kZEuXis37NW8RuruT4ElPRxbMdlqd1yQWR0MgMJz8vv6B5rWvhgCLOkFu7n1Lmeb4rsAA5+2PnePWgMkSOpfkh8E9nxi/7jmGc0WA2qmbDAPAuSWI7Cm63gxYDIsnRLj4Jwr0gxQj4eB3R8Aw67Ot+TIbL/Oiu0IXDwEdBwNnJOMCrO2bptSGSA5ja5zrK6KyAcoPgqs3jv6K/DNZMf31/iJxYnSydnsFd5JP8m7upTDiEVAo3aW2wW9/MgMR0fAyLE1gZg11oIFw2in83scP5ZcNs5aN0iFpLZIrositr3p7cBwoN/jjrVDLqswYjHQ5R7xZ2lxclhj+WOYZ4AMpOdrvBsLh944F0i+37F9b1tse/FbA2lQ0eNhYMh/a7I1t78DhEsCLmfmM1KrgeuGAw/9Kn7ZWgjWYPzXpt1uw14V64ySH7T+GHc9vEkcmh/bwbEPEkGRtdcWomsYAyClXbA9SaNV0ou0tVE6RpIAqJkbXYFjP7fcpq8CPpQp7nVnMjtXhpZbK7g1pKP/XCp/vxy5GiFrRdDS4mq5LqMmycA9q4BHJZN7pjxkedEKaww8bva30PMRy+OlPCgOHx/+OjDxO3H0Vp/pQF+ZuXsAcUizefEvYBpkeDNl70i3kzQD1OcxMbB8+iQw6xDQqA3wxKGa++XmM3KVYTmClIeA0DjgtreB1majTDV+Yp2RK+tcOcovQOxOBcT5fjqMFouAzd30nFh/Y5hhmoicongXWL3nyDT7cqRdLykPiROE7bcyf0zbW033LbkkZp6y9jv3nNGtgMm/ywc85hz55KqNMF2A1aDNMHF01fFUy/ussdYVYa8dN84Dfv+v6Ta5gMHaSBtH5v1oa7Y+l3+QODpomaR7qGmKOOpKKr4z8NQJYFFH0y6vgGCg1xTx54im8qNwHk8H8k6I3aWleZb3950B7PuiJpvkNQ5MmyD9XRq6b4Mia4JGafDh7IzWtoxbDeQcFue9ufXN2g1yHKXxB+620m1obYFLInIIM0BKcyQNL0fardGoDXDHMnENIHO3LwH6zZI8n0Zcz+mRrab7yY3aCJDp0nFkgT/A/si0VoOBwc/L3xcQCtz3ldjVcNcnwLw8oOVNNffHdhKzJf+RTKJn3rUS11lcNdpeV9zAJ8UuB6BmfR451jJahsUYW90sf7815kXi1orgnSnylWqYWJO9aHcbMOw1YNLGmvsbNAeeOSWuH+VNjtSgafyB658RC/4bWFmWxhD4ODoFhCP8A8X5pFQq3wh+iKhWMQOkNEczQCExwL1ram7LBSzaMLGwM+dv8faULeIIHGvCm4gFwvFdgEmpYi3PwjaGhokjxsxXiXc0ACrPt35ftwnAyCXi6LGfZ1veH3l1Er6YtjXDmid8A7wQUXO/ebYkQrJ8RGgsMPXqUPlcBybAbNId+Hem/CibrvcBp7eKBalyGncDnjxme90fOebPZWutMnfnVFGp5GczdvR36Un3rgF+nGU6VF+OdNFVOTP3i5nMRm1s70dEZAUzQEpzdLK4e1aKF2qD9iPF7I60tgQwrbGwFfwA4npOPaeItT1+WnExvlHLxHqX8V9BtrvC4QyQjf0Mr1muW6n1UCDxejvHli7t8CnQ5V7xdRiP70J9S2CEfNHxqHeBmQesz8ECiHPoOPp7NDB/7bbWOPL12W+dEdcJePg3cfV4dwQ35GgjInILM0BKczQDZF4YrFKJs7VaHM+J545qCdzyuum2rveKk/dp/OWXubAV2ADi6ugVReLik+kyRdP2GnnDv+13P0iDsA6jxC+pOMmcRNIaoJAYoCTH9rHl1EZ3iHmXWla69X0jmgBXTnu+DURE9RgzQEpzNHPg6Ho/jk7uZouhCHX0B+Iw6uGSIMlWBmj6HuCuj4DxX1pfyRqAzUJYW6PHOt4lfpdbrRwQa3m6TwRuf7tmm7QGaNJ65+aNqU3mtV/tbpffDwDGrQGSbgAe2lCrTSIiqk8YAClNLgPURGZUjyPLXQA1sxzbKuh1VEIfYM7ZmhFHgPVALGmQOErMwFZ7pRPzTfze9D5bs9qO/gB45ow43bycJt3FeWKkyzpI124KbyoGaX1niIGRtUDK2BYvzWbdJLlmpm45MW3F89S8l3faQ0RUDzAAUprcKLAb5lhuczQD1H0i8PDvV2t4PMB8eLm1AKXdCNPbtoqCiySjt5JuMJ3jxFbQoVY7v66S9Lz5BQChjYAhL4kj5oa+LP+Yuz4RRyt56hzac/N/OZkdEZGXsQZIaXIZILliXEdXcVepxIxCbRq3Blg11nSb+Qrrflrg3rXAyrthIf+s9WM7Gug5qsMdwPGNNZPcGdiq6+k4WnxcbQ+FfmQrcOmIOFcPERF5FQMgpcnVAMl1H9kaheRt0tFoBoLMMO42VuZokc6eDJh2iVmbcNBVflrgzg+df5w35oGJ7yJ+ERGR17ELTGmyGSBJADTyXWDGXuVWfJYTGiO26V+SBUsbtrT/uLtXiF09o8yWpZBO6lgbi0sSERGZYQZIaXKZBpVaXPco7zjQcpDl/b4g6mrA8+CvQPYBoLUDMyF3uANoP8ryNcst1klERFSLGAApTW6SO5VaXALA2jIAviShj/jlKLmAjwEQERF5GbvAlCa3BEJ9W4eIARAREXkZAyClWcsA1SdRrezvQ0RE5EHsAlMaAyBxhufC80BzJ7rSiIiI3MAASGlyAVBwtPfboSS1Guj/hNKtICKieqSepRp8kHkANPYLcVV2IiIiqjUMgJQmDYACIyyXlLhWhMTY34eIiMhLGAApTRoARbVWrh21LaSR0i0gIiIyYgCkBL0eqCy5+rNkGHziAGXa4w1RSUq3gIiIyIgBkBI+ux14pTFQlG2aAbr+GeXaVFtGLgUadweGv650S4iIiIw4CkwJp7eJ3//+riYA6naf5xcC9QXdxotfREREPoQZICWpNTUBUH2b+4eIiEhBvOoqSaViAERERKQAXnWVpFJLAiCNsm0hIiKqRxgAKUnFLjAiIiIl8KqrJJMMEH8VRERE3sKrrrdJ5/1RqWtuMwAiIiLyGl51vU1XWfPzlVPA9jfFn9WsASIiIvIWBkDeJg2AtkomB1SpvN8WIiKieooBkLfpquS3swuMiIjIa3jV9TarARC7wIiIiLyFAZC3SbvApJgBIiIi8hpedb2NXWBERESK41XX2/QMgIiIiJTGq663WesC4zB4IiIir2EA5G1Wu8A4DJ6IiMhbGAB5G2uAiIiIFMerrrdxFBgREZHieNX1Ns4DREREpDgGQN7GDBAREZHieNX1NgZAREREiuNV19uqyuS3MwAiIiLyGsWvukuXLkViYiICAwORnJyMbdu2Wd33m2++wc0334xGjRohPDwcffr0wfr16y32+/rrr9G+fXtotVq0b98e3377bW2+BOdUWwmAqkq92w4iIqJ6TNEAaM2aNZg1axbmzp2Lffv2YcCAARg+fDgyMzNl99+6dStuvvlmrFu3Dnv27MGgQYNw2223Yd++fcZ9duzYgbFjx2LChAnYv38/JkyYgDFjxmDnzp3eelm2VZXLby8v8G47iIiI6jGVIAiCUk/eq1cvdO/eHcuWLTNua9euHUaNGoUFCxY4dIwOHTpg7NixeO655wAAY8eORWFhIX755RfjPsOGDUNkZCRWrVrl0DELCwsRERGBgoIChIeHO/GKHLBtIfDbfMvtyQ8Cty327HMRERHVI85cvxXLAFVWVmLPnj0YMmSIyfYhQ4YgLS3NoWPo9XoUFRWhYcOGxm07duywOObQoUNtHrOiogKFhYUmX7XGWgaoohafk4iIiEwoFgDl5uZCp9MhNjbWZHtsbCyys7MdOsbChQtRUlKCMWPGGLdlZ2c7fcwFCxYgIiLC+NWsWTMnXomTrNX6sAuMiIjIaxQvglaZrYElCILFNjmrVq3CCy+8gDVr1iAmJsatY86ZMwcFBQXGr7NnzzrxCpxUbSUD1G9m7T0nERERmfBT6omjo6Oh0WgsMjM5OTkWGRxza9aswaRJk7B27VoMHjzY5L64uDinj6nVaqHVap18BS4y7wLTBACzM4CQaO88PxERESmXAQoICEBycjJSU1NNtqempqJv375WH7dq1So88MADWLlyJW699VaL+/v06WNxzA0bNtg8pleZD4P3C2TwQ0RE5GWKZYAAYPbs2ZgwYQJSUlLQp08fLF++HJmZmZg6dSoAsWvq/Pnz+OyzzwCIwc/EiRPx1ltvoXfv3sZMT1BQECIiIgAAM2fOxMCBA/Haa69h5MiR+P7777Fx40Zs375dmRdpznwiRI2/Mu0gIiKqxxStARo7diwWL16M+fPno2vXrti6dSvWrVuHhIQEAEBWVpbJnEDvv/8+qqur8dhjjyE+Pt74NXNmTf1M3759sXr1anzyySfo3LkzVqxYgTVr1qBXr15ef30WqiuAI+tMt2kClGkLERFRPaboPEC+qtbmAfrrE+CnWabbGiQAsw547jmIiIjqqToxD1C9lPwAMOQl023MABEREXkdAyBvUqmAvjOA4f9Xs83PS6PPiIiIyIgBkBKkhc8sgiYiIvI6BkBK8Auq+VnDDBAREZG3MQDyor8vFGDooq14Z/u5mo3MABEREXkdAyAvqqjW48jFIpwr0tdsZA0QERGR1zEA8iI/tbgeWaleMvKLo8CIiIi8jgGQF2muBkBlgrQImgEQERGRtzEA8iI/tXi6GQAREREpiwGQFxkyQCXSLjA/BkBERETexgDIi2pqgJgBIiIiUhIDIC+qyQBJAqCAEIVaQ0REVH8xAPIijVwGKCRGodYQERHVXwyAvMjQBVYiLYIOiVaoNURERPUXAyAvMmSAKvWS0x4aq1BriIiI6i8/pRtQnxiGwQOAvvM9UOefARIHKtgiIiKi+okBkBdJ4h9U3rYUgf4a5RpDRERUj7ELzIukGSCdXlCwJURERPUbAyAvMtQAAYBOYABERESkFAZAXuQnDYB0DICIiIiUwgDIi9RqFVRXY6BqdoEREREphgGQlxmyQKwBIiIiUg4DIC9TX00BVev1CreEiIio/mIA5GXMABERESmPAZCXaRgAERERKY4BkJf5acRTzgCIiIhIOQyAvMyQAeIoMCIiIuUwAPIy1gAREREpjwGQl9WMAmMAREREpBQuhuplfhpDBojD4Ino2qbT6VBVVaV0M+gaExAQALXa/fwNAyAvqxkFpnBDiIhqiSAIyM7ORn5+vtJNoWuQWq1GYmIiAgIC3DoOAyAv81NzIkQiurYZgp+YmBgEBwdDpVLZfxCRA/R6PS5cuICsrCw0b97crb8tBkBeplFzGDwRXbt0Op0x+ImKilK6OXQNatSoES5cuIDq6mr4+/u7fBwWQXvZ1WmAWARNRNckQ81PcHCwwi2ha5Wh60un07l1HAZAXmbMAOkYABHRtYvdXlRbPPW3xQDIy/w4ESIREZHiGAB5WcDVPrBKDgMjIrqm3XDDDZg1a5bSzSArWATtZQF+VwOgagZARES+wF6Xyv33348VK1Y4fdxvvvnGrSJdAHjggQeQn5+P7777zq3jkCUGQF7GAIiIyLdkZWUZf16zZg2ee+45HDlyxLgtKCjIZP+qqiqHApuGDRt6rpHkcewC87KaAMi96nUiIvKMuLg441dERARUKpXxdnl5ORo0aIAvv/wSN9xwAwIDA/H5558jLy8P48aNQ9OmTREcHIxOnTph1apVJsc17wJr0aIFXnnlFTz00EMICwtD8+bNsXz5crfavmXLFvTs2RNarRbx8fH497//jerqauP9X331FTp16oSgoCBERUVh8ODBKCkpAQBs3rwZPXv2REhICBo0aIB+/frhzJkzbrWnLmEA5GXaqzVAFcwAEVE9IAgCSiurFfkSBM8NNnnmmWfw+OOPIyMjA0OHDkV5eTmSk5Px008/4dChQ5gyZQomTJiAnTt32jzOwoULkZKSgn379mHatGl49NFH8c8//7jUpvPnz+OWW25Bjx49sH//fixbtgwfffQRXnrpJQBiZmvcuHF46KGHkJGRgc2bN2P06NEQBAHV1dUYNWoUrr/+ehw4cAA7duzAlClT6tXoPXaBeRm7wIioPimr0qH9c+sVee7D84ciOMAzl7lZs2Zh9OjRJtuefPJJ488zZszAr7/+irVr16JXr15Wj3PLLbdg2rRpAMSgatGiRdi8eTPatm3rdJuWLl2KZs2aYcmSJVCpVGjbti0uXLiAZ555Bs899xyysrJQXV2N0aNHIyEhAQDQqVMnAMDly5dRUFCAESNGoGXLlgCAdu3aOd2GusylDNDZs2dx7tw54+1du3Zh1qxZbqfy6gOtH0eBERHVNSkpKSa3dTodXn75ZXTu3BlRUVEIDQ3Fhg0bkJmZafM4nTt3Nv5s6GrLyclxqU0ZGRno06ePSdamX79+KC4uxrlz59ClSxfcdNNN6NSpE+6++2588MEHuHLlCgCxPumBBx7A0KFDcdttt+Gtt94yqYWqD1wKje+9915jui87Oxs333wzOnTogM8//xzZ2dl47rnnPN3OawYzQERUnwT5a3B4/lDFnttTQkJCTG4vXLgQixYtwuLFi9GpUyeEhIRg1qxZqKystHkc8+JplUoFvYtrQwqCYNFlZej2U6lU0Gg0SE1NRVpaGjZs2IB33nkHc+fOxc6dO5GYmIhPPvkEjz/+OH799VesWbMGzz77LFJTU9G7d2+X2lPXuJQBOnToEHr27AkA+PLLL9GxY0ekpaVh5cqVLg0VrE8MARBrgIioPlCpVAgO8FPkqzbrWbZt24aRI0fivvvuQ5cuXZCUlIRjx47V2vPJad++PdLS0kxqndLS0hAWFoYmTZoAEM9/v3798OKLL2Lfvn0ICAjAt99+a9y/W7dumDNnDtLS0tCxY0esXLnSq69BSS5lgKqqqqDVagEAGzduxO233w4AaNu2bb1LoTkrQCN+ImEXGBFR3dWqVSt8/fXXSEtLQ2RkJN58801kZ2fXSh1NQUEB0tPTTbY1bNgQ06ZNw+LFizFjxgxMnz4dR44cwfPPP4/Zs2dDrVZj586d+O233zBkyBDExMRg586duHTpEtq1a4dTp05h+fLluP3229G4cWMcOXIER48excSJEz3efl/lUgDUoUMHvPfee7j11luRmpqK//73vwCACxcucPVfO4wZoCoGQEREddW8efNw6tQpDB06FMHBwZgyZQpGjRqFgoICjz/X5s2b0a1bN5NthskZ161bh6eeegpdunRBw4YNMWnSJDz77LMAgPDwcGzduhWLFy9GYWEhEhISsHDhQgwfPhwXL17EP//8g08//RR5eXmIj4/H9OnT8cgjj3i8/T5LcMGmTZuEBg0aCGq1WnjwwQeN2+fMmSPccccdTh3r3XffFVq0aCFotVqhe/fuwtatW63ue+HCBWHcuHFCmzZtBJVKJcycOdNin08++UQAYPFVVlbmcJsKCgoEAEJBQYFTr8URH247KSQ885MwfeVejx+biEhpZWVlwuHDh516zyVyhq2/MWeu3y5lgG644Qbk5uaisLAQkZGRxu1TpkxBcHCww8dZs2YNZs2ahaVLl6Jfv354//33MXz4cBw+fBjNmze32L+iogKNGjXC3LlzsWjRIqvHDQ8PN5nFEwACAwMdbldt0nIiRCIiIsW5VARdVlaGiooKY/Bz5swZLF68GEeOHEFMTIzDx3nzzTcxadIkTJ48Ge3atcPixYvRrFkzLFu2THb/Fi1a4K233sLEiRMRERFh9bjSWTwNX76Co8CIiIiU51IANHLkSHz22WcAgPz8fPTq1QsLFy7EqFGjrAYv5iorK7Fnzx4MGTLEZPuQIUOQlpbmSrOMiouLkZCQgKZNm2LEiBHYt2+fzf0rKipQWFho8lVbOA8QERGR8lwKgPbu3YsBAwYAENcZiY2NxZkzZ/DZZ5/h7bffdugYubm50Ol0iI2NNdkeGxuL7OxsV5oFQByJtmLFCvzwww9YtWoVAgMD0a9fP5vDExcsWICIiAjjV7NmzVx+fnu0LIImIiJSnEsBUGlpKcLCwgAAGzZswOjRo6FWq9G7d2+nF1KTm8TJnbkbevfubZyXYcCAAfjyyy/Rpk0bvPPOO1YfM2fOHBQUFBi/zp496/Lz2xN0dVr2kkrWABERESnFpQCoVatW+O6773D27FmsX7/e2I2Vk5OD8PBwh44RHR0NjUZjke3JycmxyAq5Q61Wo0ePHjYzQFqtFuHh4SZftSVUK84DVFJRbWdPIiIiqi0uBUDPPfccnnzySbRo0QI9e/ZEnz59AIjZIPO5CqwJCAhAcnIyUlNTTbanpqaib9++rjRLliAISE9PR3x8vMeO6Y4Q7dUMEAMgIiIixbg0DP6uu+5C//79kZWVhS5duhi333TTTbjjjjscPs7s2bMxYcIEpKSkoE+fPli+fDkyMzMxdepUAGLX1Pnz540F1wCMs2EWFxfj0qVLSE9PR0BAANq3bw8AePHFF9G7d2+0bt0ahYWFePvtt5Geno53333XlZfqcSFXu8CKGQAREREpxqUACIBxePm5c+egUqnQpEkT4/pgjho7dizy8vIwf/58ZGVloWPHjli3bh0SEhIAAFlZWRYr60ozTHv27MHKlSuRkJCA06dPAxBHpU2ZMgXZ2dmIiIhAt27dsHXrVqfbVltCr2aAKqr1qNbp4adxKQlHREREbnDp6qvX6zF//nxEREQgISEBzZs3R4MGDfDf//7X6VVtp02bhtOnT6OiogJ79uzBwIEDjfetWLECmzdvNtlfEASLL0PwAwCLFi3CmTNnUFFRgZycHKxfv97YRecLgrU1qxOzEJqI6Npxww03YNasWcbbLVq0wOLFi20+RqVS4bvvvnP7uT11nPrEpQBo7ty5WLJkCV599VXs27cPe/fuxSuvvIJ33nkH8+bN83QbrylaPw38NeIoN9YBEREp77bbbsPgwYNl79uxYwdUKhX27t3r9HF3796NKVOmuNs8Ey+88AK6du1qsT0rKwvDhw/36HOZW7FiBRo0aFCrz+FNLnWBffrpp/jwww+Nq8ADQJcuXdCkSRNMmzYNL7/8sscaeC0K0fohv7SKARARkQ+YNGkSRo8ejTNnzhhLMAw+/vhjdO3aFd27d3f6uI0aNfJUE+3ypRUP6gqXMkCXL19G27ZtLba3bdsWly9fdrtR1zpDHVBhOQMgIiKljRgxAjExMVixYoXJ9tLSUqxZswaTJk1CXl4exo0bh6ZNmyI4OBidOnXCqlWrbB7XvAvs2LFjGDhwIAIDA9G+fXuLUdAA8Mwzz6BNmzYIDg5GUlIS5s2bh6qqKgBiBubFF1/E/v37oVKpoFKpjG027wI7ePAgbrzxRgQFBSEqKgpTpkxBcXGx8f4HHngAo0aNwhtvvIH4+HhERUXhscceMz6XKzIzMzFy5EiEhoYiPDwcY8aMwcWLF43379+/H4MGDUJYWBjCw8ORnJyMv/76C4C4pNZtt92GyMhIhISEoEOHDli3bp3LbXGESxmgLl26YMmSJRazPi9ZsgSdO3f2SMOuZTFhWpy7UoacwnKlm0JEVLsEAagqVea5/YMBBybW9fPzw8SJE7FixQo899xzxsl4165di8rKSowfPx6lpaVITk7GM888g/DwcPz888+YMGECkpKS0KtXL7vPodfrMXr0aERHR+PPP/9EYWGhSb2QQVhYGFasWIHGjRvj4MGDePjhhxEWFoann34aY8eOxaFDh/Drr79i48aNACC7LmZpaSmGDRuG3r17Y/fu3cjJycHkyZMxffp0kyBv06ZNiI+Px6ZNm3D8+HGMHTsWXbt2xcMPP2z39ZgTBAGjRo1CSEgItmzZgurqakybNg1jx4411vKOHz8e3bp1w7Jly6DRaJCeng5/f38AwGOPPYbKykps3boVISEhOHz4MEJDQ51uhzNcCoD+7//+D7feeis2btyIPn36QKVSIS0tDWfPnq31iO1aEN8gCMjMx4UCBkBEdI2rKgVeaazMc//nAhAQ4tCuDz30EF5//XVs3rwZgwYNAiB2f40ePRqRkZGIjIzEk08+adx/xowZ+PXXX7F27VqHAqCNGzciIyMDp0+fRtOmTQEAr7zyikXdzrPPPmv8uUWLFvjXv/6FNWvW4Omnn0ZQUBBCQ0Ph5+dns8vriy++QFlZGT777DOEhIivf8mSJbjtttvw2muvGScbjoyMxJIlS6DRaNC2bVvceuut+O2331wKgDZu3IgDBw7g1KlTxuWk/ve//6FDhw7YvXs3evTogczMTDz11FPGHqTWrVsbH5+ZmYk777wTnTp1AgAkJSU53QZnudQFdv311+Po0aO44447kJ+fj8uXL2P06NH4+++/8cknn3i6jdec+PBAAEBWfpnCLSEiIkAs4ejbty8+/vhjAMCJEyewbds2PPTQQwAAnU6Hl19+GZ07d0ZUVBRCQ0OxYcMGi6larMnIyEDz5s2NwQ8A2RHKX331Ffr374+4uDiEhoZi3rx5Dj+H9Lm6dOliDH4AoF+/ftDr9Thy5IhxW4cOHaDR1IxMjo+PR05OjlPPJX3OZs2amayl2b59ezRo0AAZGRkAxLn/Jk+ejMGDB+PVV1/FiRMnjPs+/vjjeOmll9CvXz88//zzOHDggEvtcIbL8wA1btzYoth5//79+PTTT41/QCQvLkIMgLLZBUZE1zr/YDETo9RzO2HSpEmYPn063n33XXzyySdISEjATTfdBABYuHAhFi1ahMWLF6NTp04ICQnBrFmzUFlZ6dCxBUGw2Ga+7uWff/6Je+65By+++CKGDh2KiIgIrF69GgsXLnTqddhaU1O63dD9JL3P2als7D2ndPsLL7yAe++9Fz///DN++eUXPP/881i9ejXuuOMOTJ48GUOHDsXPP/+MDRs2YMGCBVi4cCFmzJjhUnscwVn4FBARJP7RFbEImoiudSqV2A2lxJeTC2uPGTMGGo0GK1euxKeffooHH3zQePHetm0bRo4caVxsOykpyeYak+bat2+PzMxMXLhQEwzu2LHDZJ8//vgDCQkJmDt3LlJSUtC6dWuLBcYDAgKg09meQ659+/ZIT09HSUmJybHVajXatGnjcJudYXh90sXEDx8+jIKCArRr1864rU2bNnjiiSeMC6lLe42aNWuGqVOn4ptvvsG//vUvfPDBB7XSVgMGQAowjALjchhERL4jNDQUY8eOxX/+8x9cuHABDzzwgPG+Vq1aITU1FWlpacjIyMAjjzxisZi3LYMHD8Z1112HiRMnYv/+/di2bRvmzp1rsk+rVq2QmZmJ1atX48SJE3j77bfx7bffmuzTokULnDp1Cunp6cjNzUVFRYXFc40fPx6BgYG4//77cejQIWzatAkzZszAhAkT3F5sXKfTIT093eTr8OHDGDx4MDp37ozx48dj79692LVrFyZOnIjrr78eKSkpKCsrw/Tp07F582acOXMGf/zxB3bv3m0MjmbNmoX169fj1KlT2Lt3L37//XeTwKk2MABSQGggF0QlIvJFkyZNwpUrVzB48GA0b97cuH3evHno3r07hg4dihtuuAFxcXEYNWqUw8dVq9X49ttvUVFRgZ49e2Ly5MkWZSQjR47EE088genTp6Nr165IS0uzmFz4zjvvxLBhwzBo0CA0atRIdih+cHAw1q9fj8uXL6NHjx646667cNNNN2HJkiXOnQwZxcXF6Natm8nXLbfcYhyGHxkZiYEDB2Lw4MFISkrCmjVrAAAajQZ5eXmYOHEi2rRpgzFjxmD48OF48cUXAYiB1WOPPYZ27dph2LBhuO6667B06VK322uLSpDrmLRi9OjRNu/Pz8/Hli1b7KbnfF1hYSEiIiJQUFCA8PBwjx9/b+YVjF6ahqaRQdj+zI0ePz4RkVLKy8tx6tQpJCYmIjAwUOnm0DXI1t+YM9dvp4qg5eYbML9/4sSJzhyyXjJ0gTEDREREpAynAiAOcfeMkKsB0JXSKq4IT0REpABeeRUQGlATd779m+OjCIiIiMgzGAApIERbM/HU278fV7AlRERE9RMDIAVIu7w6NvF8kTURkdKcGF9D5BRP/W0xAFLI+F7i8MrGEUEKt4SIyHMMswuXliq0ACpd8wyzb0uX8XCFy0thkHuSEyLxxc5MlFXV7SkDiIikNBoNGjRoYFxTKjg42OqyDETO0uv1uHTpEoKDg+Hn514IwwBIIUH+YuRazgCIiK4xhpXKXV1Yk8gWtVqN5s2bux1YMwBSSFCAGAAxA0RE1xqVSoX4+HjExMSgqqpK6ebQNSYgIABqtfsVPAyAFGLIAJVWMgAiomuTRqNxu06DqLawCFohhgxQOQMgIiIir2MApBBDBohdYERERN7HAEghgewCIyIiUgwDIIUEX+0Cq6jWQ6/nhGFERETexABIIYYFUQGgpJKrwhMREXkTAyCFaP3U8NeIcxgUlTMAIiIi8iYGQApRqVQICxSnjC8s5zwZRERE3sQASEHhgWI3GDNARERE3sUASEGGDFARM0BERERexQBIQeFBYgaosIwZICIiIm9iAKSgMC0zQEREREpgAKSgsKs1QIWsASIiIvIqBkAKMq4HxuUwiIiIvIoBkIIM64ExACIiIvIuBkAK0nJBVCIiIkUwAFJQoL94+sur9Aq3hIiIqH5hAKQgdoEREREpgwGQggIZABERESmCAZCCDF1gGzNycCG/TOHWEBER1R8MgBRk6AIDgNfXH1GwJURERPULAyAFaSUBUHEFJ0MkIiLyFgZACpJmgFIPX4ReLyjYGiIiovqDAZCCVGa3fzxwQZF2EBER1TcMgBRUpTPN+GRkFSnUEiIiovqFAZCCeiU1NLmt9eOvg4iIyBt4xVWQv0aNOcPbGm8HMAAiIiLyCsWvuEuXLkViYiICAwORnJyMbdu2Wd03KysL9957L6677jqo1WrMmjVLdr+vv/4a7du3h1arRfv27fHtt9/WUuvdp1bVVAIxA0REROQdil5x16xZg1mzZmHu3LnYt28fBgwYgOHDhyMzM1N2/4qKCjRq1Ahz585Fly5dZPfZsWMHxo4diwkTJmD//v2YMGECxowZg507d9bmS3FZtWTkFzNARERE3qESBEGxsde9evVC9+7dsWzZMuO2du3aYdSoUViwYIHNx95www3o2rUrFi9ebLJ97NixKCwsxC+//GLcNmzYMERGRmLVqlWyx6qoqEBFRYXxdmFhIZo1a4aCggKEh4e78Moc985vx7Aw9SgA4Nlb22HygKRafT4iIqJrVWFhISIiIhy6fiuWcqisrMSePXswZMgQk+1DhgxBWlqay8fdsWOHxTGHDh1q85gLFixARESE8atZs2YuP7+zpBmgSh1XhSciIvIGxQKg3Nxc6HQ6xMbGmmyPjY1Fdna2y8fNzs52+phz5sxBQUGB8evs2bMuP7+z+rWKNv5cWc0AiIiIyBv8lG6ASmU6HaAgCBbbavuYWq0WWq3Wred0Vc/EhujYJByHzhcyACIiIvISxTJA0dHR0Gg0FpmZnJwciwyOM+Li4jx+zNrWr6WYBWIARERE5B2KBUABAQFITk5GamqqyfbU1FT07dvX5eP26dPH4pgbNmxw65i1zTD6q4o1QERERF6haBfY7NmzMWHCBKSkpKBPnz5Yvnw5MjMzMXXqVABibc758+fx2WefGR+Tnp4OACguLsalS5eQnp6OgIAAtG/fHgAwc+ZMDBw4EK+99hpGjhyJ77//Hhs3bsT27du9/vocFaARA6C8kkqFW0JERFQ/KBoAjR07Fnl5eZg/fz6ysrLQsWNHrFu3DgkJCQDEiQ/N5wTq1q2b8ec9e/Zg5cqVSEhIwOnTpwEAffv2xerVq/Hss89i3rx5aNmyJdasWYNevXp57XU5y5AB+ulAFl4aVYkGwQEKt4iIiOjapug8QL7KmXkEPOHDbSfx0s8ZAID3JyRjaIe4Wn9OIiKia02dmAeIaki7vhoE+SvYEiIiovqBAZAPuFhQbvxZOjEiERER1Q4GQD5gWMeaLq+Kap2CLSEiIqofGAD5gJvbx8JPLU7UWFHFofBERES1jQGQD1CpVOidFAUAqOBkiERERLWOAZCP0F4dCs8uMCIiotrHAMhHaP3FXwWXwyAiIqp9DIB8hNZPA4BdYERERN7AAMhHGJbDYABERERU+xgA+QhDF1hFFWuAiIiIahsDIB9RUwTNDBAREVFtYwDkI1gDRERE5D0MgHwEM0BERETewwDIR7AGiIiIyHsYAPmIIH+xC6y0kgEQERFRbWMA5COCA/wAAKXMABEREdU6BkA+IjjgagaoolrhlhAREV37GAD5iGDt1QwQu8CIiIhqHQMgH2HMAFUyA0RERFTbGAD5CBZBExEReQ8DIB8Rwi4wIiIir2EA5COkXWCCICjcGiIiomsbAyAfYQiA9AJngyYiIqptDIB8hGEeIAAo4VB4IiKiWsUAyEdo1CpjFqionAEQERFRbWIA5EMigvwBAHvOXFG4JURERNc2BkA+pEon1v78a+1+FkITERHVIgZAPiS3uNL4c6WOhdBERES1hQGQjyqvZABERERUWxgA+ajSKhZCExER1RYGQD6kZaMQ48+cEZqIiKj2MADyIe9PSDH+XMYAiIiIqNYwAPIhrWJCkRgtZoHKqhgAERER1RYGQD6Gq8ITERHVPgZAPibo6mzQZZUsgiYiIqotDIB8TM2q8MwAERER1RYGQD7G0AXGGiAiIqLawwDIx4RqxVXhuSAqERFR7WEA5GOiw7QAgLziCoVbQkREdO1iAORjGoWKAdClIgZAREREtYUBkI9pdDUDdIkZICIiolrDAMjHRDMDREREVOsYAPkYYwaIARAREVGtYQDkYwwB0JXSKlRW6xVuDRER0bWJAZCPaRDkDz+1CgCQV8IsEBERUW1gAORj1GoV64CIiIhqmeIB0NKlS5GYmIjAwEAkJydj27ZtNvffsmULkpOTERgYiKSkJLz33nsm969YsQIqlcriq7y8vDZfhkcZusFyChkAERER1QZFA6A1a9Zg1qxZmDt3Lvbt24cBAwZg+PDhyMzMlN3/1KlTuOWWWzBgwADs27cP//nPf/D444/j66+/NtkvPDwcWVlZJl+BgYHeeEke0SomFACw/Xiuwi0hIiK6NikaAL355puYNGkSJk+ejHbt2mHx4sVo1qwZli1bJrv/e++9h+bNm2Px4sVo164dJk+ejIceeghvvPGGyX4qlQpxcXEmX3XJkPaxAIDdpy8r3BIiIqJrk2IBUGVlJfbs2YMhQ4aYbB8yZAjS0tJkH7Njxw6L/YcOHYq//voLVVVVxm3FxcVISEhA06ZNMWLECOzbt89mWyoqKlBYWGjypaTYCDFbVVheZWdPIiIicoViAVBubi50Oh1iY2NNtsfGxiI7O1v2MdnZ2bL7V1dXIzdX7C5q27YtVqxYgR9++AGrVq1CYGAg+vXrh2PHjllty4IFCxAREWH8atasmZuvzj3hgf4AgMIyLohKRERUGxQvglapVCa3BUGw2GZvf+n23r1747777kOXLl0wYMAAfPnll2jTpg3eeecdq8ecM2cOCgoKjF9nz5519eV4RHigYUX4Kuj1gqJtISIiuhb5KfXE0dHR0Gg0FtmenJwciyyPQVxcnOz+fn5+iIqKkn2MWq1Gjx49bGaAtFottFqtk6+g9oQHiRkgvQCUVFYj7GpGiIiIiDxDsQxQQEAAkpOTkZqaarI9NTUVffv2lX1Mnz59LPbfsGEDUlJS4O8vHyQIgoD09HTEx8d7puFeoPVTI0Aj/moKy9kNRkRE5GmKdoHNnj0bH374IT7++GNkZGTgiSeeQGZmJqZOnQpA7JqaOHGicf+pU6fizJkzmD17NjIyMvDxxx/jo48+wpNPPmnc58UXX8T69etx8uRJpKenY9KkSUhPTzcesy5QqVQIDxKTc3lcFZ6IiMjjFOsCA4CxY8ciLy8P8+fPR1ZWFjp27Ih169YhISEBAJCVlWUyJ1BiYiLWrVuHJ554Au+++y4aN26Mt99+G3feeadxn/z8fEyZMgXZ2dmIiIhAt27dsHXrVvTs2dPrr88dkcEByC2uxBsbjuKzh+pW24mIiHydSjBUEZNRYWEhIiIiUFBQgPDwcEXa8POBLDy2ci8A4Pd/XY+kRqGKtIOIiKiucOb6rfgoMJJ3a+d4DGgdDQDYmHFR4dYQERFdWxgA+bD+rcQAaP+5AoVbQkREdG1hAOTDDN1ePx/Iwt7MKwq3hoiI6NrBAMiHJUQFG39+9Zd/FGwJERHRtYUBkA9r3rAmAAoJ0CjYEiIiomsLAyAfFuivwYP9WgAA1DaWByEiIiLnMADycb2TxCU+8koqFW4JERHRtYMBkI+LCgkAAFxmAEREROQxDIB8XMOrAVDm5VKMeGcbDl8oVLhFREREdR8DIB8nLYQ+dL4Qt7y9TcHWEBERXRsYAPk4P40anZpEKN0MIiKiawoDoDrgo/tTTG5z+TYiIiL3MACqA2LCA01uv/xzBlb8cUqh1hAREdV9DIDqiOUTko0/f7j9FF748TB2n76M8iqdgq0iIiKqmxgA1RFDOsRhdLcmJtvufm8H7novDb//cxED/u93pB3PVah1REREdYtKYEGJhcLCQkRERKCgoADh4eFKN8eotLIao979A0cvFsver1IBpxbc6uVWERER+QZnrt/MANUhwQF++GF6f6Q+MVD2foayREREjmEAVMcE+mvQKiZU6WYQERHVaQyA6iCVjYVR9XoBZy+XIiOLM0YTERFZwwCojvro/hTc3D4WH040nSNo5a5M3LxoC257ZzuyC8oVah0REZFvYwBUR93ULhYfTExBSotIk+3PfncI5VV6VOsFvPpLBgBgzjcHMfjNLVxQlYiI6Co/pRtA7mkQHIDR3Zvg6MUiHDpv2u31XfoFZGQV4cjFIgDAij9OYfaQ65RoJhERkU9hAHQNeHNMVwDAnjNXcOeyNJP7DMEPAOw7m+/FVhEREfkuzgMkw1fnAXJERbUO5VV6HM8pwp3Ldljc37NFQzw17DqsSDuNUV2b4Ob2sSgoq8KZvBJ0btrA+w0mIiLyEGeu3wyAZNTlAEhq9a5MrNyViUtFFciyUhA9uF0sNmZcBAC8Pa4bbu/S2JtNJCIi8hgGQG66VgIgqd8yLmLzkUvYm3kFf1+wPkQ+OlSLAI0K5dV6vHB7B9zepTH2ZV7Bl3+dw1NDr0PDkAAAQElFNUK0tntQj+cU4YudmZg1uA0igvw9+nqIiIjMMQBy07UYABkIgoCjF4tRUa3Dw5/9hYuFFQ4/dlzP5ph2Q0sM+L9NAIDuzRtg5cO9Eeivkd2/1X/WoVov/nkdf3k4/DQcdEhERLWHAZCbruUASKqgrAoqFbDn9BVM/XwPKqr1Th/jnh7NsGB0J+PkjMdzinHwfD5GdG6M1nN/Mdnv1Ts7e6ztRERE5hgAuam+BEBSgiDgrzNX0DAkAE0aBGHTPzl49Iu9Dj9+Qu8EPNQ/ESOXbEdhebXsPqlPDETr2DBPNZmIiMgEAyA31ccASI5eL2DrsUsordThpwMXsO5gNpITIjGxTwK+3nseW49ecup4g9vF4kppJZo3DMbU61uiecNgBAWI3WdZBWU4lVuCvi2ja+OlEBFRPcAAyE0MgCxV6/S4WFSBJg2CjNvO5JVg8qd/4VhOsc3HJjUKwclLJRbb/dQqPDwwCcs2nzBu++j+FNzULtZi38pqPbILytE8KtiNV0FERNcyBkBuYgDkHL1ewHtbT+D8lTL0TGyIWzrF462Nx7Bk03G8fpdY9/PUVwccOlZIgAb/GnIdBrWNwcXCcrRsFAqtvxqLUo/ikz9O45MHe6BPUhR0ekF2FFqVTo8Pt51C35ZR6NKsgSdfJhER+TgGQG5iAOQZucUViAoJQKVOj8/SzuCmdjFo3jAYizYexbubTtg/gBUatQrB/hosuLMTbm4fi8/SzmBAm2g0DA7A0s0nsCLtNADgjbu7YEDraMSGB3roFRERkS9jAOQmBkDekZlXitKqarRsFIrP/zyD8io9TlwqxvkrZfjzVB489Zf51NDr8PCAJAT4yQ/DP3u5FE99tR99kqIxc3Br5JdW4umvDqBpZDDmjWhnHOFGRES+jQGQmxgAKe94ThHSTuShWcNgCIKAXaeuYP3f2UiMDsGmIzluBUcDWkfj1k7xaN84HK1iQnHnsh3IyBInh2zZKAQnJPVKH0xMwc3tLWuSbBEEgUETEZECGAC5iQGQb6vS6fHQit04f6UME/skIO1EHjo1iUC/1tG4WFCO3aev4OM/Tnns+Wbf3Ab9WkWhTWwYVu3KxLZjuXhyyHUmNUYlFdUIDtDg3U3H8cG2U3jh9va4o1tTj7WBiIjsYwDkJgZAdV9pZTVW7TqLO7o1wbZjlzBzdbrDj20fH457ejbDK+syUF5lfXLIYR3i8Ovf2cbbbePC8E92kfH2PT2aQaUCwgP9cUuneDRrGIzVuzNRrRNQUa1DpyYRGNYx3qXXR0RElhgAuYkB0LVNEARU6wXoBQHr/xYXgr21Uzw0atNuq2/2nsOqXZnIKijHuStltdae7s0b4KH+ibguNgxHLhYhoWEIOjWNAAAUlVfhrY3HsPv0Zcy5pR16J0Uhu6Acr68/gn6tojCyaxOLdhMR1VcMgNzEAIjM5RSWY2/mFaSdyMPOk5cBAKGBfthz5gqmXt8S8RGB+ON4LlrFhGJCnwQ8uXY//jie5/LztY0LQ4uoEPz2z0VU6Wr+Rbs2a4ATl4pRdHW27a7NGuD6No3QMCQAPRMbomWjULy35QT0goDGEUG4K7kp1GoVyip1yCooQ1KjUPdOBBGRD2MA5CYGQOQJ566UoqxSh4KyKggAsgrKMaJTPE7mluCrPedw9kopfj6QVattCPLX4N5ezbEx4yIyL5di2fjuaBiixapdmTiVW4LTeSVIbh6J7gmR+HH/BfyTXYQ1U3qjV1KU7PGO5xTjSHYRerSIRMzV6QWcLfrW6wUUV1ZD66dGeaUeoYF+zGIRkUcwAHITAyDyJkEQUF6lx+GsApy4VIIdJ/JQXqXDxcJyXCquwNxb2kPrr8ZXf51DdmE5rosLw329EpB2Ihcv/ZxRa+3q0DgcIVo/XMgvQ4CfGk0aBGHbsVzj/R2bhEOjUmH/uQIAQIuoYJRU6hAW6Iei8mo0CtViwehOqNYL2PRPDrIKyvHnyTyczzftTrwruSneuLsLR88RkdsYALmJARDVFYIgoKCsCs//8DcuFpYjMToUrWNCcbGoHCqo8MG2k9DpBQxuF4ONGTkWjw/0VyM5IRI7TuRB7yPvBMM6xOHAuXxcKa1CfEQgoALaxYcjPNAfIzrHI7tADAL/vlCAA+cK8MjAltAJAqp0evx6KBsJUcG4qV0sfj5wAafzSvHoDS0RHuiP8iod/NQqVOsFBPprlH6ZRFQLGAC5iQEQXYuqdHqcvVyKk5dK0CI6GI3CAhER5A8AyCkqR1Z+OQ6cy8ep3FJ8/McpdGgcjs5NGyA8yA9r/zqHyyWViAz2R2F5NeLCA6H1V8uu8WZNl2YNkJVfhls6xaN7QiTCtH54cMXu2nq5RlEhAcgrqTTeDtCoER7kj9ziCtzaOR6Bfhps+Dsbg9vHYlDbGDSNDMLbvx1D5yYRGNGlMQrLqlBcUY0+LaOg9dNg05EcLN9yEioV0CcpChqNCr9n5KBb8wZ4sF8iLpdUom1cGPw0NRNvGrJbFdU6FJdXIypUa7W9ldV6q5N2EpFtDIDcxACIyDXlVTrsPXMF0WFaNG8YjOM5xSit1CE+IhDNGlouZCsIAub/dBhpx/NQWF6FrIJyJEaH4FRuCdrGhWHq9S3x04EL2HosF5XV1qckMAgP9EOo1g8XCspr4+UhyF+Dsiqdw/snRYegRXQI/jp9GaO7N8WuU5dx+Oqkm00aBGFgm2gE+YvdjG3jwwAAy7eeRGmlDknRIXh6WFvszbyChwckQeuvxvfpF3BDm0bYcTIPGVmF2HPmCvKKK3F3SlP4a9SICglAxyYR6NgkwqJL0fx2WaUO+zKvoHdSFNRWarDOXSlFmNYfEcH+TnVRsjuTlMIAyE0MgIiUJXcBLSqvwh/H85DSIhINgwOgVqtwOrcEu09fxqXiCmTll2PGTa0QExaInKJylFbooFGr8Mkfp7E38wpO5ZagZaMQ3JncFF/vOYe9mfkAxCBldPcmyC2uxNajl3Ay135Wq01sKFpEhWDD4Yu18fI9IjhAA3+NGgVlVSbbHxmYBK2fGr8cysaxnGIAwNAOsWjcIAhbjl7CyUsl6JMUhfyyKmRkFcJfo8Jdyc2walcmAGDW4NY4llOM8kodwoP8ERseiBuua4QVV89ztV5ASUU1BrRuhFCtBrHhYvBbpdOjZaNQtI0LQ6MwLfJKKvFm6lFsOXIJA1pH45lhbaH1V+PQ+UKkJESiWi8YM2E6vYDSymrkl1ahSYMgqwGbPYYJS8ur9NAJAjb8nY1B18Ug9fBFXCwsxyPXtzQ+p14v4OD5AqhUQOemDWwe13COI4L8caWkEvllVUiMDnGpjUo4nlOEPWeuoFvzSDSLDEZQQN3tImYA5CYGQETXPkEQkFtciaiQAJML6pHsIjSNDIK/Ro1qvR7ZBeW4UlqFQH81Kqv10AsCujePhEolBmBVOj1aRIdAf/V4GpUKGw5nY8eJPJRU6hDkr8bZy2Vi91dFNS4WVgAAIoP9caVUvHC2jQuD9mpdUmJUMA5dKMTxq8FJfWYIlo5eLDKeNwDomdgQnZtEQOuvRl5xJQrKxMCoqLwal0srcfhCIZIahZgU7Sc1CrHbZZsYHYJLRRUICtDgUlHN8w3vGIfLJZXYeeqy8femUgH9W0UjVOuH9X9nW9TQ3dIpDofOF6K8SofB7WPRtWkDXCgQBwD4a9TYmHERBWVVuKNrExRVVEOlAqqqBVTr9ajSCQjQqCBA7Gbt3zoaecWViA7Twl+jwsfbT6OsshpNIoOg0wMr0k6hRVQIxvVsjiulldh+PBeNI4IwuH0sfki/gB/2n8eQDnEI0/oh0F+Drs0bQKtRo01cGJb8fty4gLTUmJSm6JkYBf3VQPG2Lo3RtVkDNI0Mthi1WVGtQ7VOQIjWz8HfbO1hAOQmBkBE5A3nrpSiQXAAQmUuHCUV1bhYWI6IIH/oBAH5pVUIC/TDkewixEcE4UxeCdrGhSMs0A9LNh2H1k+Nh/on4kROMQ6eL8C5K2U4k1eCg+cLMLRDHLR+Gnyffh4qFaD106B7QiRiw7S4VFyB07kliA0PxKncEmNW6PW7OqNdfDh+/ycHW49ewl9nrqBRmBZhWj9jlqxXYkNcKqowyZo90LcFMrIKse9sPiqr9XYDjwbBYh1afmmV1X1IpFLBY4tEu6phSAAEQYC/Rg21SoWIIH+cuFQMtVqF6JAAqFQqNAoTa9wCNGqEBvohNjwQp3NLUFhehZaNQrH79GVEBPnjldGd0L15pEfbV6cCoKVLl+L1119HVlYWOnTogMWLF2PAgAFW99+yZQtmz56Nv//+G40bN8bTTz+NqVOnmuzz9ddfY968eThx4gRatmyJl19+GXfccYfDbWIARET1VX5pJYICNND6Od4NkltcgZAAP5OuE2nh97qDWbjxulhABZy/UoY/jucit7gC9/ZqjoSoEJRV6rDl6CXoBQFNGgThSmklGoVp8feFQmhUKkSGiEHS8Zxi7D9bgFCtH6r0elRU69G8YTD8NWoczylCoJ8Gf57Mw4WCcsRHBKJBcACyC8oQHOCHXokNUanTI6lRKGLCtEhqFIIAjdgV2L91NC4VVeCd34+hslqPMSnN0CwyGFuOXkJGViFyiipQXCFOPhqq9cPIro1RVF6NQxfEtsSEabHpyCXo9AJubBuDwrIqHDhfgMpqPVQqoFGoFmqVCg2C/ZFTVAGdXkDnphEI9NegvEqHwxcKoVGrEKL1w83tY1FUXoWNGTkmWShHaP3UqJCplWsRFYyCsiro9GKWpqi82vh6AHGU5bLx3fHj/gvYfeYKth695NTzuioqJADbnhmE4ADPZY7qTAC0Zs0aTJgwAUuXLkW/fv3w/vvv48MPP8Thw4fRvHlzi/1PnTqFjh074uGHH8YjjzyCP/74A9OmTcOqVatw5513AgB27NiBAQMG4L///S/uuOMOfPvtt3juueewfft29OrVy6F2MQAiIiJn2Ss8d/WYW4/lokGQPxqFaXGxsByNGwQhNjwQVTo9cosrcCq3BN2aRUKtBnafuoL2jcMRHKDB3jNXEBcRKDsDfHmVDuln8xEW6IcOjSMs7tfrBahUgEqlwpWSShRXVKOsSocrJZW4VFyB8EB/HL1YhEB/DaJDA1BRrUdheTWC/DXw16igFwQUlVejokqPgrIqLN92EpXVerSNC0PHJhHIKarAg/1aYNB1MW6dH3N1JgDq1asXunfvjmXLlhm3tWvXDqNGjcKCBQss9n/mmWfwww8/ICOjZvK3qVOnYv/+/dixYwcAYOzYsSgsLMQvv/xi3GfYsGGIjIzEqlWrHGoXAyAiIqLaU1sjBZ25fis22URlZSX27NmDIUOGmGwfMmQI0tLSZB+zY8cOi/2HDh2Kv/76C1VVVTb3sXZMAKioqEBhYaHJFxEREdUOX5gmQbEAKDc3FzqdDrGxsSbbY2NjkZ2dLfuY7Oxs2f2rq6uRm5trcx9rxwSABQsWICIiwvjVrFkzV14SERER1RGKTzdqHgXaS4vJ7W++3dljzpkzBwUFBcavs2fPOtx+IiIiqnsUG7QfHR0NjUZjkZnJycmxyOAYxMXFye7v5+eHqKgom/tYOyYAaLVaaLXWp6YnIiKia4tiGaCAgAAkJycjNTXVZHtqair69u0r+5g+ffpY7L9hwwakpKTA39/f5j7WjklERET1j6LTNs6ePRsTJkxASkoK+vTpg+XLlyMzM9M4r8+cOXNw/vx5fPbZZwDEEV9LlizB7Nmz8fDDD2PHjh346KOPTEZ3zZw5EwMHDsRrr72GkSNH4vvvv8fGjRuxfft2RV4jERER+R5FA6CxY8ciLy8P8+fPR1ZWFjp27Ih169YhISEBAJCVlYXMzEzj/omJiVi3bh2eeOIJvPvuu2jcuDHefvtt4xxAANC3b1+sXr0azz77LObNm4eWLVtizZo1Ds8BRERERNc+xWeC9kWcB4iIiKjuqRPzABEREREphQEQERER1TsMgIiIiKjeYQBERERE9Q4DICIiIqp3GAARERFRvaPoPEC+yjAzAFeFJyIiqjsM121HZvhhACSjqKgIALgqPBERUR1UVFSEiIgIm/twIkQZer0eFy5cQFhYmM1V5F1RWFiIZs2a4ezZs5xksRbxPHsHz7P38Fx7B8+zd9TWeRYEAUVFRWjcuDHUattVPswAyVCr1WjatGmtPkd4eDj/ubyA59k7eJ69h+faO3ievaM2zrO9zI8Bi6CJiIio3mEARERERPUOAyAv02q1eP7556HVapVuyjWN59k7eJ69h+faO3ievcMXzjOLoImIiKjeYQaIiIiI6h0GQERERFTvMAAiIiKieocBEBEREdU7DIC8aOnSpUhMTERgYCCSk5Oxbds2pZtUpyxYsAA9evRAWFgYYmJiMGrUKBw5csRkH0EQ8MILL6Bx48YICgrCDTfcgL///ttkn4qKCsyYMQPR0dEICQnB7bffjnPnznnzpdQpCxYsgEqlwqxZs4zbeJ494/z587jvvvsQFRWF4OBgdO3aFXv27DHez/PsGdXV1Xj22WeRmJiIoKAgJCUlYf78+dDr9cZ9eK6dt3XrVtx2221o3LgxVCoVvvvuO5P7PXVOr1y5ggkTJiAiIgIRERGYMGEC8vPz3X8BAnnF6tWrBX9/f+GDDz4QDh8+LMycOVMICQkRzpw5o3TT6oyhQ4cKn3zyiXDo0CEhPT1duPXWW4XmzZsLxcXFxn1effVVISwsTPj666+FgwcPCmPHjhXi4+OFwsJC4z5Tp04VmjRpIqSmpgp79+4VBg0aJHTp0kWorq5W4mX5tF27dgktWrQQOnfuLMycOdO4nefZfZcvXxYSEhKEBx54QNi5c6dw6tQpYePGjcLx48eN+/A8e8ZLL70kREVFCT/99JNw6tQpYe3atUJoaKiwePFi4z48185bt26dMHfuXOHrr78WAAjffvutyf2eOqfDhg0TOnbsKKSlpQlpaWlCx44dhREjRrjdfgZAXtKzZ09h6tSpJtvatm0r/Pvf/1aoRXVfTk6OAEDYsmWLIAiCoNfrhbi4OOHVV1817lNeXi5EREQI7733niAIgpCfny/4+/sLq1evNu5z/vx5Qa1WC7/++qt3X4CPKyoqElq3bi2kpqYK119/vTEA4nn2jGeeeUbo37+/1ft5nj3n1ltvFR566CGTbaNHjxbuu+8+QRB4rj3BPADy1Dk9fPiwAED4888/jfvs2LFDACD8888/brWZXWBeUFlZiT179mDIkCEm24cMGYK0tDSFWlX3FRQUAAAaNmwIADh16hSys7NNzrNWq8X1119vPM979uxBVVWVyT6NGzdGx44d+bsw89hjj+HWW2/F4MGDTbbzPHvGDz/8gJSUFNx9992IiYlBt27d8MEHHxjv53n2nP79++O3337D0aNHAQD79+/H9u3bccsttwDgua4NnjqnO3bsQEREBHr16mXcp3fv3oiIiHD7vHMxVC/Izc2FTqdDbGysyfbY2FhkZ2cr1Kq6TRAEzJ49G/3790fHjh0BwHgu5c7zmTNnjPsEBAQgMjLSYh/+LmqsXr0ae/fuxe7duy3u43n2jJMnT2LZsmWYPXs2/vOf/2DXrl14/PHHodVqMXHiRJ5nD3rmmWdQUFCAtm3bQqPRQKfT4eWXX8a4ceMA8G+6NnjqnGZnZyMmJsbi+DExMW6fdwZAXqRSqUxuC4JgsY0cM336dBw4cADbt2+3uM+V88zfRY2zZ89i5syZ2LBhAwIDA63ux/PsHr1ej5SUFLzyyisAgG7duuHvv//GsmXLMHHiRON+PM/uW7NmDT7//HOsXLkSHTp0QHp6OmbNmoXGjRvj/vvvN+7Hc+15njincvt74ryzC8wLoqOjodFoLKLVnJwci+iY7JsxYwZ++OEHbNq0CU2bNjVuj4uLAwCb5zkuLg6VlZW4cuWK1X3quz179iAnJwfJycnw8/ODn58ftmzZgrfffht+fn7G88Tz7J74+Hi0b9/eZFu7du2QmZkJgH/PnvTUU0/h3//+N+655x506tQJEyZMwBNPPIEFCxYA4LmuDZ46p3Fxcbh48aLF8S9duuT2eWcA5AUBAQFITk5GamqqyfbU1FT07dtXoVbVPYIgYPr06fjmm2/w+++/IzEx0eT+xMRExMXFmZznyspKbNmyxXiek5OT4e/vb7JPVlYWDh06xN/FVTfddBMOHjyI9PR041dKSgrGjx+P9PR0JCUl8Tx7QL9+/SymcTh69CgSEhIA8O/Zk0pLS6FWm17uNBqNcRg8z7Xneeqc9unTBwUFBdi1a5dxn507d6KgoMD98+5WCTU5zDAM/qOPPhIOHz4szJo1SwgJCRFOnz6tdNPqjEcffVSIiIgQNm/eLGRlZRm/SktLjfu8+uqrQkREhPDNN98IBw8eFMaNGyc77LJp06bCxo0bhb179wo33nhjvR7K6gjpKDBB4Hn2hF27dgl+fn7Cyy+/LBw7dkz44osvhODgYOHzzz837sPz7Bn333+/0KRJE+Mw+G+++UaIjo4Wnn76aeM+PNfOKyoqEvbt2yfs27dPACC8+eabwr59+4zTu3jqnA4bNkzo3LmzsGPHDmHHjh1Cp06dOAy+rnn33XeFhIQEISAgQOjevbtx+DY5BoDs1yeffGLcR6/XC88//7wQFxcnaLVaYeDAgcLBgwdNjlNWViZMnz5daNiwoRAUFCSMGDFCyMzM9PKrqVvMAyCeZ8/48ccfhY4dOwparVZo27atsHz5cpP7eZ49o7CwUJg5c6bQvHlzITAwUEhKShLmzp0rVFRUGPfhuXbepk2bZN+T77//fkEQPHdO8/LyhPHjxwthYWFCWFiYMH78eOHKlStut18lCILgXg6JiIiIqG5hDRARERHVOwyAiIiIqN5hAERERET1DgMgIiIiqncYABEREVG9wwCIiIiI6h0GQERERFTvMAAiIiKieocBEBGRA1QqFb777julm0FEHsIAiIh83gMPPACVSmXxNWzYMKWbRkR1lJ/SDSAicsSwYcPwySefmGzTarUKtYaI6jpmgIioTtBqtYiLizP5ioyMBCB2Ty1btgzDhw9HUFAQEhMTsXbtWpPHHzx4EDfeeCOCgoIQFRWFKVOmoLi42GSfjz/+GB06dIBWq0V8fDymT59ucn9ubi7uuOMOBAcHo3Xr1vjhhx9q90UTUa1hAERE14R58+bhzjvvxP79+3Hfffdh3LhxyMjIAACUlpZi2LBhiIyMxO7du7F27Vps3LjRJMBZtmwZHnvsMUyZMgUHDx7EDz/8gFatWpk8x4svvogxY8bgwIEDuOWWWzB+/HhcvnzZq6+TiDzE7fXkiYhq2f333y9oNBohJCTE5Gv+/PmCIAgCAGHq1Kkmj+nVq5fw6KOPCoIgCMuXLxciIyOF4uJi4/0///yzoFarhezsbEEQBKFx48bC3LlzrbYBgPDss88abxcXFwsqlUr45ZdfPPY6ich7WANERHXCoEGDsGzZMpNtDRs2NP7cp08fk/v69OmD9PR0AEBGRga6dOmCkJAQ4/39+vWDXq/HkSNHoFKpcOHCBdx0000229C5c2fjzyEhIQgLC0NOTo6rL4mIFMQAiIjqhJCQEIsuKXtUKhUAQBAE489y+wQFBTl0PH9/f4vH6vV6p9pERL6BNUBEdE34888/LW63bdsWANC+fXukp6ejpKTEeP8ff/wBtVqNNm3aICwsDC1atMBvv/3m1TYTkXKYASKiOqGiogLZ2dkm2/z8/BAdHQ0AWLt2LVJSUtC/f3988cUX2LVrFz766CMAwPjx4/H888/j/vvvxwsvvIBLly5hxowZmDBhAmJjYwEAL7zwAqZOnYqYmBgMHz4cRUVF+OOPPzBjxgzvvlAi8goGQERUJ/z666+Ij4832Xbdddfhn3/+ASCO0Fq9ejWmTZuGuLg4fPHFF2jfvj0AIDg4GOvXr8fMmTPRo0cPBAcH484778Sbb75pPNb999+P8vJyLFq0CE8++SSio6Nx1113ee8FEpFXqQRBEJRuBBGRO1QqFb799luMGjVK6aYQUR3BGiAiIiKqdxgAERERUb3DGiAiqvPYk09EzmIGiIiIiOodBkBERERU7zAAIiIionqHARARERHVOwyAiIiIqN5hAERERET1DgMgIiIiqncYABEREVG98/+nRTRw3EwOuAAAAABJRU5ErkJggg==","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Plot the training and validation loss\n","import matplotlib.pyplot as plt\n","plt.plot(history.history['loss'], label='Train Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Plot the training and validation MAE\n","plt.plot(history.history['mae'], label='Train MAE')\n","plt.plot(history.history['val_mae'], label='Validation MAE')\n","plt.xlabel('Epoch')\n","plt.ylabel('MAE')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["model.load_weights(\"weights.best.conv1d_sample.hdf5\")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Optimal Epoch: 6 loss: 0.1808803677558899\n"]}],"source":["# Find the epoch with the minimum validation loss\n","optimal_epoch = history.history['val_loss'].index(min(history.history['val_loss'])) + 1\n","print(f\"Optimal Epoch: {optimal_epoch} loss: {history.history['val_loss'][optimal_epoch-1]}\")"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["75/75 [==============================] - 0s 974us/step\n"]}],"source":["# Evaluate the model on the test set\n","results = model.evaluate([seq_test, vae_test], y_test)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Loss: 0.1808844546477\n","Test MAE: 0.3254185616970062\n"]}],"source":["# Print the evaluation results\n","print(\"Test Loss:\", results[0])\n","print(\"Test MAE:\", results[1])"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1.         0.31882353]\n"," [0.31882353 1.        ]]\n","0.07572315779325967\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import r2_score\n","import numpy as np\n","y_pred = model.predict([seq_test, vae_test])\n","print(np.corrcoef(y_test, y_pred.ravel()))\n","print(r2_score(y_test, y_pred))\n","plt.scatter(y_test, y_pred)\n","m, b = np.polyfit(y_test, y_pred, 1)\n","plt.plot(y_test, m * y_test + b, 'r')\n","plt.xlabel('Actual')\n","plt.ylabel('Predicted')\n","plt.title('Actual vs Predicted')\n","plt.show()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["[array([-0.67174363], dtype=float32),\n"," array([-0.3846093], dtype=float32),\n"," array([-0.3818252], dtype=float32),\n"," array([-0.2596602], dtype=float32),\n"," array([-0.25801423], dtype=float32),\n"," array([-0.19275679], dtype=float32),\n"," array([-0.14100868], dtype=float32),\n"," array([-0.09996159], dtype=float32),\n"," array([-0.03030224], dtype=float32),\n"," array([-0.02734188], dtype=float32),\n"," array([-0.02017586], dtype=float32),\n"," array([-0.01468224], dtype=float32),\n"," array([-0.0097595], dtype=float32),\n"," array([-0.00876785], dtype=float32),\n"," array([0.01248593], dtype=float32),\n"," array([0.01259153], dtype=float32),\n"," array([0.01343347], dtype=float32),\n"," array([0.02046904], dtype=float32),\n"," array([0.02523689], dtype=float32),\n"," array([0.02525518], dtype=float32),\n"," array([0.03836064], dtype=float32),\n"," array([0.04477905], dtype=float32),\n"," array([0.06328207], dtype=float32),\n"," array([0.06334299], dtype=float32),\n"," array([0.06469428], dtype=float32),\n"," array([0.0649727], dtype=float32),\n"," array([0.06569352], dtype=float32),\n"," array([0.06889957], dtype=float32),\n"," array([0.06903666], dtype=float32),\n"," array([0.07702007], dtype=float32),\n"," array([0.083898], dtype=float32),\n"," array([0.08810741], dtype=float32),\n"," array([0.09655201], dtype=float32),\n"," array([0.09658281], dtype=float32),\n"," array([0.09768911], dtype=float32),\n"," array([0.09889051], dtype=float32),\n"," array([0.10269366], dtype=float32),\n"," array([0.10498689], dtype=float32),\n"," array([0.10649078], dtype=float32),\n"," array([0.10661963], dtype=float32),\n"," array([0.11039416], dtype=float32),\n"," array([0.11580789], dtype=float32),\n"," array([0.12235779], dtype=float32),\n"," array([0.12243804], dtype=float32),\n"," array([0.12508044], dtype=float32),\n"," array([0.12693137], dtype=float32),\n"," array([0.12696613], dtype=float32),\n"," array([0.1288494], dtype=float32),\n"," array([0.1312116], dtype=float32),\n"," array([0.1343487], dtype=float32),\n"," array([0.14171554], dtype=float32),\n"," array([0.14911823], dtype=float32),\n"," array([0.14931813], dtype=float32),\n"," array([0.149956], dtype=float32),\n"," array([0.15457667], dtype=float32),\n"," array([0.15529272], dtype=float32),\n"," array([0.15851983], dtype=float32),\n"," array([0.16133164], dtype=float32),\n"," array([0.16607071], dtype=float32),\n"," array([0.1664769], dtype=float32),\n"," array([0.170501], dtype=float32),\n"," array([0.17585684], dtype=float32),\n"," array([0.17604329], dtype=float32),\n"," array([0.17927326], dtype=float32),\n"," array([0.1799192], dtype=float32),\n"," array([0.1799245], dtype=float32),\n"," array([0.18556172], dtype=float32),\n"," array([0.18994154], dtype=float32),\n"," array([0.19162317], dtype=float32),\n"," array([0.1930601], dtype=float32),\n"," array([0.20095997], dtype=float32),\n"," array([0.20574166], dtype=float32),\n"," array([0.2253067], dtype=float32),\n"," array([0.29327086], dtype=float32),\n"," array([0.34784648], dtype=float32)]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["sorted(y_pred)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["['model.joblib']"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Save model\n","from joblib import dump, load\n","dump(dleps_p.model[0], 'model.joblib')"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["<keras.engine.training.Model at 0x1d003b8cf08>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Run the test set\n","model = load('model.joblib')\n","model"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[1., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 1., 0., 0.],\n        [0., 0., 0., ..., 1., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 1.],\n        [0., 0., 0., ..., 0., ...","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12304\\1081794900.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mh5f_zinc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../data/SMILES_zinc_fda.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mzinc_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f_zinc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mzinc_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzinc_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mzinc_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    107\u001b[0m                 \u001b[1;34m'Expected to see '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' array(s), '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[1;34m'but instead got the following list of '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             raise ValueError(\n","\u001b[1;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[1., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 1., 0., 0.],\n        [0., 0., 0., ..., 1., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 1.],\n        [0., 0., 0., ..., 0., ..."]}],"source":["h5f_zinc = h5py.File('../../data/SMILES_zinc_fda.h5', 'r')\n","zinc_test = h5f_zinc['data'][:]\n","zinc_pred = model.predict(zinc_test)\n","zinc_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["1615"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# Merge test results column to the test dataset\n","import pandas as pd\n","zinc_fda_test = pd.read_csv('../../data/fda_zinc.csv')\n","len(zinc_fda_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Length of values (1612) does not match length of index (1615)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3736\\687071671.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mzinc_fda_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'results'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzinc_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mzinc_fda_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3611\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3783\u001b[0m         \"\"\"\n\u001b[1;32m-> 3784\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3786\u001b[0m         if (\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4509\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         raise ValueError(\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[1;34m\"does not match length of index \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: Length of values (1612) does not match length of index (1615)"]}],"source":["zinc_fda_test['results'] = zinc_pred\n","zinc_fda_test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### End"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1041, 1)\n","(1041, 1)\n","[ 0. nan]\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\numpy\\lib\\function_base.py:2683: RuntimeWarning: Degrees of freedom <= 0 for slice\n","  c = cov(x, y, rowvar, dtype=dtype)\n","c:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\numpy\\lib\\function_base.py:2542: RuntimeWarning: divide by zero encountered in true_divide\n","  c *= np.true_divide(1, fact)\n","c:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\numpy\\lib\\function_base.py:2542: RuntimeWarning: invalid value encountered in multiply\n","  c *= np.true_divide(1, fact)\n"]}],"source":["y_pred = dleps_p.model[0].predict(smile_train)\n","rna_train = np.reshape(rna_train, y_pred.shape)\n","print(rna_train.shape)\n","print(y_pred.shape)\n","corr = np.array([0.])\n","corr=np.hstack((corr,np.corrcoef(rna_train[0],y_pred[0])[0, 1]))\n","print(corr)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1041, 277, 76)\n","(1041, 1)\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcOklEQVR4nO3df3TVdf3A8dcGbrOjGxixCa3v+mGaqUAQcxbHY2e5jEjOqRMHPUIc0uqYmauT4A/mj3LYUVsnKY6ox/7xgHrS0wnCY0tOx1ySIOdoiR1FgtQNiNNGwzbZPt8/PM4mG+wi25s7H49z7h98eL/vfd2Pkz3P5967FWRZlgUAQCKFqQcAAN7bxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQ1NvUAQ9Hb2xuvvvpqnHjiiVFQUJB6HABgCLIsi3379sWkSZOisHDw6x95ESOvvvpqVFZWph4DADgCO3fujA9+8IOD/n1exMiJJ54YEW8+mdLS0sTTAABD0dHREZWVlX3fxweTFzHy1kszpaWlYgQA8szh3mLhDawAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASCrnGPnjH/8Yc+bMiUmTJkVBQUE88sgjh92zYcOG+NSnPhXFxcXxsY99LO67774jGBUAGI1yjpHOzs6YMmVKrFixYkjrX3755Zg9e3acd955sWXLlvje974X3/jGN+LRRx/NeVgAYPTJ+RflXXDBBXHBBRcMef3KlSvjwx/+cNx+++0REfGJT3winnjiifjpT38adXV1uT48ADDKDPt7RlpaWqK2trbfsbq6umhpaRl0T1dXV3R0dPS7AQCjU85XRnLV2toa5eXl/Y6Vl5dHR0dHvP7663H88ccftKexsTFuvPHG4R4NOEZULVl72DXbl88egUmAFI7JT9MsXbo02tvb+247d+5MPRIAMEyG/cpIRUVFtLW19TvW1tYWpaWlA14ViYgoLi6O4uLi4R4NADgGDPuVkZqammhubu537LHHHouamprhfmgAIA/kHCP/+c9/YsuWLbFly5aIePOju1u2bIkdO3ZExJsvsSxYsKBv/be+9a3Ytm1b/PCHP4ytW7fGL37xi3jggQfiqquuOjrPAADIaznHyNNPPx3Tpk2LadOmRUREfX19TJs2LZYtWxYREa+99lpfmEREfPjDH461a9fGY489FlOmTInbb7897r77bh/rBQAiIqIgy7Is9RCH09HREWVlZdHe3h6lpaWpxwGOMp+mgdFpqN+/j8lP0wAA7x1iBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAIKkjipEVK1ZEVVVVlJSURHV1dWzcuPGQ65uamuLUU0+N448/PiorK+Oqq66K//73v0c0MAAwuuQcI2vWrIn6+vpoaGiIzZs3x5QpU6Kuri527do14Pr7778/lixZEg0NDfH888/HPffcE2vWrIlrrrnmXQ8PAOS/nGPkjjvuiEsvvTQWLVoUp59+eqxcuTLe9773xb333jvg+ieffDI+85nPxEUXXRRVVVVx/vnnx/z58w97NQUAeG/IKUa6u7tj06ZNUVtb+/YdFBZGbW1ttLS0DLjnnHPOiU2bNvXFx7Zt22LdunXxxS9+cdDH6erqio6Ojn43AGB0GpvL4j179kRPT0+Ul5f3O15eXh5bt24dcM9FF10Ue/bsic9+9rORZVkcOHAgvvWtbx3yZZrGxsa48cYbcxkNAMhTw/5pmg0bNsQtt9wSv/jFL2Lz5s3x61//OtauXRs333zzoHuWLl0a7e3tfbedO3cO95gAQCI5XRmZMGFCjBkzJtra2vodb2tri4qKigH3XH/99XHJJZfEN77xjYiIOPPMM6OzszMuu+yyuPbaa6Ow8OAeKi4ujuLi4lxGAwDyVE5XRoqKimL69OnR3Nzcd6y3tzeam5ujpqZmwD379+8/KDjGjBkTERFZluU6LwAwyuR0ZSQior6+PhYuXBgzZsyImTNnRlNTU3R2dsaiRYsiImLBggUxefLkaGxsjIiIOXPmxB133BHTpk2L6urqePHFF+P666+POXPm9EUJAPDelXOMzJs3L3bv3h3Lli2L1tbWmDp1aqxfv77vTa07duzodyXkuuuui4KCgrjuuuvilVdeiQ984AMxZ86c+PGPf3z0ngUAkLcKsjx4raSjoyPKysqivb09SktLU48DHGVVS9Yeds325bNHYBLgaBrq92+/mwYASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACCpI4qRFStWRFVVVZSUlER1dXVs3LjxkOv//e9/x+WXXx4nn3xyFBcXx8c//vFYt27dEQ0MAIwuY3PdsGbNmqivr4+VK1dGdXV1NDU1RV1dXbzwwgsxceLEg9Z3d3fH5z//+Zg4cWI89NBDMXny5PjHP/4R48aNOxrzAwB5LucYueOOO+LSSy+NRYsWRUTEypUrY+3atXHvvffGkiVLDlp/7733xt69e+PJJ5+M4447LiIiqqqq3t3UAMCokdPLNN3d3bFp06aora19+w4KC6O2tjZaWloG3POb3/wmampq4vLLL4/y8vI444wz4pZbbomenp5BH6erqys6Ojr63QCA0SmnGNmzZ0/09PREeXl5v+Pl5eXR2to64J5t27bFQw89FD09PbFu3bq4/vrr4/bbb48f/ehHgz5OY2NjlJWV9d0qKytzGRMAyCPD/mma3t7emDhxYtx1110xffr0mDdvXlx77bWxcuXKQfcsXbo02tvb+247d+4c7jEBgERyes/IhAkTYsyYMdHW1tbveFtbW1RUVAy45+STT47jjjsuxowZ03fsE5/4RLS2tkZ3d3cUFRUdtKe4uDiKi4tzGQ0AyFM5XRkpKiqK6dOnR3Nzc9+x3t7eaG5ujpqamgH3fOYzn4kXX3wxent7+479/e9/j5NPPnnAEAEA3ltyfpmmvr4+Vq1aFb/61a/i+eefj29/+9vR2dnZ9+maBQsWxNKlS/vWf/vb3469e/fGlVdeGX//+99j7dq1ccstt8Tll19+9J4FAJC3cv5o77x582L37t2xbNmyaG1tjalTp8b69ev73tS6Y8eOKCx8u3EqKyvj0UcfjauuuirOOuusmDx5clx55ZVx9dVXH71nAQDkrYIsy7LUQxxOR0dHlJWVRXt7e5SWlqYeBzjKqpasPeya7ctnj8AkwNE01O/ffjcNAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUkcUIytWrIiqqqooKSmJ6urq2Lhx45D2rV69OgoKCmLu3LlH8rAAwCiUc4ysWbMm6uvro6GhITZv3hxTpkyJurq62LVr1yH3bd++PX7wgx/ErFmzjnhYAGD0yTlG7rjjjrj00ktj0aJFcfrpp8fKlSvjfe97X9x7772D7unp6YmLL744brzxxvjIRz7yrgYGAEaXnGKku7s7Nm3aFLW1tW/fQWFh1NbWRktLy6D7brrpppg4cWIsXrx4SI/T1dUVHR0d/W4AwOiUU4zs2bMnenp6ory8vN/x8vLyaG1tHXDPE088Effcc0+sWrVqyI/T2NgYZWVlfbfKyspcxgQA8siwfppm3759cckll8SqVatiwoQJQ963dOnSaG9v77vt3LlzGKcEAFIam8viCRMmxJgxY6Ktra3f8ba2tqioqDho/UsvvRTbt2+POXPm9B3r7e1984HHjo0XXnghPvrRjx60r7i4OIqLi3MZDQDIUzldGSkqKorp06dHc3Nz37He3t5obm6Ompqag9afdtpp8eyzz8aWLVv6bl/+8pfjvPPOiy1btnj5BQDI7cpIRER9fX0sXLgwZsyYETNnzoympqbo7OyMRYsWRUTEggULYvLkydHY2BglJSVxxhln9Ns/bty4iIiDjgMA7005x8i8efNi9+7dsWzZsmhtbY2pU6fG+vXr+97UumPHjigs9INdAYChKciyLEs9xOF0dHREWVlZtLe3R2lpaepxgKOsasnaw67Zvnz2CEwCHE1D/f7tEgYAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASOqIYmTFihVRVVUVJSUlUV1dHRs3bhx07apVq2LWrFkxfvz4GD9+fNTW1h5yPQDw3pJzjKxZsybq6+ujoaEhNm/eHFOmTIm6urrYtWvXgOs3bNgQ8+fPj8cffzxaWlqisrIyzj///HjllVfe9fAAQP4ryLIsy2VDdXV1fPrTn44777wzIiJ6e3ujsrIyrrjiiliyZMlh9/f09MT48ePjzjvvjAULFgzpMTs6OqKsrCza29ujtLQ0l3GBPFC1ZO1h12xfPnsEJgGOpqF+/87pykh3d3ds2rQpamtr376DwsKora2NlpaWId3H/v3744033oiTTjpp0DVdXV3R0dHR7wYAjE45xciePXuip6cnysvL+x0vLy+P1tbWId3H1VdfHZMmTeoXNO/U2NgYZWVlfbfKyspcxgQA8siIfppm+fLlsXr16nj44YejpKRk0HVLly6N9vb2vtvOnTtHcEoAYCSNzWXxhAkTYsyYMdHW1tbveFtbW1RUVBxy72233RbLly+P3//+93HWWWcdcm1xcXEUFxfnMhoAkKdyujJSVFQU06dPj+bm5r5jvb290dzcHDU1NYPu+8lPfhI333xzrF+/PmbMmHHk0wIAo05OV0YiIurr62PhwoUxY8aMmDlzZjQ1NUVnZ2csWrQoIiIWLFgQkydPjsbGxoiIuPXWW2PZsmVx//33R1VVVd97S0444YQ44YQTjuJTAQDyUc4xMm/evNi9e3csW7YsWltbY+rUqbF+/fq+N7Xu2LEjCgvfvuDyy1/+Mrq7u+OrX/1qv/tpaGiIG2644d1NDwDkvZx/zkgKfs4IjG5+zgiMTsPyc0YAAI42MQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApI4oRlasWBFVVVVRUlIS1dXVsXHjxkOuf/DBB+O0006LkpKSOPPMM2PdunVHNCwAMPrkHCNr1qyJ+vr6aGhoiM2bN8eUKVOirq4udu3aNeD6J598MubPnx+LFy+OZ555JubOnRtz586N55577l0PDwDkv4Isy7JcNlRXV8enP/3puPPOOyMiore3NyorK+OKK66IJUuWHLR+3rx50dnZGb/97W/7jp199tkxderUWLly5ZAes6OjI8rKyqK9vT1KS0tzGRfIA1VL1h52zfbls0dgEuBoGur377G53Gl3d3ds2rQpli5d2nessLAwamtro6WlZcA9LS0tUV9f3+9YXV1dPPLII4M+TldXV3R1dfX9ub29PSLefFLA6NPbtf+wa/z/D/nnrf9vD3fdI6cY2bNnT/T09ER5eXm/4+Xl5bF169YB97S2tg64vrW1ddDHaWxsjBtvvPGg45WVlbmMC4wiZU2pJwCO1L59+6KsrGzQv88pRkbK0qVL+11N6e3tjb1798b73//+KCgoSDhZeh0dHVFZWRk7d+70ktUwc65HhvM8MpznkeE895dlWezbty8mTZp0yHU5xciECRNizJgx0dbW1u94W1tbVFRUDLinoqIip/UREcXFxVFcXNzv2Lhx43IZddQrLS31hT5CnOuR4TyPDOd5ZDjPbzvUFZG35PRpmqKiopg+fXo0Nzf3Hevt7Y3m5uaoqakZcE9NTU2/9RERjz322KDrAYD3lpxfpqmvr4+FCxfGjBkzYubMmdHU1BSdnZ2xaNGiiIhYsGBBTJ48ORobGyMi4sorr4xzzz03br/99pg9e3asXr06nn766bjrrruO7jMBAPJSzjEyb9682L17dyxbtixaW1tj6tSpsX79+r43qe7YsSMKC9++4HLOOefE/fffH9ddd11cc801ccopp8QjjzwSZ5xxxtF7Fu8hxcXF0dDQcNDLWBx9zvXIcJ5HhvM8MpznI5PzzxkBADia/G4aACApMQIAJCVGAICkxAgAkJQYyQN79+6Niy++OEpLS2PcuHGxePHi+M9//jOkvVmWxQUXXBAFBQWH/H1A5H6e9+7dG1dccUWceuqpcfzxx8eHPvSh+O53v9v3u5R424oVK6KqqipKSkqiuro6Nm7ceMj1Dz74YJx22mlRUlISZ555Zqxbt26EJs1vuZznVatWxaxZs2L8+PExfvz4qK2tPex/F96U69fzW1avXh0FBQUxd+7c4R0wD4mRPHDxxRfHX//613jsscfit7/9bfzxj3+Myy67bEh7m5qa3vM/Qn+ocj3Pr776arz66qtx2223xXPPPRf33XdfrF+/PhYvXjyCUx/71qxZE/X19dHQ0BCbN2+OKVOmRF1dXezatWvA9U8++WTMnz8/Fi9eHM8880zMnTs35s6dG88999wIT55fcj3PGzZsiPnz58fjjz8eLS0tUVlZGeeff3688sorIzx5fsn1PL9l+/bt8YMf/CBmzZo1QpPmmYxj2t/+9rcsIrK//OUvfcd+97vfZQUFBdkrr7xyyL3PPPNMNnny5Oy1117LIiJ7+OGHh3na/PVuzvP/euCBB7KioqLsjTfeGI4x89LMmTOzyy+/vO/PPT092aRJk7LGxsYB13/ta1/LZs+e3e9YdXV19s1vfnNY58x3uZ7ndzpw4EB24oknZr/61a+Ga8RR4UjO84EDB7Jzzjknu/vuu7OFCxdmF1544QhMml9cGTnGtbS0xLhx42LGjBl9x2pra6OwsDCeeuqpQfft378/LrroolixYsUhfw8QbzrS8/xO7e3tUVpaGmPHHpO/g3LEdXd3x6ZNm6K2trbvWGFhYdTW1kZLS8uAe1paWvqtj4ioq6sbdD1Hdp7faf/+/fHGG2/ESSedNFxj5r0jPc833XRTTJw40VXTQ/Av5jGutbU1Jk6c2O/Y2LFj46STTorW1tZB91111VVxzjnnxIUXXjjcI44KR3qe/9eePXvi5ptvHvJLaO8Fe/bsiZ6enr6f0PyW8vLy2Lp164B7WltbB1w/1P8O70VHcp7f6eqrr45JkyYdFIK87UjO8xNPPBH33HNPbNmyZQQmzF+ujCSyZMmSKCgoOORtqP+IvNNvfvOb+MMf/hBNTU1Hd+g8NJzn+X91dHTE7Nmz4/TTT48bbrjh3Q8OI2j58uWxevXqePjhh6OkpCT1OKPGvn374pJLLolVq1bFhAkTUo9zTHNlJJHvf//78fWvf/2Qaz7ykY9ERUXFQW+MOnDgQOzdu3fQl1/+8Ic/xEsvvRTjxo3rd/wrX/lKzJo1KzZs2PAuJs8vw3me37Jv3774whe+ECeeeGI8/PDDcdxxx73bsUeNCRMmxJgxY6Ktra3f8ba2tkHPa0VFRU7rObLz/Jbbbrstli9fHr///e/jrLPOGs4x816u5/mll16K7du3x5w5c/qO9fb2RsSbV15feOGF+OhHPzq8Q+eL1G9a4dDeemPl008/3Xfs0UcfPeQbK1977bXs2Wef7XeLiOxnP/tZtm3btpEaPa8cyXnOsixrb2/Pzj777Ozcc8/NOjs7R2LUvDNz5szsO9/5Tt+fe3p6ssmTJx/yDaxf+tKX+h2rqanxBtbDyPU8Z1mW3XrrrVlpaWnW0tIyEiOOCrmc59dff/2gf4svvPDC7HOf+1z27LPPZl1dXSM5+jFNjOSBL3zhC9m0adOyp556KnviiSeyU045JZs/f37f3//zn//MTj311Oypp54a9D7Cp2kOK9fz3N7enlVXV2dnnnlm9uKLL2avvfZa3+3AgQOpnsYxZ/Xq1VlxcXF23333ZX/729+yyy67LBs3blzW2tqaZVmWXXLJJdmSJUv61v/pT3/Kxo4dm912223Z888/nzU0NGTHHXdc9uyzz6Z6Cnkh1/O8fPnyrKioKHvooYf6fe3u27cv1VPIC7me53fyaZqBiZE88K9//SubP39+dsIJJ2SlpaXZokWL+v2D8fLLL2cRkT3++OOD3ocYObxcz/Pjjz+eRcSAt5dffjnNkzhG/fznP88+9KEPZUVFRdnMmTOzP//5z31/d+6552YLFy7st/6BBx7IPv7xj2dFRUXZJz/5yWzt2rUjPHF+yuU8/9///d+AX7sNDQ0jP3ieyfXr+X+JkYEVZFmWjfRLQwAAb/FpGgAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQ1P8D6bppYo8oxWMAAAAASUVORK5CYII=","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["nan\n"]}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","%matplotlib inline\n","\n","y_pred = dleps_p.model[0].predict(smile_train)\n","\n","corr = np.array([0.])\n","\n","print(smile_train.shape)\n","\n","print(y_pred.shape)\n","for i in range(smile_train.shape[0]):\n","    \n","    corr=np.hstack((corr,np.corrcoef(rna_train[i],y_pred[i])[0, 1]))\n","plt.hist(corr,50)\n","plt.show()\n","print(corr.mean())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["array([ 0., nan, nan, ..., nan, nan, nan])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["corr"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from scipy.stats import gaussian_kde\n","\n","def density(x,y):\n","    xy = np.vstack([x,y])\n","    return gaussian_kde(xy)(xy)"]},{"cell_type":"markdown","metadata":{},"source":["Training set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\scipy\\stats\\kde.py:565: RuntimeWarning: Degrees of freedom <= 0 for slice\n","  aweights=self.weights))\n","c:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\numpy\\lib\\function_base.py:2542: RuntimeWarning: divide by zero encountered in true_divide\n","  c *= np.true_divide(1, fact)\n","c:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\numpy\\lib\\function_base.py:2542: RuntimeWarning: invalid value encountered in multiply\n","  c *= np.true_divide(1, fact)\n"]},{"ename":"ValueError","evalue":"array must not contain infs or NaNs","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3736\\2690619592.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msam\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrna_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msam\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdensity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msam\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrna_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msam\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"coolwarm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3736\\1730239127.py\u001b[0m in \u001b[0;36mdensity\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdensity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mxy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\scipy\\stats\\kde.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, bw_method, weights)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_neff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_weights\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_bandwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\scipy\\stats\\kde.py\u001b[0m in \u001b[0;36mset_bandwidth\u001b[1;34m(self, bw_method)\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_covariance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_compute_covariance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\scipy\\stats\\kde.py\u001b[0m in \u001b[0;36m_compute_covariance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    564\u001b[0m                                                \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m                                                aweights=self.weights))\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_inv_cov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_covariance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcovariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_covariance\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\scipy\\linalg\\basic.py\u001b[0m in \u001b[0;36minv\u001b[1;34m(a, overwrite_a, check_finite)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m     \"\"\"\n\u001b[1;32m--> 939\u001b[1;33m     \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    940\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0ma1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0ma1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'expected square matrix'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\scipy\\_lib\\_util.py\u001b[0m in \u001b[0;36m_asarray_validated\u001b[1;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'masked arrays are not supported'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[0mtoarray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray_chkfinite\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mobjects_ok\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'O'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AllFloat'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         raise ValueError(\n\u001b[1;32m--> 489\u001b[1;33m             \"array must not contain infs or NaNs\")\n\u001b[0m\u001b[0;32m    490\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: array must not contain infs or NaNs"]},{"data":{"text/plain":["<Figure size 2000x600 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 2000x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["n = 10  # how many digits we will display\n","sam = 50\n","plt.figure(figsize=(20, 6))\n","\n","with plt.style.context(['ggplot']):\n","    plt.figure(figsize=(20, 6))\n","    for i in range(10):\n","        # display original\n","        ax = plt.subplot(3, n, i + 1)\n","\n","        plt.scatter(y_pred[sam+i],rna_train[sam+i],c=density(y_pred[sam+i],rna_train[sam+i]),s=8,cmap=plt.get_cmap(\"coolwarm\"))\n","        ax = plt.subplot(3, n, i + 1*10+1)\n","\n","        plt.scatter(y_pred[sam+i+10],rna_train[sam+i+10],c=density(y_pred[sam+i+10],rna_train[sam+i+10]),s=8,cmap=plt.get_cmap(\"coolwarm\"))\n","        ax = plt.subplot(3, n, i + 1*20+1)\n","\n","        plt.scatter(y_pred[sam+i+20],rna_train[sam+i+20],c=density(y_pred[sam+i+20],rna_train[sam+i+20]),s=8,cmap=plt.get_cmap(\"coolwarm\"))\n","\n","\n","plt.tight_layout()\n","#plt.savefig('../analysis_plot/Figures/Train_Samples3_density.svg', format='svg')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["['Solarize_Light2',\n"," '_classic_test_patch',\n"," '_mpl-gallery',\n"," '_mpl-gallery-nogrid',\n"," 'bmh',\n"," 'classic',\n"," 'dark_background',\n"," 'fast',\n"," 'fivethirtyeight',\n"," 'ggplot',\n"," 'grayscale',\n"," 'seaborn',\n"," 'seaborn-bright',\n"," 'seaborn-colorblind',\n"," 'seaborn-dark',\n"," 'seaborn-dark-palette',\n"," 'seaborn-darkgrid',\n"," 'seaborn-deep',\n"," 'seaborn-muted',\n"," 'seaborn-notebook',\n"," 'seaborn-paper',\n"," 'seaborn-pastel',\n"," 'seaborn-poster',\n"," 'seaborn-talk',\n"," 'seaborn-ticks',\n"," 'seaborn-white',\n"," 'seaborn-whitegrid',\n"," 'tableau-colorblind10']"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["plt.style.available"]},{"cell_type":"markdown","metadata":{},"source":["Analysis of Testing set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(100, 277, 76)\n","(100, 1)\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\numpy\\lib\\function_base.py:2683: RuntimeWarning: Degrees of freedom <= 0 for slice\n","  c = cov(x, y, rowvar, dtype=dtype)\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["nan\n"]}],"source":["y_pred2 = dleps_p.model[0].predict(smile_test)\n","\n","corr = np.array([0.])\n","\n","print(smile_test.shape)\n","\n","print(y_pred2.shape)\n","for i in range(smile_test.shape[0]):\n","    corr=np.hstack((corr,np.corrcoef(rna_test[i],y_pred2[i])[0, 1]))\n","plt.hist(corr,50)\n","plt.show()\n","print(corr.mean())"]},{"cell_type":"markdown","metadata":{},"source":["Testing set"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[{"ename":"OSError","evalue":"'science' not found in the style library and input is not a valid URL or path; see `style.available` for list of available styles","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\matplotlib\\style\\core.py\u001b[0m in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                 \u001b[0mrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrc_params_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_default_template\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                 \u001b[0m_apply_style\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36mrc_params_from_file\u001b[1;34m(fname, fail_on_error, use_default_template)\u001b[0m\n\u001b[0;32m    853\u001b[0m     \"\"\"\n\u001b[1;32m--> 854\u001b[1;33m     \u001b[0mconfig_from_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_rc_params_in_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfail_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfail_on_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m_rc_params_in_file\u001b[1;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[0mrc_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_or_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m_open_file_or_url\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'science'","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5232\\3838771958.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m  \u001b[1;31m# how many digits we will display\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'science'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'no-latex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\matplotlib\\style\\core.py\u001b[0m in \u001b[0;36mcontext\u001b[1;34m(style, after_reset)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mafter_reset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcdefaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Anaconda3\\envs\\dleps\\lib\\site-packages\\matplotlib\\style\\core.py\u001b[0m in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    131\u001b[0m                     \u001b[1;34m\"{!r} not found in the style library and input is not a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                     \u001b[1;34m\"valid URL or path; see `style.available` for list of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m                     \"available styles\".format(style)) from err\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mOSError\u001b[0m: 'science' not found in the style library and input is not a valid URL or path; see `style.available` for list of available styles"]}],"source":["n = 10  # how many digits we will display\n","sam = 50\n","with plt.style.context(['science','no-latex']):\n","    plt.figure(figsize=(20, 6))\n","    for i in range(10):\n","        # display original\n","        ax = plt.subplot(3, n, i + 1)\n","\n","        plt.scatter(y_pred2[sam+i],rna_test[sam+i],s=8,c=density(y_pred2[sam+i],rna_test[sam+i]),cmap=\"coolwarm\")\n","        ax = plt.subplot(3, n, i + 1*10+1)\n","\n","        plt.scatter(y_pred2[sam+i+10],rna_test[sam+i+10],c=density(y_pred2[sam+i+10],rna_test[sam+i+10]),s=8,cmap=plt.get_cmap(\"coolwarm\"))\n","        ax = plt.subplot(3, n, i + 1*20+1)\n","\n","        plt.scatter(y_pred2[sam+i+20],rna_test[sam+i+20],c=density(y_pred2[sam+i+20],rna_test[sam+i+20]),s=8,cmap=plt.get_cmap(\"coolwarm\"))\n","\n","\n","plt.tight_layout()\n","#plt.savefig('../analysis_plot/Figures/Test_Samples3_density.svg', format='svg')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.7 ('tf1-gpu-DLEPS')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"},"vscode":{"interpreter":{"hash":"64d169dcd92e914faa081f4e9cd47ff21adbdd3c8af5f292933e0a8044a478c9"}}},"nbformat":4,"nbformat_minor":4}
